{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luigiantonelli/Algoritmi-formule-di-Horn/blob/main/NN_project_Antonelli_DeSantis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we are presenting our implementation of the Memorizing transformer architecture from the paper \"Memorizing Transformers\" by Yuhuai Wu, Markus N. Rabe, DeLesley Hutchins and Christian Szegedy (https://arxiv.org/abs/2203.08913).\n",
        "\n",
        "Memorizing transformers are decoder-only transformers which have the ability to store in a non-differentiable memory the internal representations of past inputs, allowing to combine local attention with a $k$-nearest neighbors search into the memory. In particular, the architecture of these models uses standard transfomer blocks and a special transformer block that uses this modified version of the attention, taking also into consideration information from previous training steps. For simplicity, we will refer to this block as \"memory block\" in the remainder of this notebook.\n",
        "\n",
        "As it is explained in the paper, the memory block is usually put almost at the end of the architecture and the use of more than one of these blocks doesn't result in better performances. We followed this approach and conduct our experiments by stacking multiple transformer blocks, followed by a memory block and by one last standard transformer block.\n",
        "\n",
        "The task that we are training our models on is language modeling. So the models are trained on their ability to predict the next word of a sequence given all the previous words in the sequence. The metric used to evalute the performance of the model on the test set is perplexity (https://torchmetrics.readthedocs.io/en/stable/text/perplexity.html?highlight=perplexity)."
      ],
      "metadata": {
        "id": "ZZGF-YhbMYid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations and imports"
      ],
      "metadata": {
        "id": "-4GElPh7HbB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section there is everything that is needed to run the cells of the notebook."
      ],
      "metadata": {
        "id": "lVJsp0dwMVb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_transformers --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW8KnU4lPkgI",
        "outputId": "8a0c98e4-db44-4526-d180-2e81c5761b29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_transformers import BertTokenizer\n",
        "from pytorch_transformers import BertModel"
      ],
      "metadata": {
        "id": "G5xdOnnKPbxi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata --quiet\n",
        "!pip install torchmetrics --quiet\n",
        "!pip install torchtext --quiet\n",
        "!pip install -U spacy --quiet\n",
        "!python -m spacy download en_core_web_sm --quiet"
      ],
      "metadata": {
        "id": "oZJbIamFP23c",
        "outputId": "97b04f5d-934e-4151-ed2a-95b9ac262b39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "import numpy as np\n",
        "from torch.nn import functional as F\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from pathlib import Path\n",
        "from filelock import FileLock\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pickle as pkl\n",
        "import torchtext\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import spacy\n",
        "from typing import Iterable, List\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchmetrics.text.perplexity import Perplexity\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "id": "Kd714QnlGIP-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a4BTaVB5Pxs",
        "outputId": "1e0eceef-4b82-458b-86c8-b503c140221c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dataset"
      ],
      "metadata": {
        "id": "zAXedSwA5nyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the datasets mentioned in the paper are too big to handle in reasonable time in a Colab notebook, we decided to use WikiText2, a smaller dataset.\n",
        "\n",
        "In this section the dataset is tokenized and then organized into documents. The dataset contains documents from Wikipedia, but the iterator returns them line by line and there are no end-of-sequence tokens at the end of each document that help in distinguishing different documents.\n",
        "In order to overcome this issue we decided to create fictitious documents of 10000 tokens each, so that we could train our models like described in the paper. For the purpose of the memorizing transformer architecture, having small sequences such as lines as training samples wouldn't justify the use of the external memory. In fact, the documents should be divided in subsequences and each long document should be fed into the memorizing transformer sequentially from start to end without doing any shuffling.\n",
        "Obviously, this is not optimal and not the same as having a dataset like the ones mentioned in the paper, but it's enough to conduct some experiments like we did.\n",
        "\n",
        "We tried two different alternatives for tokenization:\n",
        "* The first one consists in iterating over the lines in the dataset and building a vocabulary and then tokenize the dataset by using the vocabulary.\n",
        "* The second approach instead consists in tokenizing directly the dataset with the help of the Bert tokenizer.\n",
        "\n",
        "Then the tensor which contains all the encoded tokens in the dataset is organized into documents. With the first approach, the transformer would use the layer \"nn.Embedding\" from Pytorch to create the embeddings starting from a minibatch of subsequences of documents. With the second approach the transformer would use the Bert model to create the embeddings. Moreover, in the first case it's better to use a deeper transformers with more blocks, while in the second case we tried with fewer blocks since Bert is already a deep transformer.\n",
        "\n",
        "The second approach performs better than the first one but of course it's more expensive both in terms of time and in GPU memory usage."
      ],
      "metadata": {
        "id": "WTNyqPAfXWxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter, test_iter = WikiText2(split = ('train', 'test'))"
      ],
      "metadata": {
        "id": "jag9JLsDbyOB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decomment if you want to use the **first** method"
      ],
      "metadata": {
        "id": "Cu0QgLpVeq6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from itertools import chain\n",
        "data_iter = chain(train_iter, test_iter)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J4Lo0Rsz7fT-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6df41c8d-6f62-4bfb-ed70-bbce52d5c2ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom itertools import chain\\ndata_iter = chain(train_iter, test_iter)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "token_transform = get_tokenizer('spacy', language = 'en_core_web_sm')\n",
        "\n",
        "def yield_tokens(data) -> List[str]:\n",
        "    for line in data:\n",
        "        yield token_transform(line)\n",
        "\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "vocabulary_ = build_vocab_from_iterator(yield_tokens(data_iter), min_freq = 1, specials = special_symbols, special_first = True)\n",
        "vocabulary_.set_default_index(UNK_IDX)\n",
        "vocabulary_size = vocabulary_.__len__()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uvcwcyno7i6V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0501254c-8e29-4790-ea20-cabc52d60b18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntoken_transform = get_tokenizer('spacy', language = 'en_core_web_sm')\\n\\ndef yield_tokens(data) -> List[str]:\\n    for line in data:\\n        yield token_transform(line)\\n\\nUNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\\nspecial_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\\n\\nvocabulary_ = build_vocab_from_iterator(yield_tokens(data_iter), min_freq = 1, specials = special_symbols, special_first = True)\\nvocabulary_.set_default_index(UNK_IDX)\\nvocabulary_size = vocabulary_.__len__()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def preprocessing_(dataset):\n",
        "  new_ds = torch.tensor([], dtype = torch.int32)\n",
        "  for line in dataset:\n",
        "    tokenized_line = torch.tensor([vocabulary_[token] for token in token_transform(line)])\n",
        "    new_ds = torch.cat((new_ds, tokenized_line))\n",
        "  return new_ds\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0JbiwRcz8G7q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7ca3ecd-672b-48a9-cdd5-767c5019bfad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef preprocessing_(dataset):\\n  new_ds = torch.tensor([], dtype = torch.int32)\\n  for line in dataset:\\n    tokenized_line = torch.tensor([vocabulary_[token] for token in token_transform(line)])\\n    new_ds = torch.cat((new_ds, tokenized_line))\\n  return new_ds\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_ds = preprocessing_(train_iter)\n",
        "test_ds = preprocessing_(test_iter)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "R29fLy2G8fIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e98c4dfe-76f2-4e56-9834-509a3cb8b056"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_ds = preprocessing_(train_iter)\\ntest_ds = preprocessing_(test_iter)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_loader = DataLoader(train_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "print(len(train_loader))\n",
        "train_ds = torch.zeros((len(train_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(train_loader):\n",
        "  train_ds[i] = document\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NPZr6aDS7Lpc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff6f65e2-9bac-4d3d-981e-ec1aa4fa3b50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_loader = DataLoader(train_ds, batch_size = 10000, shuffle = False, drop_last = True)\\nprint(len(train_loader))\\ntrain_ds = torch.zeros((len(train_loader), 10000), dtype = torch.int32)\\nfor i, document in enumerate(train_loader):\\n  train_ds[i] = document\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "test_loader = DataLoader(test_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "\n",
        "test_ds = torch.zeros((len(test_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(test_loader):\n",
        "  test_ds[i] = document\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1hKcNRVn7Qu8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "335b898a-e088-4039-b922-caf6c0f71d0b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntest_loader = DataLoader(test_ds, batch_size = 10000, shuffle = False, drop_last = True)\\n\\ntest_ds = torch.zeros((len(test_loader), 10000), dtype = torch.int32)\\nfor i, document in enumerate(test_loader):\\n  test_ds[i] = document\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"train_ds.shape\"\"\""
      ],
      "metadata": {
        "id": "Q1te4chM7YAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "3e8a6f91-a3d1-4355-a706-220f8fe07aae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_ds.shape'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"test_ds.shape\"\"\""
      ],
      "metadata": {
        "id": "sk6OYEl_7Z6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "00062e94-9f28-4aa5-85a5-c9caeedb33d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_ds.shape'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decomment if you want to use the **second** method"
      ],
      "metadata": {
        "id": "BuKPJwBLwVbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zlNANpHQiOt",
        "outputId": "0918d8fe-f510-4672-8be4-ab3842e2d4b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 343905.43B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(dataset):\n",
        "  new_ds = []\n",
        "  for line in dataset:\n",
        "    tokenized_line = tokenizer.tokenize(line)\n",
        "    new_ds.append(tokenized_line)\n",
        "  return new_ds"
      ],
      "metadata": {
        "id": "RnfQlE72RQCR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = preprocessing(train_iter)\n",
        "test_ds = preprocessing(test_iter)"
      ],
      "metadata": {
        "id": "t4ZDCYlDRei8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tokens_to_idxs(dataset):\n",
        "  new_ds = torch.tensor([], dtype = torch.int32)\n",
        "  for line in dataset:\n",
        "    tokenized_line = torch.tensor(tokenizer.convert_tokens_to_ids(line))    \n",
        "    new_ds = torch.cat((new_ds, tokenized_line))\n",
        "  return new_ds"
      ],
      "metadata": {
        "id": "_wQHPc5URusJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = convert_tokens_to_idxs(train_ds)\n",
        "test_ds = convert_tokens_to_idxs(test_ds)"
      ],
      "metadata": {
        "id": "VjlekiRPSahL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728f17c0-6774-47a8-e3d9-a21888aeb84a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (895 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (842 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (835 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
            "WARNING:pytorch_transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCEOkwkgTQiS",
        "outputId": "538a194e-bba7-405c-c4e9-53bd57413bf3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2405592])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 30522"
      ],
      "metadata": {
        "id": "juDl2xbjdzEF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "print(len(train_loader))\n",
        "train_ds = torch.zeros((len(train_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(train_loader):\n",
        "  train_ds[i] = document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zCX45xyL955",
        "outputId": "5ffcff95-3d7b-415e-afaf-435275896718"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_ds, batch_size = 10000, shuffle = False, drop_last = True)\n",
        "\n",
        "test_ds = torch.zeros((len(test_loader), 10000), dtype = torch.int32)\n",
        "for i, document in enumerate(test_loader):\n",
        "  test_ds[i] = document"
      ],
      "metadata": {
        "id": "KlSGhT9-dCDt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGcfKRdsP98_",
        "outputId": "321631dc-9c49-417a-faac-e3de8d11ed22"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([240, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds.shape"
      ],
      "metadata": {
        "id": "B0wCMRhZdatc",
        "outputId": "e0c0991a-1112-4b4e-88ca-6251b87c75ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN Memory"
      ],
      "metadata": {
        "id": "4I2ce2jPLzle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section of the notebook is dedicated to the definition of the external memory that will be used by the memorizing transformer. We were allowed to use this code from https://github.com/lucidrains/memorizing-transformers-pytorch/blob/main/memorizing_transformers_pytorch/knn_memory.py, so we are using the KNNMemory as a black-box. \n",
        "\n",
        "Right before training we will instanciate an object of the class KNNMemory defined in this section that will be one of the inputs of the memory block of our model. With the building blocks provided in the next sections it's possible to create a memorizing transformer with more memory blocks. In that case, it would be necessary to create one KNNMemory object for each of these blocks and modify the forward method of our class."
      ],
      "metadata": {
        "id": "8pYePr4DhW65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QppURbZ0KL0f",
        "outputId": "c9292f4e-4a9b-4588-bc64-1dd3f5982043"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krC3-klsLPVa",
        "outputId": "81375d14-d6e7-46a4-c703-2ccd1f556088"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import per la knn memory\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "import faiss\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import wraps\n",
        "\n",
        "from contextlib import ExitStack, contextmanager\n",
        "\n",
        "from einops import rearrange, pack, unpack\n",
        "\n",
        "# multiprocessing\n",
        "\n",
        "from joblib import Parallel, delayed, cpu_count"
      ],
      "metadata": {
        "id": "KeHkdSn0KBSP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FAISS_INDEX_GPU_ID = int(os.getenv('FAISS_INDEX_GPU_ID', 0))\n",
        "\n",
        "DEFAULT_KNN_MEMORY_MEMMAP_DIRECTORY = './.tmp/knn.memories'\n",
        "\n",
        "# helper functions\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "def cast_list(val):\n",
        "    return val if isinstance(val, list) else [val]\n",
        "\n",
        "def all_el_unique(arr):\n",
        "    return len(set(arr)) == len(arr)\n",
        "\n",
        "@contextmanager\n",
        "def multi_context(*cms):\n",
        "    with ExitStack() as stack:\n",
        "        yield [stack.enter_context(cls) for cls in cms]\n",
        "\n",
        "def count_intersect(x, y):\n",
        "    # returns an array that shows how many times an element in x is contained in tensor y\n",
        "    return np.sum(rearrange(x, 'i -> i 1') == rearrange(y, 'j -> 1 j'), axis = -1)\n",
        "\n",
        "def check_shape(tensor, pattern, **kwargs):\n",
        "    return rearrange(tensor, f\"{pattern} -> {pattern}\", **kwargs)\n",
        "\n",
        "# a wrapper around faiss IndexIVFFlat\n",
        "# taking care of expiring old keys automagically\n",
        "\n",
        "class KNN():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_num_entries,\n",
        "        cap_num_entries = False,\n",
        "        M = 15,\n",
        "        keep_stats = False\n",
        "    ):\n",
        "        index = faiss.IndexHNSWFlat(dim, M, faiss.METRIC_INNER_PRODUCT)\n",
        "        self.index = index\n",
        "        self.max_num_entries = max_num_entries\n",
        "        self.cap_num_entries = cap_num_entries\n",
        "        self.is_trained = False\n",
        "        self.keep_stats = keep_stats\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'index'):\n",
        "            del self.index\n",
        "\n",
        "    def reset(self):\n",
        "        self.ids = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.empty((0,), dtype = np.int32)\n",
        "            self.age_num_iterations = np.empty((0,), dtype = np.int32)\n",
        "            self.ages_since_last_hit = np.empty((0,), dtype = np.int32)\n",
        "\n",
        "        self.index.reset()\n",
        "        self.is_trained = False\n",
        "\n",
        "    def train(self, x):\n",
        "        self.index.train(x)\n",
        "        self.is_trained = True\n",
        "\n",
        "    def add(self, x, ids):\n",
        "        if not self.is_trained:\n",
        "            self.train(x)\n",
        "\n",
        "        self.ids = np.concatenate((ids, self.ids))\n",
        "\n",
        "        if self.keep_stats:\n",
        "            self.hits = np.concatenate((np.zeros_like(ids), self.hits))\n",
        "            self.age_num_iterations = np.concatenate((np.zeros_like(ids), self.age_num_iterations))\n",
        "            self.ages_since_last_hit = np.concatenate((np.zeros_like(ids), self.ages_since_last_hit))\n",
        "\n",
        "        if self.cap_num_entries and len(self.ids) > self.max_num_entries:\n",
        "            self.reset()\n",
        "\n",
        "        return self.index.add(x)\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        x,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        return_distances = False,\n",
        "        increment_hits = False,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        if not self.is_trained:\n",
        "            return np.full((x.shape[0], topk), -1)\n",
        "\n",
        "        distances, indices = self.index.search(x, k = topk)\n",
        "\n",
        "        if increment_hits and self.keep_stats:\n",
        "            hits = count_intersect(self.ids, rearrange(indices, '... -> (...)'))\n",
        "            self.hits += hits\n",
        "\n",
        "            self.ages_since_last_hit += 1\n",
        "            self.ages_since_last_hit *= (hits == 0)\n",
        "\n",
        "        if increment_age and self.keep_stats:\n",
        "            self.age_num_iterations += 1\n",
        "\n",
        "        if return_distances:\n",
        "            return indices, distances\n",
        "\n",
        "        return indices\n",
        "\n",
        "# KNN memory layer, where one can store key / value memories\n",
        "# can automatically take care of a collection of faiss indices (across batch dimension)\n",
        "\n",
        "class KNNMemory():\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        max_memories = 16000,\n",
        "        num_indices = 1,\n",
        "        memmap_filename = './knn.memory.memmap',\n",
        "        multiprocessing = True\n",
        "    ):\n",
        "        self.dim = dim\n",
        "        self.num_indices = num_indices\n",
        "        self.scoped_indices = list(range(num_indices))\n",
        "\n",
        "        self.max_memories = max_memories\n",
        "        self.shape = (num_indices, max_memories, 2, dim)\n",
        "        self.db_offsets = np.zeros(num_indices, dtype = np.int32)\n",
        "\n",
        "        self.db = np.memmap(memmap_filename, mode = 'w+', dtype = np.float32, shape = self.shape)\n",
        "        self.knns = [KNN(dim = dim, max_num_entries = max_memories, cap_num_entries = True) for _ in range(num_indices)]\n",
        "    \n",
        "        self.n_jobs = cpu_count() if multiprocessing else 1\n",
        "\n",
        "    def set_scoped_indices(self, indices):\n",
        "        indices = list(indices)\n",
        "        assert all_el_unique(indices), f'all scoped batch indices must be unique, received: {indices}'\n",
        "        assert all([0 <= i < self.num_indices for i in indices]), f'each batch index must be between 0 and less than {self.num_indices}: received {indices}'\n",
        "        self.scoped_indices = indices\n",
        "\n",
        "    @contextmanager\n",
        "    def at_batch_indices(self, indices):\n",
        "        prev_indices = self.scoped_indices\n",
        "        self.set_scoped_indices(indices)\n",
        "        yield self\n",
        "        self.set_scoped_indices(prev_indices)\n",
        "\n",
        "    def clear(self, batch_indices = None):\n",
        "        if not exists(batch_indices):\n",
        "            batch_indices = list(range(self.num_indices))\n",
        "\n",
        "        batch_indices = cast_list(batch_indices)\n",
        "\n",
        "        for index in batch_indices:\n",
        "            knn = self.knns[index]\n",
        "            knn.reset()\n",
        "\n",
        "        self.db_offsets[batch_indices] = 0\n",
        "\n",
        "    def add(self, memories):\n",
        "        check_shape(memories, 'b n kv d', d = self.dim, kv = 2, b = len(self.scoped_indices))\n",
        "\n",
        "        memories = memories.detach().cpu().numpy()\n",
        "        memories = memories[:, -self.max_memories:]\n",
        "        num_memories = memories.shape[1]\n",
        "\n",
        "        knn_insert_ids = np.arange(num_memories)\n",
        "\n",
        "        keys = np.ascontiguousarray(memories[..., 0, :])\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "        db_offsets = [self.db_offsets[i] for i in self.scoped_indices]\n",
        "\n",
        "        # use joblib to insert new key / value memories into faiss index\n",
        "\n",
        "        @delayed\n",
        "        def knn_add(knn, key, db_offset):\n",
        "            knn.add(key, ids = knn_insert_ids + db_offset)\n",
        "            return knn\n",
        "\n",
        "        updated_knns = Parallel(n_jobs = self.n_jobs)(knn_add(*args) for args in zip(knns, keys, db_offsets))\n",
        "        for knn_idx, scoped_idx in enumerate(self.scoped_indices):\n",
        "            self.knns[scoped_idx] = updated_knns[knn_idx]\n",
        "\n",
        "        # add the new memories to the memmap \"database\"\n",
        "\n",
        "        add_indices = (rearrange(np.arange(num_memories), 'j -> 1 j') + rearrange(self.db_offsets[list(self.scoped_indices)], 'i -> i 1')) % self.max_memories\n",
        "        self.db[rearrange(np.array(self.scoped_indices), 'i -> i 1'), add_indices] = memories\n",
        "        self.db.flush()\n",
        "\n",
        "        self.db_offsets += num_memories\n",
        "\n",
        "    def search(\n",
        "        self,\n",
        "        queries,\n",
        "        topk,\n",
        "        nprobe = 8,\n",
        "        increment_hits = True,\n",
        "        increment_age = True\n",
        "    ):\n",
        "        check_shape(queries, 'b ... d', d = self.dim, b = len(self.scoped_indices))\n",
        "        queries, ps = pack([queries], 'b * d')\n",
        "\n",
        "        device = queries.device\n",
        "        queries = queries.detach().cpu().numpy()\n",
        "\n",
        "        all_masks = []\n",
        "        all_key_values = []\n",
        "\n",
        "        knns = [self.knns[i] for i in self.scoped_indices]\n",
        "\n",
        "        # parallelize faiss search\n",
        "\n",
        "        @delayed\n",
        "        def knn_search(knn, query):\n",
        "            return knn.search(query, topk, nprobe, increment_hits = increment_hits, increment_age = increment_age)\n",
        "\n",
        "        fetched_indices = Parallel(n_jobs = self.n_jobs)(knn_search(*args) for args in zip(knns, queries))\n",
        "\n",
        "        # get all the memory key / values from memmap 'database'\n",
        "        # todo - remove for loop below\n",
        "\n",
        "        for batch_index, indices in zip(self.scoped_indices, fetched_indices):\n",
        "            mask = indices !=  -1\n",
        "            db_indices = np.where(mask, indices, 0)\n",
        "\n",
        "            all_masks.append(torch.from_numpy(mask))\n",
        "\n",
        "            key_values = self.db[batch_index, db_indices % self.max_memories]\n",
        "            all_key_values.append(torch.from_numpy(key_values))\n",
        "\n",
        "        all_masks = torch.stack(all_masks)\n",
        "        all_key_values = torch.stack(all_key_values)\n",
        "        all_key_values = all_key_values.masked_fill(~rearrange(all_masks, '... -> ... 1 1'), 0.)\n",
        "\n",
        "        all_key_values, = unpack(all_key_values, ps, 'b * n kv d')\n",
        "        all_masks, = unpack(all_masks, ps, 'b * n')\n",
        "\n",
        "        return all_key_values.to(device), all_masks.to(device)\n",
        "\n",
        "    def __del__(self):\n",
        "        if hasattr(self, 'knns'):\n",
        "            for knn in self.knns:\n",
        "                del knn\n",
        "        del self.db"
      ],
      "metadata": {
        "id": "E5Wk2XJSLr-9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memorizing transformers"
      ],
      "metadata": {
        "id": "tWJS8R3fL7RM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we have defined all the necessary building blocks to create a memorizing transformer, but also a decoder-only transformer and a classic encoder-decoder transformer.\n",
        "\n",
        "The MultiHeadAttention class uses standard dot product attention like the one that we have seen in the slides of the course. The KNNAttention (the $k$NN-augmented attention layer) class instead combines dot product attention $V_c$ with the KNNattention $V_m$ coming from the nearest neighbors retrieved from the memory. These two attention values are combined with a learned gate $g = \\sigma (b_g)$, where $b_g$ is a \"nn.Parameter\" with one element for each head and $\\sigma$ is the sigmoid function, in this way (before a final projection):\n",
        "\n",
        "$$V_{\\text{final}} = V_m \\odot g + V_c \\odot (1 - g)$$\n",
        "\n"
      ],
      "metadata": {
        "id": "l6frAwwDkVzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value, sqrt_q, device, mask = None):\n",
        "    t = torch.matmul(query, key.transpose(-2, -1))/sqrt_q\n",
        "    if mask is not None:\n",
        "      t = t.masked_fill_(mask == 0, -1e-9) #-1e-9 acts like -infinity, so that the softmax will consider these tokens less important\n",
        "    return torch.matmul(F.softmax(t, dim = -1), value)\n",
        "\n",
        "def KNNattention(query, key, value, sqrt_q, mask):\n",
        "    t = torch.einsum('b h i q, b h i j q -> b h i j', query, key)/sqrt_q\n",
        "    return torch.einsum('b h i j, b h i j q -> b h i q', F.softmax(t.masked_fill_(mask, -1e-9), dim = -1), value)"
      ],
      "metadata": {
        "id": "ZK8XwbNMp5vT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d, h, batch_size):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    assert d % h == 0\n",
        "    #assume q = v \n",
        "    self.q = d // h #single head dimension\n",
        "    self.sqrt_q = sqrt(self.q)\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.W_q = nn.Linear(d, d, bias = False) #stack of h matrices of dimension (d, q), one for each head\n",
        "    self.W_k = nn.Linear(d, d, bias = False)\n",
        "    self.W_v = nn.Linear(d, d, bias = False)\n",
        "    self.W_o = nn.Linear(d, d, bias = False)\n",
        "\n",
        "  def forward(self, x, mask = None):\n",
        "    query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "    #new_memories = torch.stack((key, value), dim = -2).detach()\n",
        "    attention_value = attention(query, key, value, self.sqrt_q, mask)\n",
        "    return self.W_o(attention_value.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q))"
      ],
      "metadata": {
        "id": "AwoLII4LMvUK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KNNAttention(nn.Module):\n",
        "   def __init__(self, d, h, batch_size, num_retrieved_memories):\n",
        "      super(KNNAttention, self).__init__()\n",
        "      assert d % h == 0\n",
        "      #assume q = v \n",
        "      self.q = d // h\n",
        "      self.sqrt_q = sqrt(self.q)\n",
        "      self.h = h\n",
        "      self.W_q = nn.Linear(d, d, bias = False)\n",
        "      self.W_k = nn.Linear(d, d, bias = False)\n",
        "      self.W_v = nn.Linear(d, d, bias = False)\n",
        "      self.W_o = nn.Linear(d, d, bias = False)\n",
        "      self.b_g = nn.Parameter(torch.randn((h,))) #one for each head\n",
        "      self.num_retrieved_memories = num_retrieved_memories\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "   def forward(self, x, mask, knn_memory):\n",
        "      # calculate local attention \n",
        "      query = self.W_q(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      key = self.W_k(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      value = self.W_v(x).view(self.batch_size, -1, self.h, self.q).transpose(1, 2)\n",
        "      local_attention = attention(query, key, value, self.sqrt_q, mask)\n",
        "\n",
        "      # calculate knn attention over memory\n",
        "      query = F.normalize(query, dim = -1)\n",
        "      key = F.normalize(key, dim = -1)\n",
        "      mem_kv, mem_mask = knn_memory.search(query, self.num_retrieved_memories)\n",
        "      mem_key, mem_value = mem_kv.unbind(dim = -2)\n",
        "      knn_attention = KNNattention(query, mem_key, mem_value, self.sqrt_q, ~mem_mask)\n",
        "\n",
        "      # memory to be stored\n",
        "      new_kv_memories = torch.stack((key, value), dim = -2).view(self.batch_size, -1, 2, self.q).detach()\n",
        "\n",
        "      # add to knn memory\n",
        "      if new_kv_memories.numel() > 0:\n",
        "        knn_memory.add(new_kv_memories)\n",
        "\n",
        "      # combining local and memory\n",
        "      g = torch.sigmoid(self.b_g)\n",
        "      final_attention = torch.einsum('b h n q, h -> b h n q', knn_attention, g) + \\\n",
        "                        torch.einsum('b h n q, h -> b h n q', local_attention, (1 - g))\n",
        "      \n",
        "      return self.W_o(final_attention.transpose(1, 2).contiguous().view(self.batch_size, -1, self.h*self.q))"
      ],
      "metadata": {
        "id": "921DW0jjMyWx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decided to use the same positional encoding proposed in the paper \"Attention is all you need\". In the memorizing transformer paper the authors decided to use the T5 relative position bias in the local attention in order to improve the performance when processing long documents. In our case it would be possible to add it by modifying the function \"attention\" function, since in the paper the authors aren't using it for the retrieved memories."
      ],
      "metadata": {
        "id": "2a18-79rF5Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, d, max_len = 5000):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    pe = torch.zeros(max_len, d)\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d, 2) * -(math.log(10000.0) / d))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    return x + Variable(self.pe[:, :x.size(1)], requires_grad = False)"
      ],
      "metadata": {
        "id": "9U77GkT0cT4u"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class allows to create both regular transformer blocks and memory blocks. In fact, it's a \"nn.Module\" composed by one layer between multi-head attention and $k$NN-augmented attention, followed by layer normalization, a feed forward network and another layer normalization. There are also two residual connections right before each layer normalization. Objects of this class can be used to build decoder-only transformers or as blocks of the encoder in the standard encoder-decoder transformers."
      ],
      "metadata": {
        "id": "cxr0RNByVNlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, d, h, batch_size, hidden_size, dropout, is_mem = False, num_retrieved_memories = 32):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.d = d\n",
        "    self.h = h\n",
        "    self.batch_size = batch_size\n",
        "    self.attention = MultiHeadAttention(d, h, batch_size) if not is_mem else KNNAttention(d, h, batch_size, num_retrieved_memories)\n",
        "    self.norm1 = nn.LayerNorm(d)\n",
        "    self.dropout1 = nn.Dropout(dropout)\n",
        "    self.norm2 = nn.LayerNorm(d)\n",
        "    self.dropout2 = nn.Dropout(dropout)\n",
        "    self.ff = nn.Sequential(nn.Linear(d, hidden_size, bias = True), \n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(hidden_size, d, bias = True))\n",
        "  def forward(self, x, mask, knn_memory = None):\n",
        "    if knn_memory is None:\n",
        "      x = x + self.attention(x, mask)\n",
        "    else:\n",
        "      x = x + self.attention(x, mask, knn_memory)\n",
        "    x = self.dropout1(self.norm1(x))\n",
        "    x = x + self.ff(x)\n",
        "    x = self.dropout2(self.norm2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "prYm-KEpwLQq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objects of this class can be used as blocks of the decoder in the standard encoder-decoder transformers. In this notebook it is not used."
      ],
      "metadata": {
        "id": "bM5LDi2Tauty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module): #not used in this notebook\n",
        "  def __init__(self, d, h, batch_size, hidden_size, dropout):\n",
        "    super(DecoderBlock, self).__init__()\n",
        "    self.attention = MultiHeadAttention(d, h, batch_size)\n",
        "    self.norm = nn.LayerNorm(d)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.transformer_block = TransformerBlock(d, h, batch_size, hidden_size, dropout)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = x + self.attention(x, mask)\n",
        "    x = self.dropout(self.norm(x))\n",
        "    return self.transformer_block(x)"
      ],
      "metadata": {
        "id": "P4fkZ_djysyF"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the class that allows to create memorizing transformers with a desired number of transformer blocks (depth) and with a memory block in a desired position. Like explained before, our models use a memory block as penultimate block. The inputs to this series of blocks are the embeddings of the tokens plus the positional embeddings. The embeddings can be creates from the layer \"nn.Embedding\" or from Bert. The output of these blocks is then passed to a final linear layer so that the memorizing transformer can assign to each term in the vocabulary a probability. Actually, the model returns the logits and the probabilities are computed directly by the cross entropy loss during training."
      ],
      "metadata": {
        "id": "zRpoV-fuJTWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MemorizingTransformer(nn.Module):\n",
        "    def __init__(\n",
        "          self,\n",
        "          num_tokens,\n",
        "          d,\n",
        "          heads = 8,\n",
        "          depth = 4,\n",
        "          knn_attn_idx = 2,\n",
        "          attn_dropout = 0.,\n",
        "          hidden_size = 1000,\n",
        "          dropout = 0.3,\n",
        "          max_knn_memories = 1000,\n",
        "          num_retrieved_memories = 32,\n",
        "          batch_size = 16,\n",
        "          use_bert = True\n",
        "      ):\n",
        "          self.use_bert = use_bert\n",
        "          self.d = d if not self.use_bert else 768\n",
        "\n",
        "          # asserts\n",
        "          assert self.d % heads == 0\n",
        "          assert knn_attn_idx < depth\n",
        "\n",
        "          super(MemorizingTransformer, self).__init__()\n",
        "          if use_bert:\n",
        "            self.token_emb = BertModel.from_pretrained('bert-base-uncased') #with BERT\n",
        "          else:\n",
        "            self.token_emb = nn.Embedding(num_tokens, self.d) #without BERT\n",
        "          \n",
        "          self.positional_enc = PositionalEncoding(self.d, max_len = 5000)\n",
        "          self.dim_head = self.d // heads #the q of the blocks\n",
        "          \n",
        "          self.heads = heads\n",
        "          self.knn_attn_idx = knn_attn_idx\n",
        "          self.depth = depth\n",
        "          self.attn_dropout = attn_dropout\n",
        "          self.hidden_size = hidden_size\n",
        "          self.dropout = dropout\n",
        "          self.max_knn_memories = max_knn_memories\n",
        "          self.num_retrieved_memories = num_retrieved_memories\n",
        "          self.batch_size = batch_size\n",
        "\n",
        "          self.layers = nn.ModuleList([])\n",
        "          for idx in range(depth):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(self.d, heads, batch_size, hidden_size, dropout, is_mem = idx == self.knn_attn_idx)\n",
        "            )\n",
        "\n",
        "          self.to_out = nn.Linear(self.d, num_tokens)\n",
        "    \n",
        "    def create_mask(self, x): #compute a mask so that the prediction of the next token can only depend on the previous tokens\n",
        "      batch_size, seq_len = x.shape\n",
        "      mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "          batch_size, 1, seq_len, seq_len)\n",
        "      return mask    \n",
        "          \n",
        "    def forward(self, x, knn_memory):\n",
        "      mask = self.create_mask(x)\n",
        "      if self.use_bert:\n",
        "        x = self.token_emb(x)[0] #with BERT\n",
        "      else:\n",
        "        x = self.token_emb(x) #without BERT\n",
        "      \n",
        "      x = self.positional_enc(x)\n",
        "\n",
        "      for idx in range(self.depth):\n",
        "          x= self.layers[idx](x, mask, knn_memory = knn_memory if idx == self.knn_attn_idx else None)\n",
        "\n",
        "      return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "F5uqCzrVL569"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "ihBnTrPhaiDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_BERT = True #False if you want to train without BERT\n",
        "BATCH_SIZE = 4\n",
        "SEQ_LEN = 256\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS \n",
        "DIM_HEAD_BERT = 768 // HEADS #it's 96 with bert (768/8)\n",
        "\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 1\n",
        "CHECKPOINT = 1"
      ],
      "metadata": {
        "id": "ncWOJOkFanTK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = None\n",
        "memory = None\n",
        "data = None\n",
        "train_loader_ = None\n",
        "test_loader_ = None"
      ],
      "metadata": {
        "id": "kWjcjNDgEiuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we're creating the model for training, with 4 transformers blocks, and the KNNMemory object. The parameter \"num_indices\" must be equal to the batch size because every element in a batch is a subsequence coming from a different document, so it requires a separate external memory to do useful predictions based on the outputs from the previous training steps on the same document. \n",
        "\n",
        "Since the resources provided by Colab are limited, we are using a small memory with at most one thousands elements. In the paper, the authors were using significally bigger memory (65 thousands elements to achieve the best results) and a memorizing transformer with more blocks (12). \n",
        "\n",
        "The results of the paper show that the number of retrieved memories (the number of neighbors) doesn't affect performance in a significant way and 32 is enough to achieve almost a perplexity as good as 128 or 256 neighbors.\n",
        "\n",
        "Here the train and test loaders pack entire documents into batches and the division in subsequences is done directly in the training and evaluation loops."
      ],
      "metadata": {
        "id": "zxSagOtMOxc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MemorizingTransformer(\n",
        "    num_tokens = vocabulary_size,\n",
        "    d = SEQ_LEN,\n",
        "    heads = HEADS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    depth = 4,\n",
        "    knn_attn_idx = 2,\n",
        "    num_retrieved_memories = 32,\n",
        "    use_bert = USE_BERT\n",
        ").to(device)\n",
        "\n",
        "memory = KNNMemory(\n",
        "    dim = DIM_HEAD_BERT if USE_BERT else DIM_HEAD,       \n",
        "    max_memories = 3000,       #maximum number of memories (old ones will be discarded after reaching maximum capacity)\n",
        "    num_indices = BATCH_SIZE   #each element in the batch keeps track of its own memories, expiring when it sees a new document\n",
        ")\n",
        "\n",
        "train_loader_ = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)\n",
        "test_loader_ = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)"
      ],
      "metadata": {
        "id": "1gVvmKCm3J4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a731758-7e91-4dba-91d4-b25de39955bd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 433/433 [00:00<00:00, 285780.27B/s]\n",
            "100%|██████████| 440473133/440473133 [00:35<00:00, 12238059.29B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the training loop we consider batches of documents and we divide these documents in subsequences so that the input to the memorizing transformer has always the same shape and each document is fed sequentially to the transformer. The subsequences are (SEQ_LEN + 1) long because the first SEQ_LEN tokens are used as input and all the tokens except the first one are used as labels to compute the cross entropy.\n",
        "\n",
        "The perplexity is calculated every EVAL_EVERY epoch thanks to the class Perplexity from TorchMetrics. There's a transpose of the output of the transformer because the model returns a tensor of shape $[\\text{batch size}, \\text{vocabulary size}, \\text{subsequence length}]$ that is compatible with the cross entropy loss and the perplexity expects as prediction a tensor of size $[\\text{batch size}, \\text{subsequence length}, \\text{vocabulary size}]$."
      ],
      "metadata": {
        "id": "mf1J5F1lVxlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epochs = 3\n",
        "# training\n",
        "\n",
        "perplexity_list = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, data in enumerate(tqdm.tqdm(train_loader_, desc = 'training')):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "\n",
        "    num_seq = 10000 // (SEQ_LEN + 1) #10000 is the length of each document\n",
        "    data = data.long().to(device)\n",
        "    for j in range(num_seq):\n",
        "      #we are taking (SEQ_LEN + 1) elements each time so that in the next iteration we will consider the same documents again, unless they are finished\n",
        "      mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "      seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "      out = model(\n",
        "        seq,\n",
        "        knn_memory = memory\n",
        "      )\n",
        "      loss_item = loss(out, labels)\n",
        "      print(f'training loss: {loss_item}', flush = True)\n",
        "      loss_item.backward() \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "  data = None\n",
        "\n",
        "  if e % EVAL_EVERY == 0:\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      metric = Perplexity().to(device)\n",
        "      for i, data in enumerate(tqdm.tqdm(test_loader_, desc = 'evaluation')):\n",
        "        num_seq = 10000 // (SEQ_LEN + 1)\n",
        "        data = data.long().to(device)\n",
        "\n",
        "        for j in range(num_seq):\n",
        "          #we are taking (SEQ_LEN + 1) elements each time so that in the next iteration we will consider the same documents again, unless they are finished\n",
        "          mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)] \n",
        "          seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "          out = model(\n",
        "            seq,\n",
        "            knn_memory = memory\n",
        "          )\n",
        "          #test_loss = loss(out, labels)\n",
        "          metric(out.transpose(1, 2), labels)\n",
        "          #print(f'test loss: {test_loss}', flush = True)\n",
        "\n",
        "      perplexity = metric.compute()\n",
        "      perplexity_list.append(perplexity.to(\"cpu\").item())\n",
        "      print(f'perplexity: {perplexity}', flush = True)\n",
        "\n",
        "  data = None\n",
        "  if e % CHECKPOINT == 0:\n",
        "    #Luigi\n",
        "    torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, 'drive/MyDrive/Colab Notebooks/model_optimizer_mem.pt')\n",
        "    \"\"\"\n",
        "    #Lorenzo\n",
        "    with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity_moreNN.npy', 'wb') as f:\n",
        "      np.save(f, np.array(perplexity_list))\n",
        "    \"\"\"\n",
        "    #Luigi\n",
        "    with open(f'drive/MyDrive/Colab Notebooks/perplexity_memorizing_tr.pkl', 'wb') as pklfile:\n",
        "      pkl.dump(perplexity_list, pklfile)\n"
      ],
      "metadata": {
        "id": "9sF-vlC6koIo",
        "outputId": "4c95579c-35f4-46fb-b631-83b01bc883ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/60 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.171414852142334\n",
            "training loss: 7.076554298400879\n",
            "training loss: 7.106293678283691\n",
            "training loss: 7.162178039550781\n",
            "training loss: 7.092389106750488\n",
            "training loss: 7.142233848571777\n",
            "training loss: 7.000646591186523\n",
            "training loss: 7.186374664306641\n",
            "training loss: 6.800782203674316\n",
            "training loss: 6.785490036010742\n",
            "training loss: 6.849967956542969\n",
            "training loss: 6.993776321411133\n",
            "training loss: 6.651440620422363\n",
            "training loss: 6.869179725646973\n",
            "training loss: 7.020290374755859\n",
            "training loss: 6.762753486633301\n",
            "training loss: 6.711966514587402\n",
            "training loss: 7.083611965179443\n",
            "training loss: 7.270383834838867\n",
            "training loss: 7.185549736022949\n",
            "training loss: 7.0154194831848145\n",
            "training loss: 6.945617198944092\n",
            "training loss: 7.08819055557251\n",
            "training loss: 6.815868377685547\n",
            "training loss: 6.854002952575684\n",
            "training loss: 6.878269195556641\n",
            "training loss: 6.849568843841553\n",
            "training loss: 6.816586494445801\n",
            "training loss: 6.963411331176758\n",
            "training loss: 7.168483734130859\n",
            "training loss: 6.8007354736328125\n",
            "training loss: 7.01601505279541\n",
            "training loss: 7.258560657501221\n",
            "training loss: 7.174571514129639\n",
            "training loss: 7.23443078994751\n",
            "training loss: 7.346636772155762\n",
            "training loss: 7.276353359222412\n",
            "training loss: 6.996483325958252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 1/60 [00:51<50:36, 51.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.644317626953125\n",
            "training loss: 7.524776458740234\n",
            "training loss: 7.525722980499268\n",
            "training loss: 7.318312644958496\n",
            "training loss: 7.306836128234863\n",
            "training loss: 7.062817573547363\n",
            "training loss: 7.18632698059082\n",
            "training loss: 7.144221782684326\n",
            "training loss: 6.945761680603027\n",
            "training loss: 6.914910793304443\n",
            "training loss: 6.924144744873047\n",
            "training loss: 6.936874866485596\n",
            "training loss: 6.995830059051514\n",
            "training loss: 6.783489227294922\n",
            "training loss: 6.879090785980225\n",
            "training loss: 6.988613128662109\n",
            "training loss: 7.00388765335083\n",
            "training loss: 6.88250207901001\n",
            "training loss: 6.7384114265441895\n",
            "training loss: 7.207270622253418\n",
            "training loss: 7.170523166656494\n",
            "training loss: 7.039762496948242\n",
            "training loss: 7.117387294769287\n",
            "training loss: 6.958399295806885\n",
            "training loss: 6.967794418334961\n",
            "training loss: 6.942041873931885\n",
            "training loss: 7.313813209533691\n",
            "training loss: 7.328791618347168\n",
            "training loss: 7.131220817565918\n",
            "training loss: 7.4036054611206055\n",
            "training loss: 7.0376129150390625\n",
            "training loss: 7.510856628417969\n",
            "training loss: 7.013208866119385\n",
            "training loss: 7.163098335266113\n",
            "training loss: 7.051567077636719\n",
            "training loss: 6.873379230499268\n",
            "training loss: 7.035056114196777\n",
            "training loss: 7.034491062164307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   3%|▎         | 2/60 [01:39<48:03, 49.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9906206130981445\n",
            "training loss: 7.026451110839844\n",
            "training loss: 7.146855354309082\n",
            "training loss: 6.990254878997803\n",
            "training loss: 6.966780662536621\n",
            "training loss: 7.027778625488281\n",
            "training loss: 6.999460220336914\n",
            "training loss: 7.191910743713379\n",
            "training loss: 7.075242042541504\n",
            "training loss: 6.862547874450684\n",
            "training loss: 7.276082992553711\n",
            "training loss: 6.942714691162109\n",
            "training loss: 7.097843170166016\n",
            "training loss: 6.84681510925293\n",
            "training loss: 6.92718505859375\n",
            "training loss: 6.731064796447754\n",
            "training loss: 6.4716925621032715\n",
            "training loss: 6.643617153167725\n",
            "training loss: 6.928088665008545\n",
            "training loss: 6.862536907196045\n",
            "training loss: 7.452305316925049\n",
            "training loss: 7.321821212768555\n",
            "training loss: 7.475286483764648\n",
            "training loss: 7.411986351013184\n",
            "training loss: 7.048314094543457\n",
            "training loss: 7.478038311004639\n",
            "training loss: 7.297924041748047\n",
            "training loss: 7.049490928649902\n",
            "training loss: 6.900642395019531\n",
            "training loss: 7.023004531860352\n",
            "training loss: 6.872135162353516\n",
            "training loss: 7.120832443237305\n",
            "training loss: 7.001086711883545\n",
            "training loss: 7.044693946838379\n",
            "training loss: 6.949334144592285\n",
            "training loss: 7.181216716766357\n",
            "training loss: 7.224157810211182\n",
            "training loss: 7.0381879806518555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   5%|▌         | 3/60 [02:28<46:54, 49.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.109241962432861\n",
            "training loss: 7.070193290710449\n",
            "training loss: 7.1363525390625\n",
            "training loss: 6.908449649810791\n",
            "training loss: 7.289672374725342\n",
            "training loss: 7.341770648956299\n",
            "training loss: 7.032464981079102\n",
            "training loss: 7.049753189086914\n",
            "training loss: 6.998105049133301\n",
            "training loss: 7.059197425842285\n",
            "training loss: 7.007688999176025\n",
            "training loss: 6.929804801940918\n",
            "training loss: 6.967682838439941\n",
            "training loss: 6.593266487121582\n",
            "training loss: 6.838030815124512\n",
            "training loss: 6.8510332107543945\n",
            "training loss: 6.8299455642700195\n",
            "training loss: 6.828195095062256\n",
            "training loss: 7.115710735321045\n",
            "training loss: 6.895305633544922\n",
            "training loss: 6.843275547027588\n",
            "training loss: 7.0016326904296875\n",
            "training loss: 7.223881721496582\n",
            "training loss: 7.017093658447266\n",
            "training loss: 6.964183807373047\n",
            "training loss: 6.800197601318359\n",
            "training loss: 7.064849853515625\n",
            "training loss: 7.1294989585876465\n",
            "training loss: 7.114921569824219\n",
            "training loss: 6.696352958679199\n",
            "training loss: 7.079744338989258\n",
            "training loss: 7.181493759155273\n",
            "training loss: 6.87096643447876\n",
            "training loss: 6.977892875671387\n",
            "training loss: 7.212502956390381\n",
            "training loss: 7.064195156097412\n",
            "training loss: 7.165597438812256\n",
            "training loss: 7.144184112548828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   7%|▋         | 4/60 [03:18<46:10, 49.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.322934150695801\n",
            "training loss: 7.415244102478027\n",
            "training loss: 7.278392314910889\n",
            "training loss: 7.065687656402588\n",
            "training loss: 7.057209491729736\n",
            "training loss: 7.413053512573242\n",
            "training loss: 7.357685089111328\n",
            "training loss: 7.261269569396973\n",
            "training loss: 6.92866325378418\n",
            "training loss: 6.908041000366211\n",
            "training loss: 6.865574359893799\n",
            "training loss: 6.8874311447143555\n",
            "training loss: 7.2014594078063965\n",
            "training loss: 7.093776702880859\n",
            "training loss: 7.167263984680176\n",
            "training loss: 7.0575127601623535\n",
            "training loss: 6.851633548736572\n",
            "training loss: 7.063299179077148\n",
            "training loss: 6.840075492858887\n",
            "training loss: 7.122763633728027\n",
            "training loss: 7.12399959564209\n",
            "training loss: 7.236718654632568\n",
            "training loss: 7.300741195678711\n",
            "training loss: 7.0871076583862305\n",
            "training loss: 7.107773780822754\n",
            "training loss: 7.130373001098633\n",
            "training loss: 7.038799285888672\n",
            "training loss: 7.061920166015625\n",
            "training loss: 7.089040756225586\n",
            "training loss: 6.982339382171631\n",
            "training loss: 7.036463737487793\n",
            "training loss: 7.058529376983643\n",
            "training loss: 7.255965232849121\n",
            "training loss: 7.145720958709717\n",
            "training loss: 7.117768287658691\n",
            "training loss: 7.035715103149414\n",
            "training loss: 6.975761890411377\n",
            "training loss: 7.040031433105469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   8%|▊         | 5/60 [04:07<45:00, 49.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.810443878173828\n",
            "training loss: 7.108639717102051\n",
            "training loss: 7.0182719230651855\n",
            "training loss: 7.055293083190918\n",
            "training loss: 6.931031227111816\n",
            "training loss: 6.873591899871826\n",
            "training loss: 7.048407077789307\n",
            "training loss: 6.75252628326416\n",
            "training loss: 6.814904689788818\n",
            "training loss: 6.970552444458008\n",
            "training loss: 6.926318168640137\n",
            "training loss: 6.711555480957031\n",
            "training loss: 7.168896675109863\n",
            "training loss: 7.163351058959961\n",
            "training loss: 7.062321662902832\n",
            "training loss: 6.943856239318848\n",
            "training loss: 6.937621593475342\n",
            "training loss: 6.795864105224609\n",
            "training loss: 6.66980504989624\n",
            "training loss: 7.166859149932861\n",
            "training loss: 6.988765239715576\n",
            "training loss: 6.866310119628906\n",
            "training loss: 6.907872676849365\n",
            "training loss: 6.920246124267578\n",
            "training loss: 6.853711128234863\n",
            "training loss: 6.704317569732666\n",
            "training loss: 6.647591590881348\n",
            "training loss: 6.7271833419799805\n",
            "training loss: 6.759303092956543\n",
            "training loss: 6.865297317504883\n",
            "training loss: 7.006211757659912\n",
            "training loss: 6.891654014587402\n",
            "training loss: 6.795483112335205\n",
            "training loss: 6.762030601501465\n",
            "training loss: 6.907487869262695\n",
            "training loss: 6.799588203430176\n",
            "training loss: 6.658941268920898\n",
            "training loss: 6.879425048828125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  10%|█         | 6/60 [04:56<44:21, 49.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.262648582458496\n",
            "training loss: 7.041282653808594\n",
            "training loss: 7.067651748657227\n",
            "training loss: 6.82335090637207\n",
            "training loss: 7.111412048339844\n",
            "training loss: 6.968506813049316\n",
            "training loss: 7.001039028167725\n",
            "training loss: 7.101322174072266\n",
            "training loss: 7.054462432861328\n",
            "training loss: 7.080019950866699\n",
            "training loss: 7.3019514083862305\n",
            "training loss: 6.940052509307861\n",
            "training loss: 7.032149314880371\n",
            "training loss: 7.001697540283203\n",
            "training loss: 6.900467872619629\n",
            "training loss: 7.18034553527832\n",
            "training loss: 6.938820838928223\n",
            "training loss: 6.868014335632324\n",
            "training loss: 6.956704139709473\n",
            "training loss: 6.952041149139404\n",
            "training loss: 7.015742301940918\n",
            "training loss: 6.697059631347656\n",
            "training loss: 6.921886444091797\n",
            "training loss: 6.893149375915527\n",
            "training loss: 6.80428409576416\n",
            "training loss: 6.934625148773193\n",
            "training loss: 7.095470905303955\n",
            "training loss: 6.747290134429932\n",
            "training loss: 7.132887363433838\n",
            "training loss: 6.697094917297363\n",
            "training loss: 6.704898834228516\n",
            "training loss: 6.728334426879883\n",
            "training loss: 7.030647277832031\n",
            "training loss: 6.648692607879639\n",
            "training loss: 6.961427688598633\n",
            "training loss: 6.981799602508545\n",
            "training loss: 6.671677112579346\n",
            "training loss: 6.684527397155762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  12%|█▏        | 7/60 [05:44<43:13, 48.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.771071910858154\n",
            "training loss: 7.2955474853515625\n",
            "training loss: 7.222583770751953\n",
            "training loss: 7.52918815612793\n",
            "training loss: 7.245716571807861\n",
            "training loss: 7.319980621337891\n",
            "training loss: 7.472220420837402\n",
            "training loss: 7.169389247894287\n",
            "training loss: 7.0077433586120605\n",
            "training loss: 7.068161964416504\n",
            "training loss: 7.162726879119873\n",
            "training loss: 6.949398994445801\n",
            "training loss: 6.815435886383057\n",
            "training loss: 6.9184956550598145\n",
            "training loss: 6.953845977783203\n",
            "training loss: 7.191094398498535\n",
            "training loss: 7.0734663009643555\n",
            "training loss: 7.070797920227051\n",
            "training loss: 7.174005508422852\n",
            "training loss: 7.153312683105469\n",
            "training loss: 7.0711164474487305\n",
            "training loss: 7.104732513427734\n",
            "training loss: 7.117058753967285\n",
            "training loss: 7.058466911315918\n",
            "training loss: 6.824893474578857\n",
            "training loss: 6.899224758148193\n",
            "training loss: 7.128532409667969\n",
            "training loss: 7.102836608886719\n",
            "training loss: 7.058256149291992\n",
            "training loss: 7.049081325531006\n",
            "training loss: 6.84993314743042\n",
            "training loss: 7.206216812133789\n",
            "training loss: 7.139708995819092\n",
            "training loss: 7.064413070678711\n",
            "training loss: 6.883571624755859\n",
            "training loss: 6.9638261795043945\n",
            "training loss: 6.988758087158203\n",
            "training loss: 6.863780975341797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  13%|█▎        | 8/60 [06:33<42:26, 48.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.000903129577637\n",
            "training loss: 7.064259052276611\n",
            "training loss: 7.073643684387207\n",
            "training loss: 7.187251567840576\n",
            "training loss: 7.154573917388916\n",
            "training loss: 7.124268054962158\n",
            "training loss: 7.3087968826293945\n",
            "training loss: 7.037642955780029\n",
            "training loss: 6.9504218101501465\n",
            "training loss: 6.9132466316223145\n",
            "training loss: 6.857938766479492\n",
            "training loss: 6.849874496459961\n",
            "training loss: 6.77778434753418\n",
            "training loss: 6.686775207519531\n",
            "training loss: 6.9322052001953125\n",
            "training loss: 7.13886833190918\n",
            "training loss: 7.09922981262207\n",
            "training loss: 7.153627395629883\n",
            "training loss: 7.051224231719971\n",
            "training loss: 6.8735432624816895\n",
            "training loss: 6.912947177886963\n",
            "training loss: 7.075006484985352\n",
            "training loss: 7.148387432098389\n",
            "training loss: 7.071749687194824\n",
            "training loss: 6.887119293212891\n",
            "training loss: 6.986344814300537\n",
            "training loss: 6.998478889465332\n",
            "training loss: 6.882955074310303\n",
            "training loss: 6.716732025146484\n",
            "training loss: 6.77117919921875\n",
            "training loss: 6.947610855102539\n",
            "training loss: 6.674765586853027\n",
            "training loss: 6.6368560791015625\n",
            "training loss: 7.086396217346191\n",
            "training loss: 6.86321496963501\n",
            "training loss: 6.894374370574951\n",
            "training loss: 6.763288497924805\n",
            "training loss: 6.798717498779297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  15%|█▌        | 9/60 [07:21<41:22, 48.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.075397968292236\n",
            "training loss: 6.920524597167969\n",
            "training loss: 6.926042556762695\n",
            "training loss: 7.12077522277832\n",
            "training loss: 7.172618389129639\n",
            "training loss: 7.049500942230225\n",
            "training loss: 7.030942440032959\n",
            "training loss: 7.138145446777344\n",
            "training loss: 7.175516605377197\n",
            "training loss: 7.117697238922119\n",
            "training loss: 6.749429702758789\n",
            "training loss: 7.048226356506348\n",
            "training loss: 7.07021951675415\n",
            "training loss: 6.921514987945557\n",
            "training loss: 7.113353729248047\n",
            "training loss: 6.893457412719727\n",
            "training loss: 6.669069290161133\n",
            "training loss: 6.948009967803955\n",
            "training loss: 6.960771560668945\n",
            "training loss: 6.866785049438477\n",
            "training loss: 6.9992170333862305\n",
            "training loss: 6.732640266418457\n",
            "training loss: 7.063683986663818\n",
            "training loss: 6.941990375518799\n",
            "training loss: 7.0075225830078125\n",
            "training loss: 6.732564926147461\n",
            "training loss: 6.759430885314941\n",
            "training loss: 6.908785343170166\n",
            "training loss: 6.743636131286621\n",
            "training loss: 6.690035820007324\n",
            "training loss: 6.726125717163086\n",
            "training loss: 6.756053924560547\n",
            "training loss: 6.746781349182129\n",
            "training loss: 6.743655681610107\n",
            "training loss: 6.808207035064697\n",
            "training loss: 6.8558454513549805\n",
            "training loss: 7.097275733947754\n",
            "training loss: 7.187115669250488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  17%|█▋        | 10/60 [08:09<40:13, 48.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.230137825012207\n",
            "training loss: 7.064519882202148\n",
            "training loss: 6.718769073486328\n",
            "training loss: 7.029154300689697\n",
            "training loss: 7.119596481323242\n",
            "training loss: 6.867517948150635\n",
            "training loss: 6.832711696624756\n",
            "training loss: 6.967658996582031\n",
            "training loss: 6.921635627746582\n",
            "training loss: 7.1094560623168945\n",
            "training loss: 7.209926128387451\n",
            "training loss: 6.841377258300781\n",
            "training loss: 6.866098880767822\n",
            "training loss: 6.731327056884766\n",
            "training loss: 6.957052230834961\n",
            "training loss: 6.8012285232543945\n",
            "training loss: 6.830808639526367\n",
            "training loss: 7.031590461730957\n",
            "training loss: 6.881283283233643\n",
            "training loss: 6.817628860473633\n",
            "training loss: 7.052781105041504\n",
            "training loss: 6.866764068603516\n",
            "training loss: 6.802099704742432\n",
            "training loss: 6.672262668609619\n",
            "training loss: 6.866495132446289\n",
            "training loss: 6.577477931976318\n",
            "training loss: 6.907961845397949\n",
            "training loss: 7.032273769378662\n",
            "training loss: 6.843753337860107\n",
            "training loss: 6.839540481567383\n",
            "training loss: 6.749897480010986\n",
            "training loss: 7.159095764160156\n",
            "training loss: 6.977198600769043\n",
            "training loss: 7.005888938903809\n",
            "training loss: 6.930690765380859\n",
            "training loss: 7.214968204498291\n",
            "training loss: 7.123769283294678\n",
            "training loss: 7.09260892868042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  18%|█▊        | 11/60 [08:57<39:31, 48.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.24040412902832\n",
            "training loss: 7.306875705718994\n",
            "training loss: 7.074036598205566\n",
            "training loss: 7.219069480895996\n",
            "training loss: 7.190285682678223\n",
            "training loss: 7.18059778213501\n",
            "training loss: 7.492527484893799\n",
            "training loss: 7.266474723815918\n",
            "training loss: 7.0160231590271\n",
            "training loss: 7.27805233001709\n",
            "training loss: 7.270439147949219\n",
            "training loss: 7.239776611328125\n",
            "training loss: 7.182964324951172\n",
            "training loss: 6.9838547706604\n",
            "training loss: 7.070502758026123\n",
            "training loss: 7.0742950439453125\n",
            "training loss: 6.946706771850586\n",
            "training loss: 6.965010643005371\n",
            "training loss: 6.930169105529785\n",
            "training loss: 6.696745872497559\n",
            "training loss: 6.86164665222168\n",
            "training loss: 6.864192008972168\n",
            "training loss: 6.641299247741699\n",
            "training loss: 6.595197677612305\n",
            "training loss: 6.893983840942383\n",
            "training loss: 6.618470191955566\n",
            "training loss: 7.348041534423828\n",
            "training loss: 7.156905174255371\n",
            "training loss: 6.724139213562012\n",
            "training loss: 7.02219820022583\n",
            "training loss: 6.947797775268555\n",
            "training loss: 6.965967178344727\n",
            "training loss: 7.008405685424805\n",
            "training loss: 6.764827251434326\n",
            "training loss: 6.611804008483887\n",
            "training loss: 7.185741424560547\n",
            "training loss: 7.0530595779418945\n",
            "training loss: 6.946558952331543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  20%|██        | 12/60 [09:45<38:24, 48.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.304492473602295\n",
            "training loss: 7.238525867462158\n",
            "training loss: 7.154236793518066\n",
            "training loss: 6.947082996368408\n",
            "training loss: 7.018682956695557\n",
            "training loss: 7.238213062286377\n",
            "training loss: 7.145196914672852\n",
            "training loss: 6.989382266998291\n",
            "training loss: 7.175547122955322\n",
            "training loss: 7.0333757400512695\n",
            "training loss: 7.123048782348633\n",
            "training loss: 6.891998291015625\n",
            "training loss: 7.150855541229248\n",
            "training loss: 7.29962158203125\n",
            "training loss: 7.000617027282715\n",
            "training loss: 7.062254905700684\n",
            "training loss: 6.550699234008789\n",
            "training loss: 6.891470432281494\n",
            "training loss: 6.959695816040039\n",
            "training loss: 6.766366004943848\n",
            "training loss: 7.140477657318115\n",
            "training loss: 6.856943607330322\n",
            "training loss: 7.065226078033447\n",
            "training loss: 6.941236972808838\n",
            "training loss: 7.062094688415527\n",
            "training loss: 6.674037456512451\n",
            "training loss: 6.704930305480957\n",
            "training loss: 7.026003837585449\n",
            "training loss: 6.8592329025268555\n",
            "training loss: 6.857410430908203\n",
            "training loss: 6.922891139984131\n",
            "training loss: 7.050182342529297\n",
            "training loss: 6.872647285461426\n",
            "training loss: 6.904345512390137\n",
            "training loss: 6.754133224487305\n",
            "training loss: 6.800775527954102\n",
            "training loss: 6.643393516540527\n",
            "training loss: 6.737836837768555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  22%|██▏       | 13/60 [10:32<37:26, 47.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.08975887298584\n",
            "training loss: 7.027223587036133\n",
            "training loss: 7.381901741027832\n",
            "training loss: 7.224781036376953\n",
            "training loss: 7.183868885040283\n",
            "training loss: 7.182218551635742\n",
            "training loss: 7.073811054229736\n",
            "training loss: 7.153075218200684\n",
            "training loss: 6.902737140655518\n",
            "training loss: 7.135931968688965\n",
            "training loss: 6.991635799407959\n",
            "training loss: 6.950160980224609\n",
            "training loss: 6.7218732833862305\n",
            "training loss: 7.008622169494629\n",
            "training loss: 7.167542457580566\n",
            "training loss: 6.995799541473389\n",
            "training loss: 6.940949440002441\n",
            "training loss: 6.796226501464844\n",
            "training loss: 6.756537437438965\n",
            "training loss: 6.795332431793213\n",
            "training loss: 7.0494232177734375\n",
            "training loss: 6.962704181671143\n",
            "training loss: 6.452136993408203\n",
            "training loss: 6.763962268829346\n",
            "training loss: 6.790451526641846\n",
            "training loss: 6.779642105102539\n",
            "training loss: 6.790924072265625\n",
            "training loss: 7.088669776916504\n",
            "training loss: 6.809047222137451\n",
            "training loss: 6.762341022491455\n",
            "training loss: 6.857822418212891\n",
            "training loss: 6.508805751800537\n",
            "training loss: 6.63379430770874\n",
            "training loss: 6.946521282196045\n",
            "training loss: 6.972460746765137\n",
            "training loss: 7.073346138000488\n",
            "training loss: 7.1080403327941895\n",
            "training loss: 6.9614458084106445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  23%|██▎       | 14/60 [11:20<36:41, 47.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.545365333557129\n",
            "training loss: 7.424524784088135\n",
            "training loss: 7.201003074645996\n",
            "training loss: 7.4091477394104\n",
            "training loss: 7.076572895050049\n",
            "training loss: 7.205522060394287\n",
            "training loss: 6.803767204284668\n",
            "training loss: 6.776440143585205\n",
            "training loss: 6.928178787231445\n",
            "training loss: 6.951293468475342\n",
            "training loss: 7.094696998596191\n",
            "training loss: 6.879530906677246\n",
            "training loss: 6.905740737915039\n",
            "training loss: 6.972078323364258\n",
            "training loss: 7.113502502441406\n",
            "training loss: 6.885915279388428\n",
            "training loss: 6.942845344543457\n",
            "training loss: 6.897015571594238\n",
            "training loss: 7.245604038238525\n",
            "training loss: 7.251811981201172\n",
            "training loss: 7.057809829711914\n",
            "training loss: 6.980555534362793\n",
            "training loss: 7.1463623046875\n",
            "training loss: 7.142452239990234\n",
            "training loss: 7.033670902252197\n",
            "training loss: 7.198680877685547\n",
            "training loss: 6.832568168640137\n",
            "training loss: 6.902317047119141\n",
            "training loss: 6.754634857177734\n",
            "training loss: 6.749269008636475\n",
            "training loss: 6.997711181640625\n",
            "training loss: 6.882535934448242\n",
            "training loss: 6.850974082946777\n",
            "training loss: 6.970034599304199\n",
            "training loss: 6.846069812774658\n",
            "training loss: 7.179044723510742\n",
            "training loss: 6.915931701660156\n",
            "training loss: 6.996160984039307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  25%|██▌       | 15/60 [12:07<35:45, 47.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.122646331787109\n",
            "training loss: 7.064802646636963\n",
            "training loss: 7.209256172180176\n",
            "training loss: 7.104331970214844\n",
            "training loss: 6.897312164306641\n",
            "training loss: 6.93569278717041\n",
            "training loss: 6.909670829772949\n",
            "training loss: 7.023224830627441\n",
            "training loss: 7.128190994262695\n",
            "training loss: 6.852392673492432\n",
            "training loss: 6.866985321044922\n",
            "training loss: 6.804422378540039\n",
            "training loss: 6.837881565093994\n",
            "training loss: 6.968487739562988\n",
            "training loss: 6.921451091766357\n",
            "training loss: 6.688485622406006\n",
            "training loss: 6.855710506439209\n",
            "training loss: 6.929577827453613\n",
            "training loss: 6.9998016357421875\n",
            "training loss: 6.964184284210205\n",
            "training loss: 7.067586898803711\n",
            "training loss: 7.118051528930664\n",
            "training loss: 7.061047554016113\n",
            "training loss: 7.03892707824707\n",
            "training loss: 7.124889373779297\n",
            "training loss: 6.991943359375\n",
            "training loss: 7.211013317108154\n",
            "training loss: 6.9811201095581055\n",
            "training loss: 7.089527606964111\n",
            "training loss: 7.247308254241943\n",
            "training loss: 7.017720699310303\n",
            "training loss: 6.953067779541016\n",
            "training loss: 6.877048492431641\n",
            "training loss: 6.7113542556762695\n",
            "training loss: 6.854820728302002\n",
            "training loss: 6.6686811447143555\n",
            "training loss: 6.62291145324707\n",
            "training loss: 6.929624557495117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  27%|██▋       | 16/60 [12:56<35:07, 47.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.045871734619141\n",
            "training loss: 7.430859088897705\n",
            "training loss: 7.0985107421875\n",
            "training loss: 7.074993133544922\n",
            "training loss: 6.910268306732178\n",
            "training loss: 6.937741279602051\n",
            "training loss: 7.099968910217285\n",
            "training loss: 7.2348175048828125\n",
            "training loss: 7.145283222198486\n",
            "training loss: 6.910305500030518\n",
            "training loss: 6.981571197509766\n",
            "training loss: 7.017414093017578\n",
            "training loss: 6.9801506996154785\n",
            "training loss: 6.97463321685791\n",
            "training loss: 6.795856475830078\n",
            "training loss: 6.830672264099121\n",
            "training loss: 7.109595775604248\n",
            "training loss: 7.1388258934021\n",
            "training loss: 7.1350908279418945\n",
            "training loss: 7.072203159332275\n",
            "training loss: 6.896696090698242\n",
            "training loss: 7.119533061981201\n",
            "training loss: 6.9666900634765625\n",
            "training loss: 7.251389503479004\n",
            "training loss: 6.927541255950928\n",
            "training loss: 6.861869812011719\n",
            "training loss: 7.001166343688965\n",
            "training loss: 7.000344753265381\n",
            "training loss: 6.842898845672607\n",
            "training loss: 6.962878227233887\n",
            "training loss: 6.959959030151367\n",
            "training loss: 7.061714172363281\n",
            "training loss: 6.922883033752441\n",
            "training loss: 7.050279140472412\n",
            "training loss: 7.134738445281982\n",
            "training loss: 6.7609357833862305\n",
            "training loss: 7.1289591789245605\n",
            "training loss: 7.090325355529785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  28%|██▊       | 17/60 [13:43<34:10, 47.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.185439109802246\n",
            "training loss: 7.266064167022705\n",
            "training loss: 7.040641784667969\n",
            "training loss: 7.030784606933594\n",
            "training loss: 6.769515037536621\n",
            "training loss: 7.356069564819336\n",
            "training loss: 7.109172821044922\n",
            "training loss: 7.206521511077881\n",
            "training loss: 7.3148698806762695\n",
            "training loss: 7.160266876220703\n",
            "training loss: 7.3102898597717285\n",
            "training loss: 7.271389961242676\n",
            "training loss: 7.053251266479492\n",
            "training loss: 7.0108466148376465\n",
            "training loss: 7.281918525695801\n",
            "training loss: 7.004618167877197\n",
            "training loss: 7.091376304626465\n",
            "training loss: 7.106114864349365\n",
            "training loss: 7.337224960327148\n",
            "training loss: 7.297098159790039\n",
            "training loss: 7.140293121337891\n",
            "training loss: 7.215016841888428\n",
            "training loss: 6.854220867156982\n",
            "training loss: 6.881306171417236\n",
            "training loss: 6.743771076202393\n",
            "training loss: 7.106794834136963\n",
            "training loss: 6.8655524253845215\n",
            "training loss: 7.058201789855957\n",
            "training loss: 6.882722854614258\n",
            "training loss: 7.072535037994385\n",
            "training loss: 7.006625175476074\n",
            "training loss: 7.059965133666992\n",
            "training loss: 6.982048034667969\n",
            "training loss: 6.914691925048828\n",
            "training loss: 6.8122663497924805\n",
            "training loss: 6.8648223876953125\n",
            "training loss: 6.8382744789123535\n",
            "training loss: 6.663257122039795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  30%|███       | 18/60 [14:30<33:15, 47.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.007823944091797\n",
            "training loss: 7.135669231414795\n",
            "training loss: 7.094788551330566\n",
            "training loss: 7.20832633972168\n",
            "training loss: 7.216762542724609\n",
            "training loss: 7.107847690582275\n",
            "training loss: 6.988589763641357\n",
            "training loss: 7.015876770019531\n",
            "training loss: 6.916971683502197\n",
            "training loss: 7.175167560577393\n",
            "training loss: 6.970077037811279\n",
            "training loss: 6.725649833679199\n",
            "training loss: 6.870434284210205\n",
            "training loss: 6.767319202423096\n",
            "training loss: 6.906573295593262\n",
            "training loss: 7.272455215454102\n",
            "training loss: 7.1711745262146\n",
            "training loss: 6.939663887023926\n",
            "training loss: 7.057732105255127\n",
            "training loss: 7.014840126037598\n",
            "training loss: 6.863285064697266\n",
            "training loss: 6.905322074890137\n",
            "training loss: 6.93633508682251\n",
            "training loss: 6.889156818389893\n",
            "training loss: 7.083928108215332\n",
            "training loss: 6.975345134735107\n",
            "training loss: 7.142160892486572\n",
            "training loss: 7.076015472412109\n",
            "training loss: 6.943964958190918\n",
            "training loss: 6.9606404304504395\n",
            "training loss: 6.7940673828125\n",
            "training loss: 6.809584617614746\n",
            "training loss: 7.040789604187012\n",
            "training loss: 6.858172416687012\n",
            "training loss: 7.014231204986572\n",
            "training loss: 6.924276351928711\n",
            "training loss: 6.633520603179932\n",
            "training loss: 6.486794948577881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  32%|███▏      | 19/60 [15:17<32:20, 47.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.09345006942749\n",
            "training loss: 6.945935249328613\n",
            "training loss: 6.898520469665527\n",
            "training loss: 6.7220001220703125\n",
            "training loss: 6.908364295959473\n",
            "training loss: 6.917787551879883\n",
            "training loss: 6.786769866943359\n",
            "training loss: 6.976836204528809\n",
            "training loss: 6.746310234069824\n",
            "training loss: 7.071653366088867\n",
            "training loss: 6.7838544845581055\n",
            "training loss: 6.933856964111328\n",
            "training loss: 6.925364017486572\n",
            "training loss: 6.755781173706055\n",
            "training loss: 6.876007080078125\n",
            "training loss: 7.182458877563477\n",
            "training loss: 6.755596160888672\n",
            "training loss: 6.827486038208008\n",
            "training loss: 6.963502883911133\n",
            "training loss: 6.941757678985596\n",
            "training loss: 7.0850749015808105\n",
            "training loss: 6.875609397888184\n",
            "training loss: 6.720388412475586\n",
            "training loss: 6.912792682647705\n",
            "training loss: 6.963059902191162\n",
            "training loss: 7.257494926452637\n",
            "training loss: 6.93858528137207\n",
            "training loss: 7.077330589294434\n",
            "training loss: 6.917977333068848\n",
            "training loss: 6.736053943634033\n",
            "training loss: 7.012261390686035\n",
            "training loss: 6.911217212677002\n",
            "training loss: 7.050742149353027\n",
            "training loss: 6.953701496124268\n",
            "training loss: 6.988027095794678\n",
            "training loss: 6.982911109924316\n",
            "training loss: 6.875494956970215\n",
            "training loss: 6.936592102050781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  33%|███▎      | 20/60 [16:05<31:38, 47.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.044610977172852\n",
            "training loss: 7.08576774597168\n",
            "training loss: 7.129075050354004\n",
            "training loss: 7.236520767211914\n",
            "training loss: 7.00089168548584\n",
            "training loss: 6.870294570922852\n",
            "training loss: 7.013314247131348\n",
            "training loss: 7.050967216491699\n",
            "training loss: 7.129295825958252\n",
            "training loss: 7.093515396118164\n",
            "training loss: 7.017709732055664\n",
            "training loss: 6.994524002075195\n",
            "training loss: 6.867870330810547\n",
            "training loss: 6.8559041023254395\n",
            "training loss: 6.955935478210449\n",
            "training loss: 6.9298553466796875\n",
            "training loss: 6.939152717590332\n",
            "training loss: 6.788957595825195\n",
            "training loss: 6.889503479003906\n",
            "training loss: 6.931272029876709\n",
            "training loss: 6.868544578552246\n",
            "training loss: 6.855445861816406\n",
            "training loss: 7.009722709655762\n",
            "training loss: 6.4885172843933105\n",
            "training loss: 7.005897521972656\n",
            "training loss: 6.8089728355407715\n",
            "training loss: 6.897121429443359\n",
            "training loss: 7.033730506896973\n",
            "training loss: 6.663948059082031\n",
            "training loss: 6.668326377868652\n",
            "training loss: 6.474987030029297\n",
            "training loss: 6.850376129150391\n",
            "training loss: 6.911097526550293\n",
            "training loss: 6.881687164306641\n",
            "training loss: 7.0965094566345215\n",
            "training loss: 6.604665756225586\n",
            "training loss: 6.734221458435059\n",
            "training loss: 6.911881446838379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  35%|███▌      | 21/60 [16:54<31:12, 48.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.943075180053711\n",
            "training loss: 7.175429344177246\n",
            "training loss: 6.929305076599121\n",
            "training loss: 6.79274845123291\n",
            "training loss: 6.8996663093566895\n",
            "training loss: 6.935577392578125\n",
            "training loss: 7.141239166259766\n",
            "training loss: 6.995506763458252\n",
            "training loss: 6.793820381164551\n",
            "training loss: 6.717080593109131\n",
            "training loss: 6.868960380554199\n",
            "training loss: 6.941637992858887\n",
            "training loss: 6.955841064453125\n",
            "training loss: 6.935091018676758\n",
            "training loss: 7.167248725891113\n",
            "training loss: 6.970861434936523\n",
            "training loss: 6.860062599182129\n",
            "training loss: 6.829629898071289\n",
            "training loss: 7.020259380340576\n",
            "training loss: 6.806070327758789\n",
            "training loss: 6.6892499923706055\n",
            "training loss: 6.928132057189941\n",
            "training loss: 6.800703048706055\n",
            "training loss: 6.937806606292725\n",
            "training loss: 6.860495567321777\n",
            "training loss: 6.820338249206543\n",
            "training loss: 6.975691795349121\n",
            "training loss: 6.86590051651001\n",
            "training loss: 6.8672027587890625\n",
            "training loss: 7.019772529602051\n",
            "training loss: 6.88133430480957\n",
            "training loss: 6.8678483963012695\n",
            "training loss: 6.875790596008301\n",
            "training loss: 6.7661848068237305\n",
            "training loss: 6.62827730178833\n",
            "training loss: 6.661747932434082\n",
            "training loss: 6.656746864318848\n",
            "training loss: 7.0179762840271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  37%|███▋      | 22/60 [17:41<30:12, 47.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.082673072814941\n",
            "training loss: 7.097709655761719\n",
            "training loss: 7.209717750549316\n",
            "training loss: 6.87437105178833\n",
            "training loss: 7.035257339477539\n",
            "training loss: 6.613175392150879\n",
            "training loss: 6.877250671386719\n",
            "training loss: 6.823714256286621\n",
            "training loss: 6.508543968200684\n",
            "training loss: 6.649189472198486\n",
            "training loss: 6.694273948669434\n",
            "training loss: 6.91766881942749\n",
            "training loss: 6.851504802703857\n",
            "training loss: 6.716306686401367\n",
            "training loss: 6.850964546203613\n",
            "training loss: 6.79958438873291\n",
            "training loss: 6.913846969604492\n",
            "training loss: 6.954568386077881\n",
            "training loss: 6.785345554351807\n",
            "training loss: 6.903846263885498\n",
            "training loss: 7.010893821716309\n",
            "training loss: 7.119379043579102\n",
            "training loss: 7.041883945465088\n",
            "training loss: 7.100779056549072\n",
            "training loss: 6.827782154083252\n",
            "training loss: 6.852653503417969\n",
            "training loss: 6.727470397949219\n",
            "training loss: 6.819990634918213\n",
            "training loss: 6.707907676696777\n",
            "training loss: 6.93015193939209\n",
            "training loss: 6.816218852996826\n",
            "training loss: 6.890688896179199\n",
            "training loss: 6.957949161529541\n",
            "training loss: 6.943037033081055\n",
            "training loss: 6.770069599151611\n",
            "training loss: 7.130986213684082\n",
            "training loss: 6.83113956451416\n",
            "training loss: 6.855111598968506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  38%|███▊      | 23/60 [18:28<29:16, 47.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.803039073944092\n",
            "training loss: 6.768294811248779\n",
            "training loss: 7.125774383544922\n",
            "training loss: 7.161231994628906\n",
            "training loss: 6.90407657623291\n",
            "training loss: 6.907392501831055\n",
            "training loss: 6.9218573570251465\n",
            "training loss: 7.0802717208862305\n",
            "training loss: 6.95979642868042\n",
            "training loss: 7.036605358123779\n",
            "training loss: 6.975214004516602\n",
            "training loss: 6.932747840881348\n",
            "training loss: 6.85504674911499\n",
            "training loss: 6.796523094177246\n",
            "training loss: 6.871755599975586\n",
            "training loss: 6.856759071350098\n",
            "training loss: 6.7620086669921875\n",
            "training loss: 6.5940399169921875\n",
            "training loss: 6.909263610839844\n",
            "training loss: 6.685678482055664\n",
            "training loss: 6.737546920776367\n",
            "training loss: 6.804328918457031\n",
            "training loss: 6.7083587646484375\n",
            "training loss: 6.95292854309082\n",
            "training loss: 6.901932716369629\n",
            "training loss: 6.671889781951904\n",
            "training loss: 6.761580467224121\n",
            "training loss: 6.817437171936035\n",
            "training loss: 6.736977577209473\n",
            "training loss: 6.899258136749268\n",
            "training loss: 6.71746826171875\n",
            "training loss: 6.9346923828125\n",
            "training loss: 7.098987579345703\n",
            "training loss: 6.587987899780273\n",
            "training loss: 6.550935745239258\n",
            "training loss: 6.501304626464844\n",
            "training loss: 6.805461406707764\n",
            "training loss: 7.011428356170654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  40%|████      | 24/60 [19:15<28:23, 47.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.087876319885254\n",
            "training loss: 7.1383466720581055\n",
            "training loss: 7.327585220336914\n",
            "training loss: 6.991351127624512\n",
            "training loss: 7.39893913269043\n",
            "training loss: 7.339613437652588\n",
            "training loss: 7.133642196655273\n",
            "training loss: 7.05699348449707\n",
            "training loss: 7.182405471801758\n",
            "training loss: 7.1011881828308105\n",
            "training loss: 6.9902024269104\n",
            "training loss: 6.864926338195801\n",
            "training loss: 6.711630821228027\n",
            "training loss: 6.839580535888672\n",
            "training loss: 7.024657249450684\n",
            "training loss: 6.894508361816406\n",
            "training loss: 6.8443756103515625\n",
            "training loss: 6.8517866134643555\n",
            "training loss: 6.856722831726074\n",
            "training loss: 6.911556243896484\n",
            "training loss: 7.036745071411133\n",
            "training loss: 7.08017635345459\n",
            "training loss: 7.091507911682129\n",
            "training loss: 7.144495964050293\n",
            "training loss: 6.848380088806152\n",
            "training loss: 7.136911392211914\n",
            "training loss: 7.010035991668701\n",
            "training loss: 7.1635236740112305\n",
            "training loss: 7.008459091186523\n",
            "training loss: 6.891030311584473\n",
            "training loss: 6.739185333251953\n",
            "training loss: 6.944647789001465\n",
            "training loss: 7.2768659591674805\n",
            "training loss: 6.406109809875488\n",
            "training loss: 6.957202911376953\n",
            "training loss: 7.164299964904785\n",
            "training loss: 7.053001880645752\n",
            "training loss: 7.160161018371582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  42%|████▏     | 25/60 [20:02<27:32, 47.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.2316460609436035\n",
            "training loss: 7.138207912445068\n",
            "training loss: 6.892511367797852\n",
            "training loss: 6.934518814086914\n",
            "training loss: 6.983022689819336\n",
            "training loss: 7.054511070251465\n",
            "training loss: 6.79029655456543\n",
            "training loss: 6.797455787658691\n",
            "training loss: 7.1326189041137695\n",
            "training loss: 6.986253261566162\n",
            "training loss: 6.807882308959961\n",
            "training loss: 6.957022666931152\n",
            "training loss: 7.042791366577148\n",
            "training loss: 6.90582799911499\n",
            "training loss: 6.902369499206543\n",
            "training loss: 7.101959705352783\n",
            "training loss: 6.894155025482178\n",
            "training loss: 6.775191307067871\n",
            "training loss: 7.036435127258301\n",
            "training loss: 6.893670082092285\n",
            "training loss: 7.1130499839782715\n",
            "training loss: 6.890063285827637\n",
            "training loss: 6.94811487197876\n",
            "training loss: 6.687531471252441\n",
            "training loss: 6.887749671936035\n",
            "training loss: 7.0511651039123535\n",
            "training loss: 6.795485019683838\n",
            "training loss: 7.00362491607666\n",
            "training loss: 6.919827461242676\n",
            "training loss: 6.955533981323242\n",
            "training loss: 6.851061820983887\n",
            "training loss: 6.868411064147949\n",
            "training loss: 6.926417827606201\n",
            "training loss: 6.692462921142578\n",
            "training loss: 7.0696916580200195\n",
            "training loss: 6.884428024291992\n",
            "training loss: 6.794817924499512\n",
            "training loss: 7.007328987121582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  43%|████▎     | 26/60 [20:50<26:59, 47.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.2179694175720215\n",
            "training loss: 7.396240234375\n",
            "training loss: 7.02992057800293\n",
            "training loss: 7.02139949798584\n",
            "training loss: 7.101118087768555\n",
            "training loss: 7.088369846343994\n",
            "training loss: 7.144396781921387\n",
            "training loss: 6.744434833526611\n",
            "training loss: 6.642955780029297\n",
            "training loss: 7.031176567077637\n",
            "training loss: 6.8831939697265625\n",
            "training loss: 6.877281188964844\n",
            "training loss: 6.5280256271362305\n",
            "training loss: 6.991168975830078\n",
            "training loss: 6.927309989929199\n",
            "training loss: 6.976519584655762\n",
            "training loss: 6.952475547790527\n",
            "training loss: 6.781957149505615\n",
            "training loss: 7.0582404136657715\n",
            "training loss: 6.72945499420166\n",
            "training loss: 7.004101753234863\n",
            "training loss: 6.788317680358887\n",
            "training loss: 7.019511699676514\n",
            "training loss: 6.853763103485107\n",
            "training loss: 7.159610748291016\n",
            "training loss: 7.370151042938232\n",
            "training loss: 7.374470233917236\n",
            "training loss: 6.978682994842529\n",
            "training loss: 7.0869293212890625\n",
            "training loss: 6.789218902587891\n",
            "training loss: 6.780047416687012\n",
            "training loss: 6.80659818649292\n",
            "training loss: 6.831211090087891\n",
            "training loss: 6.830842018127441\n",
            "training loss: 7.185288429260254\n",
            "training loss: 6.931870460510254\n",
            "training loss: 6.665002346038818\n",
            "training loss: 6.612850666046143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  45%|████▌     | 27/60 [21:37<26:03, 47.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.965227127075195\n",
            "training loss: 6.900527477264404\n",
            "training loss: 6.9301371574401855\n",
            "training loss: 6.753046989440918\n",
            "training loss: 6.825348377227783\n",
            "training loss: 6.99062442779541\n",
            "training loss: 6.805915832519531\n",
            "training loss: 6.746908664703369\n",
            "training loss: 6.736187934875488\n",
            "training loss: 7.048668384552002\n",
            "training loss: 6.998229503631592\n",
            "training loss: 6.79716682434082\n",
            "training loss: 6.973781585693359\n",
            "training loss: 6.989982604980469\n",
            "training loss: 6.8931965827941895\n",
            "training loss: 6.952475070953369\n",
            "training loss: 6.941239356994629\n",
            "training loss: 7.0139570236206055\n",
            "training loss: 6.704900741577148\n",
            "training loss: 6.688198089599609\n",
            "training loss: 6.947818756103516\n",
            "training loss: 6.990405082702637\n",
            "training loss: 7.034143924713135\n",
            "training loss: 7.070635795593262\n",
            "training loss: 7.156157493591309\n",
            "training loss: 6.740878105163574\n",
            "training loss: 6.480097770690918\n",
            "training loss: 6.681446552276611\n",
            "training loss: 6.918274879455566\n",
            "training loss: 7.0391845703125\n",
            "training loss: 7.076965808868408\n",
            "training loss: 7.14553165435791\n",
            "training loss: 7.144581317901611\n",
            "training loss: 6.924042701721191\n",
            "training loss: 7.3089165687561035\n",
            "training loss: 7.109167098999023\n",
            "training loss: 6.840184688568115\n",
            "training loss: 7.039542198181152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  47%|████▋     | 28/60 [22:25<25:24, 47.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.129179000854492\n",
            "training loss: 7.139087677001953\n",
            "training loss: 7.039451599121094\n",
            "training loss: 7.060919284820557\n",
            "training loss: 6.891603469848633\n",
            "training loss: 7.194663047790527\n",
            "training loss: 7.206171035766602\n",
            "training loss: 6.956959247589111\n",
            "training loss: 7.2037248611450195\n",
            "training loss: 7.070778846740723\n",
            "training loss: 7.015530109405518\n",
            "training loss: 6.994976043701172\n",
            "training loss: 7.063992500305176\n",
            "training loss: 7.12843132019043\n",
            "training loss: 7.275372505187988\n",
            "training loss: 7.220670223236084\n",
            "training loss: 6.914185523986816\n",
            "training loss: 6.99643087387085\n",
            "training loss: 6.785114288330078\n",
            "training loss: 6.783959865570068\n",
            "training loss: 6.993102073669434\n",
            "training loss: 7.039658069610596\n",
            "training loss: 7.074371337890625\n",
            "training loss: 6.82160758972168\n",
            "training loss: 7.043567657470703\n",
            "training loss: 7.212837219238281\n",
            "training loss: 7.125291347503662\n",
            "training loss: 6.568496227264404\n",
            "training loss: 6.668734550476074\n",
            "training loss: 6.938745021820068\n",
            "training loss: 7.020811080932617\n",
            "training loss: 7.0510735511779785\n",
            "training loss: 6.877715110778809\n",
            "training loss: 6.815185546875\n",
            "training loss: 6.745055675506592\n",
            "training loss: 6.898972511291504\n",
            "training loss: 6.782884120941162\n",
            "training loss: 6.894969940185547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  48%|████▊     | 29/60 [23:12<24:31, 47.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.939653396606445\n",
            "training loss: 6.800482749938965\n",
            "training loss: 7.263104438781738\n",
            "training loss: 6.968637466430664\n",
            "training loss: 6.930591583251953\n",
            "training loss: 6.894779682159424\n",
            "training loss: 6.848330497741699\n",
            "training loss: 6.835013389587402\n",
            "training loss: 6.960121154785156\n",
            "training loss: 6.943467140197754\n",
            "training loss: 6.9719624519348145\n",
            "training loss: 7.1702446937561035\n",
            "training loss: 6.657093524932861\n",
            "training loss: 6.669829368591309\n",
            "training loss: 6.9007344245910645\n",
            "training loss: 6.802483558654785\n",
            "training loss: 6.721473693847656\n",
            "training loss: 6.580402851104736\n",
            "training loss: 6.452844142913818\n",
            "training loss: 6.796067714691162\n",
            "training loss: 7.06516695022583\n",
            "training loss: 7.082635402679443\n",
            "training loss: 7.072545528411865\n",
            "training loss: 6.7740373611450195\n",
            "training loss: 6.91062068939209\n",
            "training loss: 6.713705062866211\n",
            "training loss: 6.79578971862793\n",
            "training loss: 6.935981273651123\n",
            "training loss: 6.861575126647949\n",
            "training loss: 6.64073371887207\n",
            "training loss: 6.8593950271606445\n",
            "training loss: 6.974700927734375\n",
            "training loss: 6.781460285186768\n",
            "training loss: 6.901063442230225\n",
            "training loss: 6.705766677856445\n",
            "training loss: 6.647021293640137\n",
            "training loss: 6.6554484367370605\n",
            "training loss: 6.80342960357666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  50%|█████     | 30/60 [23:59<23:38, 47.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.911437034606934\n",
            "training loss: 7.030150890350342\n",
            "training loss: 6.771056652069092\n",
            "training loss: 6.892135143280029\n",
            "training loss: 7.004648685455322\n",
            "training loss: 6.855734825134277\n",
            "training loss: 6.846464157104492\n",
            "training loss: 6.886404514312744\n",
            "training loss: 6.898322105407715\n",
            "training loss: 7.021246910095215\n",
            "training loss: 7.037132263183594\n",
            "training loss: 6.938407897949219\n",
            "training loss: 7.028575897216797\n",
            "training loss: 6.839854717254639\n",
            "training loss: 6.826992034912109\n",
            "training loss: 6.743281841278076\n",
            "training loss: 6.8184661865234375\n",
            "training loss: 6.965758323669434\n",
            "training loss: 6.955080986022949\n",
            "training loss: 6.776658058166504\n",
            "training loss: 6.888094425201416\n",
            "training loss: 6.913890361785889\n",
            "training loss: 6.8040876388549805\n",
            "training loss: 6.693373680114746\n",
            "training loss: 6.78123664855957\n",
            "training loss: 6.6661272048950195\n",
            "training loss: 6.9418487548828125\n",
            "training loss: 6.940842628479004\n",
            "training loss: 6.811548709869385\n",
            "training loss: 6.662556171417236\n",
            "training loss: 6.857016086578369\n",
            "training loss: 6.898188591003418\n",
            "training loss: 6.928766250610352\n",
            "training loss: 6.902095794677734\n",
            "training loss: 6.986719131469727\n",
            "training loss: 6.836582183837891\n",
            "training loss: 6.828117370605469\n",
            "training loss: 6.655287265777588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  52%|█████▏    | 31/60 [24:48<23:00, 47.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.057051658630371\n",
            "training loss: 7.0459418296813965\n",
            "training loss: 7.220217227935791\n",
            "training loss: 7.034786224365234\n",
            "training loss: 7.1463799476623535\n",
            "training loss: 6.806656837463379\n",
            "training loss: 6.728638648986816\n",
            "training loss: 6.59401798248291\n",
            "training loss: 6.752004146575928\n",
            "training loss: 6.716677188873291\n",
            "training loss: 7.0311174392700195\n",
            "training loss: 6.797603130340576\n",
            "training loss: 6.832526206970215\n",
            "training loss: 6.803200721740723\n",
            "training loss: 6.711528778076172\n",
            "training loss: 6.648744583129883\n",
            "training loss: 6.718658924102783\n",
            "training loss: 6.542900562286377\n",
            "training loss: 6.6934075355529785\n",
            "training loss: 6.743828773498535\n",
            "training loss: 6.907183647155762\n",
            "training loss: 6.648139953613281\n",
            "training loss: 6.610965728759766\n",
            "training loss: 6.899764537811279\n",
            "training loss: 6.845513343811035\n",
            "training loss: 7.138115882873535\n",
            "training loss: 6.851792335510254\n",
            "training loss: 6.970749855041504\n",
            "training loss: 7.032508373260498\n",
            "training loss: 6.971030235290527\n",
            "training loss: 7.0877814292907715\n",
            "training loss: 7.167874813079834\n",
            "training loss: 7.210820198059082\n",
            "training loss: 6.872170925140381\n",
            "training loss: 7.388933181762695\n",
            "training loss: 6.615480422973633\n",
            "training loss: 6.8738508224487305\n",
            "training loss: 6.991692066192627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  53%|█████▎    | 32/60 [25:34<22:06, 47.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.162792205810547\n",
            "training loss: 6.986173152923584\n",
            "training loss: 6.770320892333984\n",
            "training loss: 7.231131553649902\n",
            "training loss: 7.015872955322266\n",
            "training loss: 6.936838150024414\n",
            "training loss: 7.054195404052734\n",
            "training loss: 6.689529895782471\n",
            "training loss: 6.885644435882568\n",
            "training loss: 6.840997695922852\n",
            "training loss: 6.95163631439209\n",
            "training loss: 6.944974899291992\n",
            "training loss: 6.8585309982299805\n",
            "training loss: 6.851955413818359\n",
            "training loss: 6.883884429931641\n",
            "training loss: 7.11644172668457\n",
            "training loss: 6.686811447143555\n",
            "training loss: 6.816599369049072\n",
            "training loss: 7.195029258728027\n",
            "training loss: 7.029970169067383\n",
            "training loss: 7.0446906089782715\n",
            "training loss: 6.85609245300293\n",
            "training loss: 6.89650821685791\n",
            "training loss: 6.921353816986084\n",
            "training loss: 6.650400638580322\n",
            "training loss: 6.836680889129639\n",
            "training loss: 6.636008262634277\n",
            "training loss: 6.819230079650879\n",
            "training loss: 7.005913734436035\n",
            "training loss: 6.559547424316406\n",
            "training loss: 7.0709228515625\n",
            "training loss: 6.788415908813477\n",
            "training loss: 7.111790657043457\n",
            "training loss: 7.163687705993652\n",
            "training loss: 6.946046829223633\n",
            "training loss: 6.8624653816223145\n",
            "training loss: 6.913829803466797\n",
            "training loss: 6.674643516540527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  55%|█████▌    | 33/60 [26:21<21:14, 47.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.765023708343506\n",
            "training loss: 7.106010437011719\n",
            "training loss: 7.006326198577881\n",
            "training loss: 7.056040287017822\n",
            "training loss: 7.143185615539551\n",
            "training loss: 6.8852105140686035\n",
            "training loss: 6.9188032150268555\n",
            "training loss: 6.96373176574707\n",
            "training loss: 7.129192352294922\n",
            "training loss: 7.176520824432373\n",
            "training loss: 7.134285926818848\n",
            "training loss: 6.8400444984436035\n",
            "training loss: 6.839982032775879\n",
            "training loss: 7.005307197570801\n",
            "training loss: 6.627670764923096\n",
            "training loss: 6.870255470275879\n",
            "training loss: 6.902285575866699\n",
            "training loss: 6.741090774536133\n",
            "training loss: 6.832819938659668\n",
            "training loss: 6.819424629211426\n",
            "training loss: 6.878265380859375\n",
            "training loss: 6.809684753417969\n",
            "training loss: 7.076840877532959\n",
            "training loss: 6.776242256164551\n",
            "training loss: 6.8592047691345215\n",
            "training loss: 7.0314226150512695\n",
            "training loss: 6.881424903869629\n",
            "training loss: 6.647679328918457\n",
            "training loss: 6.853827953338623\n",
            "training loss: 6.95088005065918\n",
            "training loss: 6.816159248352051\n",
            "training loss: 6.938108444213867\n",
            "training loss: 6.831453323364258\n",
            "training loss: 6.683581352233887\n",
            "training loss: 6.915658950805664\n",
            "training loss: 6.828772068023682\n",
            "training loss: 6.525973320007324\n",
            "training loss: 6.702030181884766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  57%|█████▋    | 34/60 [27:08<20:23, 47.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.939235687255859\n",
            "training loss: 7.025730609893799\n",
            "training loss: 7.122486114501953\n",
            "training loss: 6.917442321777344\n",
            "training loss: 6.9581990242004395\n",
            "training loss: 7.035899639129639\n",
            "training loss: 6.973599433898926\n",
            "training loss: 6.88787841796875\n",
            "training loss: 6.9916558265686035\n",
            "training loss: 6.929422378540039\n",
            "training loss: 6.850088596343994\n",
            "training loss: 6.695053577423096\n",
            "training loss: 7.026073932647705\n",
            "training loss: 7.195613861083984\n",
            "training loss: 7.05546760559082\n",
            "training loss: 7.10171365737915\n",
            "training loss: 7.094359397888184\n",
            "training loss: 7.0539045333862305\n",
            "training loss: 7.139869689941406\n",
            "training loss: 6.924770355224609\n",
            "training loss: 6.795651435852051\n",
            "training loss: 6.9344353675842285\n",
            "training loss: 7.17170524597168\n",
            "training loss: 6.95091438293457\n",
            "training loss: 7.110374450683594\n",
            "training loss: 6.801375865936279\n",
            "training loss: 6.883772850036621\n",
            "training loss: 6.7525434494018555\n",
            "training loss: 6.770426273345947\n",
            "training loss: 7.069570064544678\n",
            "training loss: 6.927504539489746\n",
            "training loss: 7.031190872192383\n",
            "training loss: 6.94881534576416\n",
            "training loss: 6.981378078460693\n",
            "training loss: 7.011295318603516\n",
            "training loss: 6.982277870178223\n",
            "training loss: 6.7979350090026855\n",
            "training loss: 6.699742317199707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  58%|█████▊    | 35/60 [27:55<19:34, 46.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.195051193237305\n",
            "training loss: 7.119441986083984\n",
            "training loss: 7.223029136657715\n",
            "training loss: 6.982684135437012\n",
            "training loss: 7.097151756286621\n",
            "training loss: 6.9533491134643555\n",
            "training loss: 7.102384567260742\n",
            "training loss: 7.002664566040039\n",
            "training loss: 6.900954246520996\n",
            "training loss: 6.985022068023682\n",
            "training loss: 7.028557777404785\n",
            "training loss: 7.002326011657715\n",
            "training loss: 6.752978324890137\n",
            "training loss: 7.019844055175781\n",
            "training loss: 6.855802536010742\n",
            "training loss: 6.8915886878967285\n",
            "training loss: 6.694066047668457\n",
            "training loss: 6.61279296875\n",
            "training loss: 6.7600860595703125\n",
            "training loss: 6.437418460845947\n",
            "training loss: 6.957208633422852\n",
            "training loss: 6.925742149353027\n",
            "training loss: 6.912822723388672\n",
            "training loss: 6.812590599060059\n",
            "training loss: 7.0087738037109375\n",
            "training loss: 6.839386940002441\n",
            "training loss: 6.9817633628845215\n",
            "training loss: 6.777704238891602\n",
            "training loss: 6.7266058921813965\n",
            "training loss: 6.703448295593262\n",
            "training loss: 6.809908866882324\n",
            "training loss: 6.737016677856445\n",
            "training loss: 6.750387668609619\n",
            "training loss: 6.874202728271484\n",
            "training loss: 6.901722431182861\n",
            "training loss: 6.904731750488281\n",
            "training loss: 7.060299396514893\n",
            "training loss: 6.750579357147217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  60%|██████    | 36/60 [28:44<19:03, 47.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.5372724533081055\n",
            "training loss: 6.617059707641602\n",
            "training loss: 6.803834915161133\n",
            "training loss: 6.568861961364746\n",
            "training loss: 6.726504325866699\n",
            "training loss: 6.802397727966309\n",
            "training loss: 6.781680107116699\n",
            "training loss: 7.081777572631836\n",
            "training loss: 6.9409637451171875\n",
            "training loss: 6.785445213317871\n",
            "training loss: 6.699090957641602\n",
            "training loss: 6.905245780944824\n",
            "training loss: 6.982334136962891\n",
            "training loss: 6.980691909790039\n",
            "training loss: 6.631671905517578\n",
            "training loss: 6.740388870239258\n",
            "training loss: 6.7294158935546875\n",
            "training loss: 7.102396011352539\n",
            "training loss: 7.090000629425049\n",
            "training loss: 6.594762325286865\n",
            "training loss: 6.666629314422607\n",
            "training loss: 6.80108642578125\n",
            "training loss: 6.913800239562988\n",
            "training loss: 6.822276592254639\n",
            "training loss: 6.888678550720215\n",
            "training loss: 6.795210361480713\n",
            "training loss: 6.642030239105225\n",
            "training loss: 6.623149394989014\n",
            "training loss: 6.9321417808532715\n",
            "training loss: 6.93000602722168\n",
            "training loss: 7.000388145446777\n",
            "training loss: 7.1154632568359375\n",
            "training loss: 6.735411167144775\n",
            "training loss: 6.98571252822876\n",
            "training loss: 6.898861408233643\n",
            "training loss: 6.829202651977539\n",
            "training loss: 6.771799087524414\n",
            "training loss: 6.701540470123291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  62%|██████▏   | 37/60 [29:31<18:09, 47.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.744999885559082\n",
            "training loss: 7.027604103088379\n",
            "training loss: 7.1731157302856445\n",
            "training loss: 6.932669639587402\n",
            "training loss: 6.941332817077637\n",
            "training loss: 7.106497764587402\n",
            "training loss: 7.062186241149902\n",
            "training loss: 6.811863899230957\n",
            "training loss: 6.851468086242676\n",
            "training loss: 7.037649631500244\n",
            "training loss: 6.7691473960876465\n",
            "training loss: 6.72569465637207\n",
            "training loss: 6.783405303955078\n",
            "training loss: 6.785971641540527\n",
            "training loss: 7.036532878875732\n",
            "training loss: 6.700486183166504\n",
            "training loss: 6.906060218811035\n",
            "training loss: 6.789080619812012\n",
            "training loss: 6.70167350769043\n",
            "training loss: 6.75647497177124\n",
            "training loss: 6.640263080596924\n",
            "training loss: 7.018448829650879\n",
            "training loss: 6.647032737731934\n",
            "training loss: 6.667841911315918\n",
            "training loss: 6.740445137023926\n",
            "training loss: 6.55739688873291\n",
            "training loss: 6.619025707244873\n",
            "training loss: 6.709787845611572\n",
            "training loss: 6.748706817626953\n",
            "training loss: 6.811784744262695\n",
            "training loss: 6.843876838684082\n",
            "training loss: 6.694220542907715\n",
            "training loss: 7.025396823883057\n",
            "training loss: 7.0226263999938965\n",
            "training loss: 6.977007865905762\n",
            "training loss: 6.791756629943848\n",
            "training loss: 6.938799858093262\n",
            "training loss: 6.962267875671387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  63%|██████▎   | 38/60 [30:17<17:18, 47.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.885542869567871\n",
            "training loss: 6.8420610427856445\n",
            "training loss: 7.092815399169922\n",
            "training loss: 7.191490173339844\n",
            "training loss: 6.888239860534668\n",
            "training loss: 6.9079999923706055\n",
            "training loss: 6.590791702270508\n",
            "training loss: 6.942081451416016\n",
            "training loss: 7.044740200042725\n",
            "training loss: 6.89531135559082\n",
            "training loss: 7.245142936706543\n",
            "training loss: 7.116280555725098\n",
            "training loss: 6.79548978805542\n",
            "training loss: 6.830904006958008\n",
            "training loss: 6.754700183868408\n",
            "training loss: 6.9031524658203125\n",
            "training loss: 6.826849937438965\n",
            "training loss: 6.688868045806885\n",
            "training loss: 7.03681755065918\n",
            "training loss: 6.95989990234375\n",
            "training loss: 6.9580864906311035\n",
            "training loss: 6.665530204772949\n",
            "training loss: 6.862471580505371\n",
            "training loss: 6.6854095458984375\n",
            "training loss: 6.818878173828125\n",
            "training loss: 6.767577171325684\n",
            "training loss: 6.464282989501953\n",
            "training loss: 6.985433578491211\n",
            "training loss: 7.167311668395996\n",
            "training loss: 6.99281120300293\n",
            "training loss: 6.949507236480713\n",
            "training loss: 6.849726676940918\n",
            "training loss: 6.858219146728516\n",
            "training loss: 6.8269853591918945\n",
            "training loss: 6.902216911315918\n",
            "training loss: 6.974681854248047\n",
            "training loss: 7.050512790679932\n",
            "training loss: 6.932868003845215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  65%|██████▌   | 39/60 [31:04<16:25, 46.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.949617385864258\n",
            "training loss: 6.996194839477539\n",
            "training loss: 6.522735118865967\n",
            "training loss: 6.728925704956055\n",
            "training loss: 6.952461242675781\n",
            "training loss: 7.075918197631836\n",
            "training loss: 7.220847129821777\n",
            "training loss: 6.630680084228516\n",
            "training loss: 6.929985046386719\n",
            "training loss: 6.9112348556518555\n",
            "training loss: 6.692814826965332\n",
            "training loss: 6.932795524597168\n",
            "training loss: 6.994918346405029\n",
            "training loss: 6.99269962310791\n",
            "training loss: 7.0601043701171875\n",
            "training loss: 7.023395538330078\n",
            "training loss: 6.829675674438477\n",
            "training loss: 6.72871208190918\n",
            "training loss: 6.675998687744141\n",
            "training loss: 6.972180366516113\n",
            "training loss: 6.905900955200195\n",
            "training loss: 6.930959701538086\n",
            "training loss: 6.965460777282715\n",
            "training loss: 7.117254257202148\n",
            "training loss: 6.963112831115723\n",
            "training loss: 7.151159286499023\n",
            "training loss: 6.864807605743408\n",
            "training loss: 7.108503341674805\n",
            "training loss: 7.133149147033691\n",
            "training loss: 6.955392360687256\n",
            "training loss: 6.968347072601318\n",
            "training loss: 7.072113037109375\n",
            "training loss: 7.112902641296387\n",
            "training loss: 6.831111907958984\n",
            "training loss: 6.950137138366699\n",
            "training loss: 6.935911178588867\n",
            "training loss: 6.702876091003418\n",
            "training loss: 6.850423812866211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  67%|██████▋   | 40/60 [31:50<15:35, 46.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.016994476318359\n",
            "training loss: 7.105792999267578\n",
            "training loss: 7.010734558105469\n",
            "training loss: 6.756245136260986\n",
            "training loss: 6.821376800537109\n",
            "training loss: 6.942885398864746\n",
            "training loss: 7.184420585632324\n",
            "training loss: 7.078049659729004\n",
            "training loss: 6.917266368865967\n",
            "training loss: 6.849886894226074\n",
            "training loss: 6.924863815307617\n",
            "training loss: 7.055963039398193\n",
            "training loss: 6.879768371582031\n",
            "training loss: 6.82974100112915\n",
            "training loss: 7.055554389953613\n",
            "training loss: 6.987504005432129\n",
            "training loss: 6.969655990600586\n",
            "training loss: 6.957233428955078\n",
            "training loss: 6.793335437774658\n",
            "training loss: 6.817890167236328\n",
            "training loss: 6.829110145568848\n",
            "training loss: 6.838620662689209\n",
            "training loss: 6.712605953216553\n",
            "training loss: 6.83212947845459\n",
            "training loss: 6.807336330413818\n",
            "training loss: 6.7128448486328125\n",
            "training loss: 6.785102367401123\n",
            "training loss: 6.776209831237793\n",
            "training loss: 6.823960304260254\n",
            "training loss: 6.881344318389893\n",
            "training loss: 6.74636697769165\n",
            "training loss: 6.517487049102783\n",
            "training loss: 6.717811107635498\n",
            "training loss: 6.901185989379883\n",
            "training loss: 6.8228254318237305\n",
            "training loss: 6.966131687164307\n",
            "training loss: 6.831700325012207\n",
            "training loss: 6.7832489013671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  68%|██████▊   | 41/60 [32:38<14:56, 47.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.784204483032227\n",
            "training loss: 6.77229118347168\n",
            "training loss: 6.997138977050781\n",
            "training loss: 6.879436492919922\n",
            "training loss: 6.91840934753418\n",
            "training loss: 6.842865467071533\n",
            "training loss: 6.85136604309082\n",
            "training loss: 6.683610916137695\n",
            "training loss: 6.8002448081970215\n",
            "training loss: 6.782914161682129\n",
            "training loss: 6.8620452880859375\n",
            "training loss: 7.265918254852295\n",
            "training loss: 7.048409938812256\n",
            "training loss: 7.226994514465332\n",
            "training loss: 7.303220748901367\n",
            "training loss: 7.051856994628906\n",
            "training loss: 7.069610595703125\n",
            "training loss: 7.14021110534668\n",
            "training loss: 7.0058698654174805\n",
            "training loss: 6.619476795196533\n",
            "training loss: 6.929812431335449\n",
            "training loss: 6.754768371582031\n",
            "training loss: 6.878021240234375\n",
            "training loss: 7.083944797515869\n",
            "training loss: 6.9153900146484375\n",
            "training loss: 6.790835857391357\n",
            "training loss: 6.733865737915039\n",
            "training loss: 6.770452976226807\n",
            "training loss: 6.809189796447754\n",
            "training loss: 6.7771806716918945\n",
            "training loss: 6.662527561187744\n",
            "training loss: 6.755088806152344\n",
            "training loss: 6.852532386779785\n",
            "training loss: 7.101966381072998\n",
            "training loss: 6.940999984741211\n",
            "training loss: 6.906552314758301\n",
            "training loss: 6.791749954223633\n",
            "training loss: 6.798192977905273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  70%|███████   | 42/60 [33:25<14:04, 46.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.048881530761719\n",
            "training loss: 7.014833450317383\n",
            "training loss: 6.886065483093262\n",
            "training loss: 6.955660820007324\n",
            "training loss: 7.011886119842529\n",
            "training loss: 7.019671440124512\n",
            "training loss: 7.114782333374023\n",
            "training loss: 7.075275421142578\n",
            "training loss: 6.993049621582031\n",
            "training loss: 6.955813884735107\n",
            "training loss: 7.000616073608398\n",
            "training loss: 6.923170566558838\n",
            "training loss: 6.965494632720947\n",
            "training loss: 7.004980087280273\n",
            "training loss: 6.954856872558594\n",
            "training loss: 6.741189002990723\n",
            "training loss: 6.858170509338379\n",
            "training loss: 7.005841255187988\n",
            "training loss: 6.89693021774292\n",
            "training loss: 6.710843086242676\n",
            "training loss: 6.708702087402344\n",
            "training loss: 6.822697639465332\n",
            "training loss: 6.560504913330078\n",
            "training loss: 6.829920768737793\n",
            "training loss: 7.023454189300537\n",
            "training loss: 6.8647284507751465\n",
            "training loss: 6.667086601257324\n",
            "training loss: 6.742486953735352\n",
            "training loss: 6.972842216491699\n",
            "training loss: 6.776329040527344\n",
            "training loss: 6.861788272857666\n",
            "training loss: 6.837451934814453\n",
            "training loss: 6.962019443511963\n",
            "training loss: 7.060785293579102\n",
            "training loss: 6.863323211669922\n",
            "training loss: 6.864095687866211\n",
            "training loss: 6.924415111541748\n",
            "training loss: 6.570897102355957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  72%|███████▏  | 43/60 [34:11<13:15, 46.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.866785049438477\n",
            "training loss: 6.790627479553223\n",
            "training loss: 7.039370536804199\n",
            "training loss: 7.08102560043335\n",
            "training loss: 6.84221887588501\n",
            "training loss: 7.074357986450195\n",
            "training loss: 6.677927494049072\n",
            "training loss: 6.800473213195801\n",
            "training loss: 6.911787986755371\n",
            "training loss: 6.961735248565674\n",
            "training loss: 6.950423240661621\n",
            "training loss: 6.869710922241211\n",
            "training loss: 6.892805576324463\n",
            "training loss: 6.883444786071777\n",
            "training loss: 6.903896808624268\n",
            "training loss: 6.796429634094238\n",
            "training loss: 6.809087753295898\n",
            "training loss: 7.003806114196777\n",
            "training loss: 7.06839656829834\n",
            "training loss: 6.7985992431640625\n",
            "training loss: 6.9676008224487305\n",
            "training loss: 6.831547737121582\n",
            "training loss: 6.686260223388672\n",
            "training loss: 7.050132751464844\n",
            "training loss: 6.764769077301025\n",
            "training loss: 6.8221635818481445\n",
            "training loss: 6.728729248046875\n",
            "training loss: 6.878485202789307\n",
            "training loss: 6.51945686340332\n",
            "training loss: 6.954678535461426\n",
            "training loss: 6.684016227722168\n",
            "training loss: 6.630708694458008\n",
            "training loss: 6.953495979309082\n",
            "training loss: 6.806173324584961\n",
            "training loss: 7.051365852355957\n",
            "training loss: 7.066649436950684\n",
            "training loss: 7.079371452331543\n",
            "training loss: 7.02838659286499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  73%|███████▎  | 44/60 [34:58<12:29, 46.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.809747695922852\n",
            "training loss: 6.672330856323242\n",
            "training loss: 7.075543403625488\n",
            "training loss: 6.938016414642334\n",
            "training loss: 6.8726959228515625\n",
            "training loss: 7.085998058319092\n",
            "training loss: 7.130146026611328\n",
            "training loss: 6.947591781616211\n",
            "training loss: 7.046282768249512\n",
            "training loss: 6.767531394958496\n",
            "training loss: 6.898624897003174\n",
            "training loss: 6.916271209716797\n",
            "training loss: 6.89354944229126\n",
            "training loss: 6.668524742126465\n",
            "training loss: 6.887712001800537\n",
            "training loss: 7.04660701751709\n",
            "training loss: 6.927385330200195\n",
            "training loss: 7.048322677612305\n",
            "training loss: 6.669089317321777\n",
            "training loss: 6.844972610473633\n",
            "training loss: 6.881242275238037\n",
            "training loss: 7.065140724182129\n",
            "training loss: 7.07291841506958\n",
            "training loss: 6.875895977020264\n",
            "training loss: 6.8120880126953125\n",
            "training loss: 6.8656005859375\n",
            "training loss: 6.790254592895508\n",
            "training loss: 6.931221008300781\n",
            "training loss: 6.852704048156738\n",
            "training loss: 6.795133590698242\n",
            "training loss: 6.8038201332092285\n",
            "training loss: 6.668569564819336\n",
            "training loss: 6.98576021194458\n",
            "training loss: 7.094644546508789\n",
            "training loss: 6.773178577423096\n",
            "training loss: 6.757974624633789\n",
            "training loss: 6.745198726654053\n",
            "training loss: 6.754471302032471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  75%|███████▌  | 45/60 [35:45<11:43, 46.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.899338722229004\n",
            "training loss: 6.960959434509277\n",
            "training loss: 6.969559669494629\n",
            "training loss: 7.081690788269043\n",
            "training loss: 7.042984962463379\n",
            "training loss: 6.998567581176758\n",
            "training loss: 7.06467342376709\n",
            "training loss: 6.973939895629883\n",
            "training loss: 6.805554389953613\n",
            "training loss: 7.012441158294678\n",
            "training loss: 6.981682777404785\n",
            "training loss: 7.018229961395264\n",
            "training loss: 6.8979902267456055\n",
            "training loss: 6.817776679992676\n",
            "training loss: 6.94382905960083\n",
            "training loss: 6.6514482498168945\n",
            "training loss: 6.898053169250488\n",
            "training loss: 6.830502033233643\n",
            "training loss: 6.952328681945801\n",
            "training loss: 6.832812309265137\n",
            "training loss: 6.830526351928711\n",
            "training loss: 6.845713138580322\n",
            "training loss: 6.762893199920654\n",
            "training loss: 6.791115760803223\n",
            "training loss: 6.754408836364746\n",
            "training loss: 6.837166786193848\n",
            "training loss: 6.966487884521484\n",
            "training loss: 6.754119396209717\n",
            "training loss: 7.064957141876221\n",
            "training loss: 6.789715766906738\n",
            "training loss: 6.9412007331848145\n",
            "training loss: 6.929468154907227\n",
            "training loss: 7.013566970825195\n",
            "training loss: 7.015950679779053\n",
            "training loss: 6.7893266677856445\n",
            "training loss: 6.883471488952637\n",
            "training loss: 6.822656154632568\n",
            "training loss: 6.794220924377441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  77%|███████▋  | 46/60 [36:33<11:02, 47.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.957711219787598\n",
            "training loss: 7.082014083862305\n",
            "training loss: 6.931750297546387\n",
            "training loss: 6.996736526489258\n",
            "training loss: 6.845877170562744\n",
            "training loss: 7.094071865081787\n",
            "training loss: 7.019095420837402\n",
            "training loss: 7.107876777648926\n",
            "training loss: 6.975668430328369\n",
            "training loss: 6.94474983215332\n",
            "training loss: 6.824117183685303\n",
            "training loss: 6.871559143066406\n",
            "training loss: 6.794106483459473\n",
            "training loss: 6.78616189956665\n",
            "training loss: 6.952796936035156\n",
            "training loss: 6.923102378845215\n",
            "training loss: 6.997015953063965\n",
            "training loss: 6.725373268127441\n",
            "training loss: 6.684302806854248\n",
            "training loss: 6.679800033569336\n",
            "training loss: 7.055191516876221\n",
            "training loss: 6.950933933258057\n",
            "training loss: 7.1116557121276855\n",
            "training loss: 6.8824143409729\n",
            "training loss: 6.402304649353027\n",
            "training loss: 7.04115629196167\n",
            "training loss: 6.853610515594482\n",
            "training loss: 6.793416976928711\n",
            "training loss: 6.631655693054199\n",
            "training loss: 6.697432518005371\n",
            "training loss: 6.614259243011475\n",
            "training loss: 6.520104885101318\n",
            "training loss: 7.073245525360107\n",
            "training loss: 6.766135215759277\n",
            "training loss: 6.918781280517578\n",
            "training loss: 6.677604675292969\n",
            "training loss: 6.461429595947266\n",
            "training loss: 6.778886795043945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  78%|███████▊  | 47/60 [37:20<10:10, 46.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.026680946350098\n",
            "training loss: 6.906254768371582\n",
            "training loss: 6.784714698791504\n",
            "training loss: 6.990663051605225\n",
            "training loss: 7.204891204833984\n",
            "training loss: 6.924594879150391\n",
            "training loss: 6.925558090209961\n",
            "training loss: 6.8055572509765625\n",
            "training loss: 6.756682872772217\n",
            "training loss: 6.892285346984863\n",
            "training loss: 6.800612449645996\n",
            "training loss: 6.844512462615967\n",
            "training loss: 6.872569561004639\n",
            "training loss: 6.986185073852539\n",
            "training loss: 6.970757484436035\n",
            "training loss: 6.88778018951416\n",
            "training loss: 6.77056884765625\n",
            "training loss: 7.039309501647949\n",
            "training loss: 6.871194362640381\n",
            "training loss: 6.851308822631836\n",
            "training loss: 7.118377685546875\n",
            "training loss: 6.794926166534424\n",
            "training loss: 6.871293544769287\n",
            "training loss: 7.063148498535156\n",
            "training loss: 6.888645172119141\n",
            "training loss: 6.9259209632873535\n",
            "training loss: 6.715385437011719\n",
            "training loss: 6.93728494644165\n",
            "training loss: 6.682498455047607\n",
            "training loss: 6.933564186096191\n",
            "training loss: 6.649714469909668\n",
            "training loss: 6.869596004486084\n",
            "training loss: 6.761855602264404\n",
            "training loss: 7.037204265594482\n",
            "training loss: 6.970303058624268\n",
            "training loss: 6.78692626953125\n",
            "training loss: 7.045232772827148\n",
            "training loss: 6.915377140045166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  80%|████████  | 48/60 [38:05<09:19, 46.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.107576847076416\n",
            "training loss: 7.028563499450684\n",
            "training loss: 6.8113789558410645\n",
            "training loss: 7.053946495056152\n",
            "training loss: 7.090322017669678\n",
            "training loss: 6.934633731842041\n",
            "training loss: 6.801673412322998\n",
            "training loss: 7.013044834136963\n",
            "training loss: 6.848217487335205\n",
            "training loss: 7.1602091789245605\n",
            "training loss: 7.006614685058594\n",
            "training loss: 6.81486177444458\n",
            "training loss: 7.052221775054932\n",
            "training loss: 7.026933193206787\n",
            "training loss: 6.996885299682617\n",
            "training loss: 6.971335411071777\n",
            "training loss: 6.719773292541504\n",
            "training loss: 6.840360164642334\n",
            "training loss: 6.907027244567871\n",
            "training loss: 6.742637634277344\n",
            "training loss: 6.887595176696777\n",
            "training loss: 6.817776679992676\n",
            "training loss: 6.878379821777344\n",
            "training loss: 6.998095512390137\n",
            "training loss: 6.978085517883301\n",
            "training loss: 6.591984272003174\n",
            "training loss: 6.767166614532471\n",
            "training loss: 6.951506614685059\n",
            "training loss: 6.927235126495361\n",
            "training loss: 6.871582984924316\n",
            "training loss: 6.940109729766846\n",
            "training loss: 7.081167221069336\n",
            "training loss: 6.9754958152771\n",
            "training loss: 6.93560791015625\n",
            "training loss: 6.860245704650879\n",
            "training loss: 7.137763977050781\n",
            "training loss: 6.843234062194824\n",
            "training loss: 6.7344970703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  82%|████████▏ | 49/60 [38:52<08:31, 46.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.084416389465332\n",
            "training loss: 6.859100341796875\n",
            "training loss: 6.990074157714844\n",
            "training loss: 7.126212120056152\n",
            "training loss: 6.944484710693359\n",
            "training loss: 7.009706497192383\n",
            "training loss: 7.007885932922363\n",
            "training loss: 6.816277980804443\n",
            "training loss: 6.712179183959961\n",
            "training loss: 6.951794147491455\n",
            "training loss: 6.928683280944824\n",
            "training loss: 7.2394585609436035\n",
            "training loss: 7.023697376251221\n",
            "training loss: 6.761449813842773\n",
            "training loss: 6.855251312255859\n",
            "training loss: 7.025451183319092\n",
            "training loss: 7.096373558044434\n",
            "training loss: 6.803771018981934\n",
            "training loss: 6.874973773956299\n",
            "training loss: 6.900274753570557\n",
            "training loss: 6.817075729370117\n",
            "training loss: 6.869586944580078\n",
            "training loss: 6.635747909545898\n",
            "training loss: 6.790246963500977\n",
            "training loss: 6.918381690979004\n",
            "training loss: 6.771017074584961\n",
            "training loss: 6.970160484313965\n",
            "training loss: 6.989761829376221\n",
            "training loss: 7.02520751953125\n",
            "training loss: 6.746264457702637\n",
            "training loss: 6.931639671325684\n",
            "training loss: 7.019933700561523\n",
            "training loss: 6.675039291381836\n",
            "training loss: 6.7370100021362305\n",
            "training loss: 6.911068439483643\n",
            "training loss: 6.908410549163818\n",
            "training loss: 6.80940580368042\n",
            "training loss: 6.744789123535156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  83%|████████▎ | 50/60 [39:37<07:43, 46.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.910338401794434\n",
            "training loss: 7.006342887878418\n",
            "training loss: 7.002586841583252\n",
            "training loss: 6.742562770843506\n",
            "training loss: 7.040609359741211\n",
            "training loss: 6.917524337768555\n",
            "training loss: 6.85542631149292\n",
            "training loss: 6.752687454223633\n",
            "training loss: 6.923469543457031\n",
            "training loss: 6.82560920715332\n",
            "training loss: 6.777737617492676\n",
            "training loss: 6.922074317932129\n",
            "training loss: 6.671724319458008\n",
            "training loss: 6.875573635101318\n",
            "training loss: 6.792201995849609\n",
            "training loss: 7.0779571533203125\n",
            "training loss: 6.858693599700928\n",
            "training loss: 6.653817176818848\n",
            "training loss: 6.803011894226074\n",
            "training loss: 6.808826446533203\n",
            "training loss: 6.81519889831543\n",
            "training loss: 6.797430992126465\n",
            "training loss: 6.643464088439941\n",
            "training loss: 6.885803699493408\n",
            "training loss: 6.8820109367370605\n",
            "training loss: 6.725489616394043\n",
            "training loss: 6.758742809295654\n",
            "training loss: 6.923213958740234\n",
            "training loss: 6.9134416580200195\n",
            "training loss: 6.725327491760254\n",
            "training loss: 6.763362884521484\n",
            "training loss: 6.828711986541748\n",
            "training loss: 6.781125545501709\n",
            "training loss: 6.730088233947754\n",
            "training loss: 7.086495876312256\n",
            "training loss: 6.716986179351807\n",
            "training loss: 6.895943641662598\n",
            "training loss: 6.58663272857666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  85%|████████▌ | 51/60 [40:23<06:55, 46.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.828402519226074\n",
            "training loss: 6.850039482116699\n",
            "training loss: 6.944134712219238\n",
            "training loss: 6.992869853973389\n",
            "training loss: 6.903406143188477\n",
            "training loss: 7.212890148162842\n",
            "training loss: 6.66936731338501\n",
            "training loss: 6.831042289733887\n",
            "training loss: 6.628640651702881\n",
            "training loss: 6.817737579345703\n",
            "training loss: 7.151129722595215\n",
            "training loss: 6.716992378234863\n",
            "training loss: 6.849780082702637\n",
            "training loss: 6.614826202392578\n",
            "training loss: 6.8964738845825195\n",
            "training loss: 6.922966957092285\n",
            "training loss: 7.066300868988037\n",
            "training loss: 6.954921245574951\n",
            "training loss: 6.907454967498779\n",
            "training loss: 6.914545059204102\n",
            "training loss: 6.634906768798828\n",
            "training loss: 6.388954162597656\n",
            "training loss: 6.623054504394531\n",
            "training loss: 6.781615257263184\n",
            "training loss: 6.537853240966797\n",
            "training loss: 6.500711441040039\n",
            "training loss: 6.718670845031738\n",
            "training loss: 6.734493732452393\n",
            "training loss: 6.770946502685547\n",
            "training loss: 6.655759811401367\n",
            "training loss: 6.631744861602783\n",
            "training loss: 6.714496612548828\n",
            "training loss: 6.522855281829834\n",
            "training loss: 6.9517364501953125\n",
            "training loss: 6.911545753479004\n",
            "training loss: 6.811553478240967\n",
            "training loss: 6.832635879516602\n",
            "training loss: 6.989353179931641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  87%|████████▋ | 52/60 [41:11<06:12, 46.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.865561485290527\n",
            "training loss: 6.987356185913086\n",
            "training loss: 6.930563926696777\n",
            "training loss: 6.609302997589111\n",
            "training loss: 6.81966495513916\n",
            "training loss: 7.019274711608887\n",
            "training loss: 6.798612117767334\n",
            "training loss: 6.7926249504089355\n",
            "training loss: 6.663578987121582\n",
            "training loss: 6.863880634307861\n",
            "training loss: 7.106383800506592\n",
            "training loss: 6.978341579437256\n",
            "training loss: 6.741790771484375\n",
            "training loss: 6.746660232543945\n",
            "training loss: 6.562216758728027\n",
            "training loss: 6.591716766357422\n",
            "training loss: 6.474399089813232\n",
            "training loss: 6.69902229309082\n",
            "training loss: 6.698534965515137\n",
            "training loss: 7.294678688049316\n",
            "training loss: 6.99637508392334\n",
            "training loss: 6.923409461975098\n",
            "training loss: 7.102534294128418\n",
            "training loss: 6.86518669128418\n",
            "training loss: 7.021617889404297\n",
            "training loss: 6.7375898361206055\n",
            "training loss: 6.84409761428833\n",
            "training loss: 6.901712417602539\n",
            "training loss: 6.827487468719482\n",
            "training loss: 6.703238487243652\n",
            "training loss: 6.369772911071777\n",
            "training loss: 7.124495506286621\n",
            "training loss: 6.953462600708008\n",
            "training loss: 6.718077182769775\n",
            "training loss: 6.561398029327393\n",
            "training loss: 6.784894943237305\n",
            "training loss: 6.9528489112854\n",
            "training loss: 6.5927839279174805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  88%|████████▊ | 53/60 [41:56<05:23, 46.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.0997209548950195\n",
            "training loss: 6.908668518066406\n",
            "training loss: 7.168501853942871\n",
            "training loss: 7.0293707847595215\n",
            "training loss: 7.000474452972412\n",
            "training loss: 6.915871620178223\n",
            "training loss: 6.902446269989014\n",
            "training loss: 7.080851078033447\n",
            "training loss: 7.113986968994141\n",
            "training loss: 7.065359592437744\n",
            "training loss: 7.016099452972412\n",
            "training loss: 6.843846321105957\n",
            "training loss: 6.993582725524902\n",
            "training loss: 7.039487838745117\n",
            "training loss: 6.655085563659668\n",
            "training loss: 6.513619422912598\n",
            "training loss: 6.704207420349121\n",
            "training loss: 6.878813743591309\n",
            "training loss: 6.923464775085449\n",
            "training loss: 6.991652965545654\n",
            "training loss: 6.993606090545654\n",
            "training loss: 6.840598106384277\n",
            "training loss: 6.874235153198242\n",
            "training loss: 6.871018886566162\n",
            "training loss: 6.782212257385254\n",
            "training loss: 6.770000457763672\n",
            "training loss: 6.780621528625488\n",
            "training loss: 6.995878219604492\n",
            "training loss: 6.691425800323486\n",
            "training loss: 6.7667131423950195\n",
            "training loss: 6.860532283782959\n",
            "training loss: 6.875776290893555\n",
            "training loss: 6.831631660461426\n",
            "training loss: 6.626388072967529\n",
            "training loss: 6.720653533935547\n",
            "training loss: 6.678976535797119\n",
            "training loss: 6.785693645477295\n",
            "training loss: 6.796017646789551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  90%|█████████ | 54/60 [42:42<04:36, 46.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.0165863037109375\n",
            "training loss: 7.168322563171387\n",
            "training loss: 7.030549049377441\n",
            "training loss: 6.842226982116699\n",
            "training loss: 6.953417778015137\n",
            "training loss: 7.007760047912598\n",
            "training loss: 7.014496803283691\n",
            "training loss: 6.939899444580078\n",
            "training loss: 6.66132926940918\n",
            "training loss: 6.892449855804443\n",
            "training loss: 6.984202861785889\n",
            "training loss: 6.862083435058594\n",
            "training loss: 6.808984756469727\n",
            "training loss: 6.83715295791626\n",
            "training loss: 6.656857490539551\n",
            "training loss: 6.7825469970703125\n",
            "training loss: 7.099629878997803\n",
            "training loss: 6.886806964874268\n",
            "training loss: 6.930753707885742\n",
            "training loss: 6.845378875732422\n",
            "training loss: 6.712833404541016\n",
            "training loss: 6.668258190155029\n",
            "training loss: 6.873639106750488\n",
            "training loss: 6.847512722015381\n",
            "training loss: 6.850223541259766\n",
            "training loss: 6.6969733238220215\n",
            "training loss: 6.8111772537231445\n",
            "training loss: 6.886002063751221\n",
            "training loss: 6.841043472290039\n",
            "training loss: 6.671390056610107\n",
            "training loss: 6.676738739013672\n",
            "training loss: 6.912182807922363\n",
            "training loss: 6.880540370941162\n",
            "training loss: 6.7505645751953125\n",
            "training loss: 6.939042091369629\n",
            "training loss: 7.019623756408691\n",
            "training loss: 6.765345573425293\n",
            "training loss: 6.7666754722595215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  92%|█████████▏| 55/60 [43:27<03:48, 45.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.968197822570801\n",
            "training loss: 7.069189071655273\n",
            "training loss: 7.121739387512207\n",
            "training loss: 7.059990882873535\n",
            "training loss: 7.09350061416626\n",
            "training loss: 6.789337635040283\n",
            "training loss: 7.001229286193848\n",
            "training loss: 6.787107467651367\n",
            "training loss: 6.96212100982666\n",
            "training loss: 6.861453056335449\n",
            "training loss: 6.836770057678223\n",
            "training loss: 6.5143914222717285\n",
            "training loss: 6.844381332397461\n",
            "training loss: 6.801365852355957\n",
            "training loss: 6.579099655151367\n",
            "training loss: 6.866705894470215\n",
            "training loss: 6.988827705383301\n",
            "training loss: 6.819672584533691\n",
            "training loss: 6.84001350402832\n",
            "training loss: 6.648825645446777\n",
            "training loss: 6.901104927062988\n",
            "training loss: 7.043172359466553\n",
            "training loss: 6.90992546081543\n",
            "training loss: 6.84358024597168\n",
            "training loss: 6.80680513381958\n",
            "training loss: 6.658177375793457\n",
            "training loss: 6.651242256164551\n",
            "training loss: 6.908632278442383\n",
            "training loss: 6.721769332885742\n",
            "training loss: 6.738746166229248\n",
            "training loss: 7.024075031280518\n",
            "training loss: 6.585977554321289\n",
            "training loss: 6.466978073120117\n",
            "training loss: 6.701256275177002\n",
            "training loss: 6.831514835357666\n",
            "training loss: 7.0843505859375\n",
            "training loss: 7.075417518615723\n",
            "training loss: 7.033029556274414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  93%|█████████▎| 56/60 [44:12<03:02, 45.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.14929723739624\n",
            "training loss: 6.936649322509766\n",
            "training loss: 6.913225173950195\n",
            "training loss: 6.821967124938965\n",
            "training loss: 6.718227386474609\n",
            "training loss: 6.9277496337890625\n",
            "training loss: 6.935303688049316\n",
            "training loss: 7.294146537780762\n",
            "training loss: 6.8367462158203125\n",
            "training loss: 6.8563385009765625\n",
            "training loss: 6.8230881690979\n",
            "training loss: 6.931555271148682\n",
            "training loss: 6.695127964019775\n",
            "training loss: 6.920134544372559\n",
            "training loss: 6.896463871002197\n",
            "training loss: 6.65720796585083\n",
            "training loss: 6.945492744445801\n",
            "training loss: 6.687676906585693\n",
            "training loss: 6.86846923828125\n",
            "training loss: 6.94058895111084\n",
            "training loss: 6.849931716918945\n",
            "training loss: 6.836836338043213\n",
            "training loss: 6.806541442871094\n",
            "training loss: 6.702798843383789\n",
            "training loss: 6.871902942657471\n",
            "training loss: 7.008059501647949\n",
            "training loss: 6.6432976722717285\n",
            "training loss: 6.632652759552002\n",
            "training loss: 6.727868556976318\n",
            "training loss: 6.718922138214111\n",
            "training loss: 6.749781608581543\n",
            "training loss: 7.028464317321777\n",
            "training loss: 6.8448872566223145\n",
            "training loss: 6.5500640869140625\n",
            "training loss: 6.600637435913086\n",
            "training loss: 7.0335493087768555\n",
            "training loss: 6.8615312576293945\n",
            "training loss: 6.576603412628174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  95%|█████████▌| 57/60 [44:59<02:18, 46.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.060667991638184\n",
            "training loss: 7.031485557556152\n",
            "training loss: 7.113644123077393\n",
            "training loss: 6.967253684997559\n",
            "training loss: 6.875616550445557\n",
            "training loss: 7.013486862182617\n",
            "training loss: 7.040668964385986\n",
            "training loss: 7.035135269165039\n",
            "training loss: 6.72922420501709\n",
            "training loss: 6.860360145568848\n",
            "training loss: 6.911479473114014\n",
            "training loss: 7.131113052368164\n",
            "training loss: 7.1529741287231445\n",
            "training loss: 7.123356819152832\n",
            "training loss: 6.953172206878662\n",
            "training loss: 7.203777313232422\n",
            "training loss: 7.152757167816162\n",
            "training loss: 6.903753280639648\n",
            "training loss: 6.924371242523193\n",
            "training loss: 7.213237285614014\n",
            "training loss: 7.089074611663818\n",
            "training loss: 7.121741771697998\n",
            "training loss: 7.110359191894531\n",
            "training loss: 6.8977251052856445\n",
            "training loss: 6.973706245422363\n",
            "training loss: 7.020798206329346\n",
            "training loss: 6.909191608428955\n",
            "training loss: 7.082634925842285\n",
            "training loss: 6.961818218231201\n",
            "training loss: 6.922931671142578\n",
            "training loss: 6.982369422912598\n",
            "training loss: 7.037778854370117\n",
            "training loss: 6.9342827796936035\n",
            "training loss: 6.738519668579102\n",
            "training loss: 6.855240345001221\n",
            "training loss: 7.047844886779785\n",
            "training loss: 6.8872575759887695\n",
            "training loss: 6.819644927978516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  97%|█████████▋| 58/60 [45:44<01:31, 45.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.190310001373291\n",
            "training loss: 6.313479423522949\n",
            "training loss: 6.596270561218262\n",
            "training loss: 6.820706367492676\n",
            "training loss: 6.8364057540893555\n",
            "training loss: 7.050815582275391\n",
            "training loss: 6.781099319458008\n",
            "training loss: 6.868194103240967\n",
            "training loss: 7.092973232269287\n",
            "training loss: 7.0535125732421875\n",
            "training loss: 6.794602394104004\n",
            "training loss: 7.073168754577637\n",
            "training loss: 6.729029655456543\n",
            "training loss: 6.771549224853516\n",
            "training loss: 7.1246843338012695\n",
            "training loss: 7.042487621307373\n",
            "training loss: 7.132587432861328\n",
            "training loss: 7.028584957122803\n",
            "training loss: 7.343695640563965\n",
            "training loss: 7.1262969970703125\n",
            "training loss: 6.847651481628418\n",
            "training loss: 6.98566198348999\n",
            "training loss: 7.040767669677734\n",
            "training loss: 7.103167533874512\n",
            "training loss: 7.094795227050781\n",
            "training loss: 6.832363128662109\n",
            "training loss: 6.7206573486328125\n",
            "training loss: 6.866756439208984\n",
            "training loss: 6.888229846954346\n",
            "training loss: 6.903683662414551\n",
            "training loss: 6.838619709014893\n",
            "training loss: 7.1501264572143555\n",
            "training loss: 6.869423866271973\n",
            "training loss: 7.039934158325195\n",
            "training loss: 7.055201053619385\n",
            "training loss: 6.753876209259033\n",
            "training loss: 6.975724220275879\n",
            "training loss: 6.822900772094727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  98%|█████████▊| 59/60 [46:29<00:45, 45.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.048961639404297\n",
            "training loss: 6.84520149230957\n",
            "training loss: 7.017086982727051\n",
            "training loss: 7.006104469299316\n",
            "training loss: 7.028810977935791\n",
            "training loss: 6.768268585205078\n",
            "training loss: 6.9065117835998535\n",
            "training loss: 6.751235008239746\n",
            "training loss: 6.6167402267456055\n",
            "training loss: 6.746565818786621\n",
            "training loss: 6.654123306274414\n",
            "training loss: 6.711519241333008\n",
            "training loss: 6.870868682861328\n",
            "training loss: 6.765015125274658\n",
            "training loss: 6.909705638885498\n",
            "training loss: 6.599569320678711\n",
            "training loss: 6.682755470275879\n",
            "training loss: 6.836512088775635\n",
            "training loss: 6.702033996582031\n",
            "training loss: 6.724315643310547\n",
            "training loss: 6.743771553039551\n",
            "training loss: 6.8430914878845215\n",
            "training loss: 7.08822774887085\n",
            "training loss: 7.06553316116333\n",
            "training loss: 6.950961112976074\n",
            "training loss: 6.899020195007324\n",
            "training loss: 6.852474212646484\n",
            "training loss: 7.146500587463379\n",
            "training loss: 7.212863922119141\n",
            "training loss: 6.765601634979248\n",
            "training loss: 6.693375110626221\n",
            "training loss: 6.879700660705566\n",
            "training loss: 6.939633369445801\n",
            "training loss: 6.890140533447266\n",
            "training loss: 6.83951473236084\n",
            "training loss: 6.681230545043945\n",
            "training loss: 6.99415397644043\n",
            "training loss: 6.676310062408447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training: 100%|██████████| 60/60 [47:14<00:00, 47.25s/it]\n",
            "evaluation: 100%|██████████| 7/7 [03:20<00:00, 28.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 577.5076904296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training:   0%|          | 0/60 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.510356903076172\n",
            "training loss: 6.757486343383789\n",
            "training loss: 6.6328630447387695\n",
            "training loss: 6.728132724761963\n",
            "training loss: 6.717950344085693\n",
            "training loss: 6.838336944580078\n",
            "training loss: 6.966795921325684\n",
            "training loss: 6.922530174255371\n",
            "training loss: 6.805405139923096\n",
            "training loss: 6.6578755378723145\n",
            "training loss: 6.362881183624268\n",
            "training loss: 6.553928375244141\n",
            "training loss: 6.762398719787598\n",
            "training loss: 6.640352249145508\n",
            "training loss: 6.813636779785156\n",
            "training loss: 6.845776081085205\n",
            "training loss: 6.789206504821777\n",
            "training loss: 6.805570602416992\n",
            "training loss: 6.613215446472168\n",
            "training loss: 6.546566963195801\n",
            "training loss: 6.863786697387695\n",
            "training loss: 6.955855369567871\n",
            "training loss: 6.968053817749023\n",
            "training loss: 7.041532039642334\n",
            "training loss: 6.785773754119873\n",
            "training loss: 7.162948131561279\n",
            "training loss: 6.930270671844482\n",
            "training loss: 7.042219638824463\n",
            "training loss: 6.871337413787842\n",
            "training loss: 6.834636688232422\n",
            "training loss: 7.013596057891846\n",
            "training loss: 7.009239673614502\n",
            "training loss: 6.93837308883667\n",
            "training loss: 6.737273216247559\n",
            "training loss: 6.951807975769043\n",
            "training loss: 6.651201248168945\n",
            "training loss: 6.672738075256348\n",
            "training loss: 6.795802116394043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 1/60 [00:47<46:52, 47.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.894475936889648\n",
            "training loss: 6.850249290466309\n",
            "training loss: 7.0319952964782715\n",
            "training loss: 6.801179885864258\n",
            "training loss: 6.932727336883545\n",
            "training loss: 6.94406795501709\n",
            "training loss: 6.853383541107178\n",
            "training loss: 6.793853759765625\n",
            "training loss: 6.780278205871582\n",
            "training loss: 6.918486595153809\n",
            "training loss: 6.886020660400391\n",
            "training loss: 6.71783971786499\n",
            "training loss: 6.875295639038086\n",
            "training loss: 6.961373805999756\n",
            "training loss: 7.01235818862915\n",
            "training loss: 6.669069766998291\n",
            "training loss: 6.848647594451904\n",
            "training loss: 6.6300368309021\n",
            "training loss: 6.775835990905762\n",
            "training loss: 6.640373229980469\n",
            "training loss: 6.72596549987793\n",
            "training loss: 6.398162841796875\n",
            "training loss: 6.544604778289795\n",
            "training loss: 6.65439510345459\n",
            "training loss: 6.59855842590332\n",
            "training loss: 6.654783725738525\n",
            "training loss: 6.584099769592285\n",
            "training loss: 6.631197929382324\n",
            "training loss: 6.617081642150879\n",
            "training loss: 6.800854682922363\n",
            "training loss: 6.8482770919799805\n",
            "training loss: 6.637516021728516\n",
            "training loss: 6.682596206665039\n",
            "training loss: 6.569105625152588\n",
            "training loss: 6.594045639038086\n",
            "training loss: 6.666391372680664\n",
            "training loss: 6.631356239318848\n",
            "training loss: 6.9282331466674805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   3%|▎         | 2/60 [01:32<44:41, 46.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.940439701080322\n",
            "training loss: 7.0932416915893555\n",
            "training loss: 6.983954906463623\n",
            "training loss: 7.073462009429932\n",
            "training loss: 6.966060638427734\n",
            "training loss: 6.980544090270996\n",
            "training loss: 6.930962562561035\n",
            "training loss: 7.094615936279297\n",
            "training loss: 6.956641674041748\n",
            "training loss: 6.858004093170166\n",
            "training loss: 6.746917724609375\n",
            "training loss: 6.547013759613037\n",
            "training loss: 6.552022933959961\n",
            "training loss: 6.770895957946777\n",
            "training loss: 6.884052753448486\n",
            "training loss: 6.493070602416992\n",
            "training loss: 6.7620320320129395\n",
            "training loss: 6.593502521514893\n",
            "training loss: 6.626829624176025\n",
            "training loss: 6.869146823883057\n",
            "training loss: 6.868793964385986\n",
            "training loss: 6.875154495239258\n",
            "training loss: 6.676782608032227\n",
            "training loss: 6.825984001159668\n",
            "training loss: 6.944509029388428\n",
            "training loss: 6.9317731857299805\n",
            "training loss: 6.946654796600342\n",
            "training loss: 6.8134541511535645\n",
            "training loss: 6.8225250244140625\n",
            "training loss: 6.710761547088623\n",
            "training loss: 6.678671360015869\n",
            "training loss: 6.797906398773193\n",
            "training loss: 6.748974800109863\n",
            "training loss: 6.710977077484131\n",
            "training loss: 6.322876930236816\n",
            "training loss: 6.6510210037231445\n",
            "training loss: 6.509257793426514\n",
            "training loss: 6.555750846862793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   5%|▌         | 3/60 [02:19<44:00, 46.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.171889305114746\n",
            "training loss: 6.71240758895874\n",
            "training loss: 7.162014007568359\n",
            "training loss: 6.815819263458252\n",
            "training loss: 6.683122634887695\n",
            "training loss: 6.803259372711182\n",
            "training loss: 7.02180814743042\n",
            "training loss: 6.77014684677124\n",
            "training loss: 6.920869827270508\n",
            "training loss: 6.740128993988037\n",
            "training loss: 7.046572685241699\n",
            "training loss: 6.893610000610352\n",
            "training loss: 6.693717956542969\n",
            "training loss: 6.690732002258301\n",
            "training loss: 6.725248336791992\n",
            "training loss: 6.873118877410889\n",
            "training loss: 6.47974967956543\n",
            "training loss: 6.558244705200195\n",
            "training loss: 6.410350799560547\n",
            "training loss: 6.695979595184326\n",
            "training loss: 7.021805286407471\n",
            "training loss: 6.666396617889404\n",
            "training loss: 6.6561455726623535\n",
            "training loss: 6.6784586906433105\n",
            "training loss: 6.71396541595459\n",
            "training loss: 6.770937919616699\n",
            "training loss: 6.9413299560546875\n",
            "training loss: 6.933707237243652\n",
            "training loss: 6.9505181312561035\n",
            "training loss: 7.136401176452637\n",
            "training loss: 6.850449562072754\n",
            "training loss: 7.061426162719727\n",
            "training loss: 6.833657264709473\n",
            "training loss: 6.583624839782715\n",
            "training loss: 6.979418754577637\n",
            "training loss: 6.727606296539307\n",
            "training loss: 6.73105525970459\n",
            "training loss: 6.871546268463135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   7%|▋         | 4/60 [03:05<43:13, 46.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.8146071434021\n",
            "training loss: 6.801397800445557\n",
            "training loss: 6.918281555175781\n",
            "training loss: 6.858686447143555\n",
            "training loss: 7.055188179016113\n",
            "training loss: 6.934467315673828\n",
            "training loss: 6.836541175842285\n",
            "training loss: 6.7808451652526855\n",
            "training loss: 6.978297710418701\n",
            "training loss: 6.922768592834473\n",
            "training loss: 7.099946022033691\n",
            "training loss: 7.1406989097595215\n",
            "training loss: 6.9340643882751465\n",
            "training loss: 7.154457092285156\n",
            "training loss: 7.117048263549805\n",
            "training loss: 6.755674362182617\n",
            "training loss: 6.852713108062744\n",
            "training loss: 6.989329814910889\n",
            "training loss: 6.882233619689941\n",
            "training loss: 6.691425323486328\n",
            "training loss: 6.825214862823486\n",
            "training loss: 6.751659393310547\n",
            "training loss: 6.715612888336182\n",
            "training loss: 6.81550931930542\n",
            "training loss: 6.688238143920898\n",
            "training loss: 6.678765773773193\n",
            "training loss: 6.549879550933838\n",
            "training loss: 6.719466209411621\n",
            "training loss: 6.646956443786621\n",
            "training loss: 6.8391594886779785\n",
            "training loss: 6.828423500061035\n",
            "training loss: 6.896736145019531\n",
            "training loss: 6.699695110321045\n",
            "training loss: 6.787801742553711\n",
            "training loss: 6.609457492828369\n",
            "training loss: 6.762890815734863\n",
            "training loss: 6.54694938659668\n",
            "training loss: 6.7437286376953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   8%|▊         | 5/60 [03:50<41:50, 45.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.937355995178223\n",
            "training loss: 6.856103420257568\n",
            "training loss: 6.871808052062988\n",
            "training loss: 6.882911682128906\n",
            "training loss: 6.967332363128662\n",
            "training loss: 6.978579521179199\n",
            "training loss: 6.955368995666504\n",
            "training loss: 6.9341721534729\n",
            "training loss: 6.72397518157959\n",
            "training loss: 6.79440450668335\n",
            "training loss: 6.887880325317383\n",
            "training loss: 6.936756134033203\n",
            "training loss: 6.797913551330566\n",
            "training loss: 6.622433662414551\n",
            "training loss: 6.663823127746582\n",
            "training loss: 6.811479568481445\n",
            "training loss: 6.659286975860596\n",
            "training loss: 6.619669437408447\n",
            "training loss: 6.768390655517578\n",
            "training loss: 6.631217002868652\n",
            "training loss: 6.879263877868652\n",
            "training loss: 6.929443836212158\n",
            "training loss: 6.796684265136719\n",
            "training loss: 6.541689872741699\n",
            "training loss: 6.614532947540283\n",
            "training loss: 6.452273368835449\n",
            "training loss: 6.597776412963867\n",
            "training loss: 6.700578689575195\n",
            "training loss: 6.343081474304199\n",
            "training loss: 6.45552921295166\n",
            "training loss: 6.634252548217773\n",
            "training loss: 6.610487937927246\n",
            "training loss: 6.565244197845459\n",
            "training loss: 6.947829246520996\n",
            "training loss: 6.733126640319824\n",
            "training loss: 6.764041900634766\n",
            "training loss: 6.808347702026367\n",
            "training loss: 6.713042736053467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  10%|█         | 6/60 [04:34<40:50, 45.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.772170066833496\n",
            "training loss: 6.89910364151001\n",
            "training loss: 6.942985534667969\n",
            "training loss: 6.755897521972656\n",
            "training loss: 6.861809730529785\n",
            "training loss: 6.818626403808594\n",
            "training loss: 6.443248748779297\n",
            "training loss: 6.759629249572754\n",
            "training loss: 6.520808219909668\n",
            "training loss: 6.676156044006348\n",
            "training loss: 7.016918659210205\n",
            "training loss: 6.798778533935547\n",
            "training loss: 6.775262832641602\n",
            "training loss: 6.694415092468262\n",
            "training loss: 6.759003639221191\n",
            "training loss: 6.800023555755615\n",
            "training loss: 6.692770004272461\n",
            "training loss: 6.581704139709473\n",
            "training loss: 6.6274261474609375\n",
            "training loss: 6.809272766113281\n",
            "training loss: 6.271821975708008\n",
            "training loss: 6.203835487365723\n",
            "training loss: 6.474216461181641\n",
            "training loss: 6.548866271972656\n",
            "training loss: 6.350293159484863\n",
            "training loss: 6.214746475219727\n",
            "training loss: 6.595247268676758\n",
            "training loss: 6.454773902893066\n",
            "training loss: 6.3686652183532715\n",
            "training loss: 6.3485517501831055\n",
            "training loss: 6.1432294845581055\n",
            "training loss: 6.593422889709473\n",
            "training loss: 6.544853687286377\n",
            "training loss: 6.812490940093994\n",
            "training loss: 6.836437225341797\n",
            "training loss: 7.007102966308594\n",
            "training loss: 6.809332847595215\n",
            "training loss: 6.893671035766602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  12%|█▏        | 7/60 [05:19<39:55, 45.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.097611904144287\n",
            "training loss: 6.869513511657715\n",
            "training loss: 7.047063827514648\n",
            "training loss: 6.6146559715271\n",
            "training loss: 7.0999064445495605\n",
            "training loss: 6.8754072189331055\n",
            "training loss: 6.801091194152832\n",
            "training loss: 6.901854515075684\n",
            "training loss: 6.811237812042236\n",
            "training loss: 6.722447395324707\n",
            "training loss: 6.83950138092041\n",
            "training loss: 7.030477523803711\n",
            "training loss: 6.737852096557617\n",
            "training loss: 6.581336975097656\n",
            "training loss: 6.667612075805664\n",
            "training loss: 6.476670742034912\n",
            "training loss: 6.4908552169799805\n",
            "training loss: 6.816727638244629\n",
            "training loss: 6.44586181640625\n",
            "training loss: 6.766927242279053\n",
            "training loss: 6.618369102478027\n",
            "training loss: 6.790326118469238\n",
            "training loss: 6.777082920074463\n",
            "training loss: 6.857165336608887\n",
            "training loss: 6.873149871826172\n",
            "training loss: 6.839115142822266\n",
            "training loss: 6.695464134216309\n",
            "training loss: 6.682541370391846\n",
            "training loss: 6.857353687286377\n",
            "training loss: 6.740889072418213\n",
            "training loss: 6.697167873382568\n",
            "training loss: 6.689651012420654\n",
            "training loss: 6.876806735992432\n",
            "training loss: 6.795888900756836\n",
            "training loss: 6.713924407958984\n",
            "training loss: 6.705375671386719\n",
            "training loss: 6.644603729248047\n",
            "training loss: 6.727116107940674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  13%|█▎        | 8/60 [06:06<39:30, 45.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.765318870544434\n",
            "training loss: 6.808149337768555\n",
            "training loss: 6.629117012023926\n",
            "training loss: 6.807459831237793\n",
            "training loss: 6.884005546569824\n",
            "training loss: 7.2108330726623535\n",
            "training loss: 6.984170913696289\n",
            "training loss: 6.976151466369629\n",
            "training loss: 6.950935363769531\n",
            "training loss: 6.941074848175049\n",
            "training loss: 6.9574174880981445\n",
            "training loss: 7.01710319519043\n",
            "training loss: 6.689650535583496\n",
            "training loss: 6.802703857421875\n",
            "training loss: 6.718767166137695\n",
            "training loss: 6.936293125152588\n",
            "training loss: 6.851016998291016\n",
            "training loss: 6.698055267333984\n",
            "training loss: 6.887163162231445\n",
            "training loss: 6.606186866760254\n",
            "training loss: 6.749063968658447\n",
            "training loss: 6.812597274780273\n",
            "training loss: 6.785613059997559\n",
            "training loss: 6.695502281188965\n",
            "training loss: 6.705628395080566\n",
            "training loss: 6.67219352722168\n",
            "training loss: 6.816212177276611\n",
            "training loss: 7.038241386413574\n",
            "training loss: 6.692879676818848\n",
            "training loss: 6.670290470123291\n",
            "training loss: 6.720823287963867\n",
            "training loss: 6.716704845428467\n",
            "training loss: 6.716561317443848\n",
            "training loss: 6.72213077545166\n",
            "training loss: 6.847259998321533\n",
            "training loss: 6.7163286209106445\n",
            "training loss: 6.82092809677124\n",
            "training loss: 6.688636302947998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  15%|█▌        | 9/60 [06:51<38:39, 45.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.6739959716796875\n",
            "training loss: 6.780521392822266\n",
            "training loss: 7.068752288818359\n",
            "training loss: 6.832322597503662\n",
            "training loss: 6.925380706787109\n",
            "training loss: 6.792790412902832\n",
            "training loss: 6.843710422515869\n",
            "training loss: 6.867351531982422\n",
            "training loss: 6.810824394226074\n",
            "training loss: 6.881065368652344\n",
            "training loss: 6.66549015045166\n",
            "training loss: 6.826047897338867\n",
            "training loss: 6.804189682006836\n",
            "training loss: 6.752947807312012\n",
            "training loss: 6.727789402008057\n",
            "training loss: 6.847447872161865\n",
            "training loss: 6.696188926696777\n",
            "training loss: 6.734455585479736\n",
            "training loss: 6.807254314422607\n",
            "training loss: 6.7481865882873535\n",
            "training loss: 6.618811130523682\n",
            "training loss: 6.830687999725342\n",
            "training loss: 6.873830795288086\n",
            "training loss: 6.88175106048584\n",
            "training loss: 6.920714378356934\n",
            "training loss: 6.683777809143066\n",
            "training loss: 6.753064155578613\n",
            "training loss: 6.728952407836914\n",
            "training loss: 6.752079963684082\n",
            "training loss: 6.775238037109375\n",
            "training loss: 6.814239978790283\n",
            "training loss: 6.6300554275512695\n",
            "training loss: 6.707029342651367\n",
            "training loss: 6.61679744720459\n",
            "training loss: 6.880285263061523\n",
            "training loss: 6.701900959014893\n",
            "training loss: 6.5372161865234375\n",
            "training loss: 6.353906154632568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  17%|█▋        | 10/60 [07:36<37:42, 45.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.764558792114258\n",
            "training loss: 6.436187744140625\n",
            "training loss: 6.848531723022461\n",
            "training loss: 6.780793190002441\n",
            "training loss: 6.670423984527588\n",
            "training loss: 6.718996047973633\n",
            "training loss: 6.770108699798584\n",
            "training loss: 6.873629093170166\n",
            "training loss: 6.890227794647217\n",
            "training loss: 6.660993576049805\n",
            "training loss: 6.754721641540527\n",
            "training loss: 6.762375831604004\n",
            "training loss: 6.902754783630371\n",
            "training loss: 6.625371932983398\n",
            "training loss: 6.794528961181641\n",
            "training loss: 6.498600482940674\n",
            "training loss: 6.672159671783447\n",
            "training loss: 6.474793434143066\n",
            "training loss: 6.7981133460998535\n",
            "training loss: 6.7770233154296875\n",
            "training loss: 6.896059989929199\n",
            "training loss: 6.802476406097412\n",
            "training loss: 6.751997470855713\n",
            "training loss: 6.747893810272217\n",
            "training loss: 6.735410213470459\n",
            "training loss: 6.695243835449219\n",
            "training loss: 6.568497657775879\n",
            "training loss: 6.68266487121582\n",
            "training loss: 6.725832462310791\n",
            "training loss: 6.397344589233398\n",
            "training loss: 6.476004600524902\n",
            "training loss: 6.72010612487793\n",
            "training loss: 6.683930397033691\n",
            "training loss: 6.7491278648376465\n",
            "training loss: 6.774308681488037\n",
            "training loss: 6.63289737701416\n",
            "training loss: 6.679608345031738\n",
            "training loss: 6.792874336242676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  18%|█▊        | 11/60 [08:20<36:50, 45.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.7256693840026855\n",
            "training loss: 6.899935722351074\n",
            "training loss: 6.621070384979248\n",
            "training loss: 6.804337501525879\n",
            "training loss: 7.085805892944336\n",
            "training loss: 6.930545806884766\n",
            "training loss: 7.048577308654785\n",
            "training loss: 6.80713415145874\n",
            "training loss: 6.894296646118164\n",
            "training loss: 7.026553630828857\n",
            "training loss: 6.72373104095459\n",
            "training loss: 6.8012614250183105\n",
            "training loss: 6.8858323097229\n",
            "training loss: 6.912664890289307\n",
            "training loss: 6.914728164672852\n",
            "training loss: 6.873037815093994\n",
            "training loss: 6.790626049041748\n",
            "training loss: 6.655348777770996\n",
            "training loss: 6.92713737487793\n",
            "training loss: 6.8724846839904785\n",
            "training loss: 6.837451457977295\n",
            "training loss: 6.71351432800293\n",
            "training loss: 6.739333629608154\n",
            "training loss: 6.800499439239502\n",
            "training loss: 6.689637184143066\n",
            "training loss: 6.671901702880859\n",
            "training loss: 7.000717639923096\n",
            "training loss: 6.808329105377197\n",
            "training loss: 6.821806907653809\n",
            "training loss: 6.777169227600098\n",
            "training loss: 6.762939929962158\n",
            "training loss: 6.8904619216918945\n",
            "training loss: 6.994746208190918\n",
            "training loss: 6.486138820648193\n",
            "training loss: 6.70493221282959\n",
            "training loss: 7.01911735534668\n",
            "training loss: 7.108298301696777\n",
            "training loss: 6.892910957336426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  20%|██        | 12/60 [09:06<36:05, 45.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.690526008605957\n",
            "training loss: 7.044301986694336\n",
            "training loss: 6.836570739746094\n",
            "training loss: 6.93068265914917\n",
            "training loss: 6.850343704223633\n",
            "training loss: 6.940708160400391\n",
            "training loss: 6.739358901977539\n",
            "training loss: 6.684942722320557\n",
            "training loss: 6.525216102600098\n",
            "training loss: 6.9450812339782715\n",
            "training loss: 6.908787727355957\n",
            "training loss: 6.681865215301514\n",
            "training loss: 6.84458065032959\n",
            "training loss: 7.114530086517334\n",
            "training loss: 6.679806232452393\n",
            "training loss: 6.804582595825195\n",
            "training loss: 6.786594390869141\n",
            "training loss: 6.6594109535217285\n",
            "training loss: 6.9531073570251465\n",
            "training loss: 7.047066688537598\n",
            "training loss: 6.847085475921631\n",
            "training loss: 6.872184753417969\n",
            "training loss: 7.14107608795166\n",
            "training loss: 6.685575485229492\n",
            "training loss: 6.679238319396973\n",
            "training loss: 6.749909400939941\n",
            "training loss: 6.598033428192139\n",
            "training loss: 6.575370788574219\n",
            "training loss: 6.762737274169922\n",
            "training loss: 6.771252632141113\n",
            "training loss: 6.646112442016602\n",
            "training loss: 6.803571701049805\n",
            "training loss: 6.953497409820557\n",
            "training loss: 6.664724826812744\n",
            "training loss: 6.931704521179199\n",
            "training loss: 6.90728235244751\n",
            "training loss: 6.503791809082031\n",
            "training loss: 6.53653621673584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  22%|██▏       | 13/60 [09:51<35:17, 45.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.091682434082031\n",
            "training loss: 6.962334156036377\n",
            "training loss: 7.0890045166015625\n",
            "training loss: 7.012026309967041\n",
            "training loss: 6.671747207641602\n",
            "training loss: 6.897180557250977\n",
            "training loss: 6.95937442779541\n",
            "training loss: 6.854462623596191\n",
            "training loss: 6.548069000244141\n",
            "training loss: 6.636222839355469\n",
            "training loss: 6.635507583618164\n",
            "training loss: 6.520116329193115\n",
            "training loss: 6.618783473968506\n",
            "training loss: 6.734622001647949\n",
            "training loss: 6.8204345703125\n",
            "training loss: 6.916534423828125\n",
            "training loss: 6.694574356079102\n",
            "training loss: 6.787472724914551\n",
            "training loss: 6.551355361938477\n",
            "training loss: 6.656667709350586\n",
            "training loss: 6.692644119262695\n",
            "training loss: 6.699233055114746\n",
            "training loss: 6.660595417022705\n",
            "training loss: 6.647570610046387\n",
            "training loss: 6.521396636962891\n",
            "training loss: 6.7999162673950195\n",
            "training loss: 6.626842498779297\n",
            "training loss: 6.752397537231445\n",
            "training loss: 6.7770795822143555\n",
            "training loss: 6.6331787109375\n",
            "training loss: 6.79017448425293\n",
            "training loss: 6.58615779876709\n",
            "training loss: 6.92963171005249\n",
            "training loss: 6.81331205368042\n",
            "training loss: 6.668769836425781\n",
            "training loss: 6.915715217590332\n",
            "training loss: 6.81041145324707\n",
            "training loss: 6.883114814758301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  23%|██▎       | 14/60 [10:38<35:02, 45.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.968931674957275\n",
            "training loss: 6.873721599578857\n",
            "training loss: 7.066956996917725\n",
            "training loss: 6.902986526489258\n",
            "training loss: 6.802137851715088\n",
            "training loss: 6.814634799957275\n",
            "training loss: 6.655749797821045\n",
            "training loss: 6.808599948883057\n",
            "training loss: 6.795665264129639\n",
            "training loss: 6.704015254974365\n",
            "training loss: 6.727385520935059\n",
            "training loss: 6.385973930358887\n",
            "training loss: 6.299144744873047\n",
            "training loss: 6.471284866333008\n",
            "training loss: 6.815187454223633\n",
            "training loss: 6.88966178894043\n",
            "training loss: 6.488885879516602\n",
            "training loss: 6.593727111816406\n",
            "training loss: 6.7651448249816895\n",
            "training loss: 6.782683372497559\n",
            "training loss: 6.88944149017334\n",
            "training loss: 6.635054588317871\n",
            "training loss: 6.614516258239746\n",
            "training loss: 6.719825744628906\n",
            "training loss: 6.829687118530273\n",
            "training loss: 6.727306842803955\n",
            "training loss: 6.618927001953125\n",
            "training loss: 6.6820478439331055\n",
            "training loss: 6.883394718170166\n",
            "training loss: 6.403048515319824\n",
            "training loss: 6.602896213531494\n",
            "training loss: 6.861306667327881\n",
            "training loss: 6.7422966957092285\n",
            "training loss: 6.897647857666016\n",
            "training loss: 6.886272430419922\n",
            "training loss: 6.809971332550049\n",
            "training loss: 6.8705596923828125\n",
            "training loss: 6.859035015106201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  25%|██▌       | 15/60 [11:23<34:13, 45.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.731813907623291\n",
            "training loss: 6.945179462432861\n",
            "training loss: 6.831301689147949\n",
            "training loss: 6.781647682189941\n",
            "training loss: 6.856778144836426\n",
            "training loss: 6.873205184936523\n",
            "training loss: 6.770059585571289\n",
            "training loss: 6.765913009643555\n",
            "training loss: 6.918858051300049\n",
            "training loss: 6.742215156555176\n",
            "training loss: 6.698734283447266\n",
            "training loss: 6.556015491485596\n",
            "training loss: 6.761224746704102\n",
            "training loss: 6.875030040740967\n",
            "training loss: 6.933487892150879\n",
            "training loss: 6.999879837036133\n",
            "training loss: 6.749363899230957\n",
            "training loss: 6.787798881530762\n",
            "training loss: 6.852547645568848\n",
            "training loss: 6.910277366638184\n",
            "training loss: 6.9862565994262695\n",
            "training loss: 6.957479476928711\n",
            "training loss: 6.952209949493408\n",
            "training loss: 6.96840238571167\n",
            "training loss: 6.789890289306641\n",
            "training loss: 7.024319648742676\n",
            "training loss: 6.884275436401367\n",
            "training loss: 6.686728477478027\n",
            "training loss: 6.659853935241699\n",
            "training loss: 6.568493366241455\n",
            "training loss: 6.7367939949035645\n",
            "training loss: 6.645298004150391\n",
            "training loss: 6.851142883300781\n",
            "training loss: 6.957008361816406\n",
            "training loss: 7.008857250213623\n",
            "training loss: 7.068694591522217\n",
            "training loss: 6.746242523193359\n",
            "training loss: 6.737349510192871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  27%|██▋       | 16/60 [12:09<33:27, 45.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.892141819000244\n",
            "training loss: 6.898037910461426\n",
            "training loss: 6.955338478088379\n",
            "training loss: 6.913980484008789\n",
            "training loss: 6.811832427978516\n",
            "training loss: 7.019308090209961\n",
            "training loss: 6.929873466491699\n",
            "training loss: 6.62099552154541\n",
            "training loss: 6.884947776794434\n",
            "training loss: 6.668268203735352\n",
            "training loss: 6.829154968261719\n",
            "training loss: 6.583988189697266\n",
            "training loss: 6.826509475708008\n",
            "training loss: 6.9780778884887695\n",
            "training loss: 6.609954833984375\n",
            "training loss: 6.835535526275635\n",
            "training loss: 6.328494071960449\n",
            "training loss: 6.850529193878174\n",
            "training loss: 7.1492509841918945\n",
            "training loss: 6.788554668426514\n",
            "training loss: 6.778800964355469\n",
            "training loss: 6.820412635803223\n",
            "training loss: 7.043923377990723\n",
            "training loss: 6.804178714752197\n",
            "training loss: 6.864809989929199\n",
            "training loss: 6.743414878845215\n",
            "training loss: 6.885470867156982\n",
            "training loss: 6.850679397583008\n",
            "training loss: 6.9261674880981445\n",
            "training loss: 6.636659622192383\n",
            "training loss: 6.930816650390625\n",
            "training loss: 6.704064846038818\n",
            "training loss: 6.641443252563477\n",
            "training loss: 6.5986328125\n",
            "training loss: 6.6492815017700195\n",
            "training loss: 7.021117210388184\n",
            "training loss: 6.644469261169434\n",
            "training loss: 6.82659912109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  28%|██▊       | 17/60 [12:54<32:41, 45.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.970058441162109\n",
            "training loss: 7.053046703338623\n",
            "training loss: 7.0315093994140625\n",
            "training loss: 7.098158836364746\n",
            "training loss: 6.727085113525391\n",
            "training loss: 6.693081378936768\n",
            "training loss: 6.858744144439697\n",
            "training loss: 6.682011604309082\n",
            "training loss: 6.539786338806152\n",
            "training loss: 6.770899772644043\n",
            "training loss: 6.790256500244141\n",
            "training loss: 7.175437927246094\n",
            "training loss: 6.924432754516602\n",
            "training loss: 6.906795978546143\n",
            "training loss: 6.789072036743164\n",
            "training loss: 6.927700996398926\n",
            "training loss: 6.921812534332275\n",
            "training loss: 6.902249336242676\n",
            "training loss: 6.958108901977539\n",
            "training loss: 6.940367221832275\n",
            "training loss: 7.013635635375977\n",
            "training loss: 6.855356216430664\n",
            "training loss: 6.919006824493408\n",
            "training loss: 6.559861183166504\n",
            "training loss: 6.754477500915527\n",
            "training loss: 6.385650157928467\n",
            "training loss: 6.857258319854736\n",
            "training loss: 6.860048294067383\n",
            "training loss: 6.68486213684082\n",
            "training loss: 6.532746315002441\n",
            "training loss: 6.80953311920166\n",
            "training loss: 6.928734302520752\n",
            "training loss: 6.698535919189453\n",
            "training loss: 6.528034210205078\n",
            "training loss: 6.66209602355957\n",
            "training loss: 6.621482849121094\n",
            "training loss: 6.654338836669922\n",
            "training loss: 6.469959735870361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  30%|███       | 18/60 [13:40<31:53, 45.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.92636775970459\n",
            "training loss: 6.817318916320801\n",
            "training loss: 6.849983215332031\n",
            "training loss: 6.600329399108887\n",
            "training loss: 6.843605041503906\n",
            "training loss: 6.9555864334106445\n",
            "training loss: 6.710012435913086\n",
            "training loss: 7.039972305297852\n",
            "training loss: 6.754624366760254\n",
            "training loss: 6.832015514373779\n",
            "training loss: 6.972047805786133\n",
            "training loss: 6.958072185516357\n",
            "training loss: 6.89703369140625\n",
            "training loss: 6.599977016448975\n",
            "training loss: 6.973348140716553\n",
            "training loss: 6.761888027191162\n",
            "training loss: 6.799160957336426\n",
            "training loss: 6.709564685821533\n",
            "training loss: 6.803631782531738\n",
            "training loss: 6.840977668762207\n",
            "training loss: 6.675032615661621\n",
            "training loss: 6.747535228729248\n",
            "training loss: 6.717433929443359\n",
            "training loss: 6.967095375061035\n",
            "training loss: 6.982973098754883\n",
            "training loss: 6.833616733551025\n",
            "training loss: 6.8897199630737305\n",
            "training loss: 6.825005054473877\n",
            "training loss: 6.951181411743164\n",
            "training loss: 6.830857276916504\n",
            "training loss: 6.9565019607543945\n",
            "training loss: 6.919214725494385\n",
            "training loss: 6.938014984130859\n",
            "training loss: 7.083388328552246\n",
            "training loss: 6.932117938995361\n",
            "training loss: 6.990942478179932\n",
            "training loss: 6.947486877441406\n",
            "training loss: 6.758310794830322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  32%|███▏      | 19/60 [14:27<31:27, 46.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.121973514556885\n",
            "training loss: 6.867563247680664\n",
            "training loss: 6.570977210998535\n",
            "training loss: 6.870001792907715\n",
            "training loss: 7.030805587768555\n",
            "training loss: 6.876002311706543\n",
            "training loss: 6.974182605743408\n",
            "training loss: 6.810172080993652\n",
            "training loss: 6.6493306159973145\n",
            "training loss: 6.749227523803711\n",
            "training loss: 6.784230709075928\n",
            "training loss: 6.81813383102417\n",
            "training loss: 6.666323661804199\n",
            "training loss: 6.747507572174072\n",
            "training loss: 6.4947919845581055\n",
            "training loss: 6.70427131652832\n",
            "training loss: 6.75535774230957\n",
            "training loss: 6.771969318389893\n",
            "training loss: 6.786454677581787\n",
            "training loss: 6.647789001464844\n",
            "training loss: 6.808115005493164\n",
            "training loss: 7.000065803527832\n",
            "training loss: 6.7766594886779785\n",
            "training loss: 6.734489440917969\n",
            "training loss: 6.779541969299316\n",
            "training loss: 6.698666572570801\n",
            "training loss: 6.525228977203369\n",
            "training loss: 6.856791019439697\n",
            "training loss: 6.939449310302734\n",
            "training loss: 6.752349853515625\n",
            "training loss: 6.8465046882629395\n",
            "training loss: 7.033278465270996\n",
            "training loss: 6.913959980010986\n",
            "training loss: 7.1374101638793945\n",
            "training loss: 6.851479530334473\n",
            "training loss: 6.846689224243164\n",
            "training loss: 6.963850975036621\n",
            "training loss: 6.9586262702941895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  33%|███▎      | 20/60 [15:13<30:40, 46.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.068419456481934\n",
            "training loss: 6.9697465896606445\n",
            "training loss: 6.997006893157959\n",
            "training loss: 7.02199125289917\n",
            "training loss: 7.080086708068848\n",
            "training loss: 6.957334995269775\n",
            "training loss: 6.622750759124756\n",
            "training loss: 6.897469520568848\n",
            "training loss: 6.951181411743164\n",
            "training loss: 6.80964469909668\n",
            "training loss: 6.971649169921875\n",
            "training loss: 6.963255405426025\n",
            "training loss: 6.778897762298584\n",
            "training loss: 6.816296577453613\n",
            "training loss: 6.927459239959717\n",
            "training loss: 6.825066566467285\n",
            "training loss: 7.015192985534668\n",
            "training loss: 6.856645107269287\n",
            "training loss: 7.10286808013916\n",
            "training loss: 7.154909133911133\n",
            "training loss: 7.026953220367432\n",
            "training loss: 6.798267364501953\n",
            "training loss: 6.877160549163818\n",
            "training loss: 6.911354064941406\n",
            "training loss: 6.670770645141602\n",
            "training loss: 6.720645904541016\n",
            "training loss: 6.400515556335449\n",
            "training loss: 6.64865779876709\n",
            "training loss: 6.622668743133545\n",
            "training loss: 6.828680038452148\n",
            "training loss: 6.423943996429443\n",
            "training loss: 6.999656677246094\n",
            "training loss: 7.169849395751953\n",
            "training loss: 6.759317398071289\n",
            "training loss: 6.874835968017578\n",
            "training loss: 6.776796817779541\n",
            "training loss: 6.86033821105957\n",
            "training loss: 6.6838202476501465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  35%|███▌      | 21/60 [15:58<29:49, 45.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.11181116104126\n",
            "training loss: 6.846688270568848\n",
            "training loss: 6.992051124572754\n",
            "training loss: 7.088254451751709\n",
            "training loss: 7.017731666564941\n",
            "training loss: 6.754378318786621\n",
            "training loss: 6.772132873535156\n",
            "training loss: 6.724016189575195\n",
            "training loss: 6.925736427307129\n",
            "training loss: 6.992748260498047\n",
            "training loss: 6.9493513107299805\n",
            "training loss: 7.012674808502197\n",
            "training loss: 6.882009983062744\n",
            "training loss: 6.6594462394714355\n",
            "training loss: 6.9562087059021\n",
            "training loss: 6.959914684295654\n",
            "training loss: 6.958280086517334\n",
            "training loss: 6.926923751831055\n",
            "training loss: 6.998667240142822\n",
            "training loss: 6.873941898345947\n",
            "training loss: 6.822182655334473\n",
            "training loss: 7.043364524841309\n",
            "training loss: 6.87165641784668\n",
            "training loss: 6.766049861907959\n",
            "training loss: 6.8548479080200195\n",
            "training loss: 6.889040946960449\n",
            "training loss: 6.803294658660889\n",
            "training loss: 6.840211391448975\n",
            "training loss: 6.9595417976379395\n",
            "training loss: 7.012715816497803\n",
            "training loss: 6.971614837646484\n",
            "training loss: 6.874312400817871\n",
            "training loss: 6.827698230743408\n",
            "training loss: 6.804371356964111\n",
            "training loss: 6.8719611167907715\n",
            "training loss: 6.750320911407471\n",
            "training loss: 6.834864616394043\n",
            "training loss: 6.777021408081055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  37%|███▋      | 22/60 [16:44<29:01, 45.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.972494602203369\n",
            "training loss: 7.139357566833496\n",
            "training loss: 7.008266448974609\n",
            "training loss: 7.0561113357543945\n",
            "training loss: 7.013668537139893\n",
            "training loss: 6.778532981872559\n",
            "training loss: 6.792055606842041\n",
            "training loss: 7.038131237030029\n",
            "training loss: 6.961915969848633\n",
            "training loss: 6.82961368560791\n",
            "training loss: 6.792481422424316\n",
            "training loss: 6.493990898132324\n",
            "training loss: 6.810362815856934\n",
            "training loss: 6.795879364013672\n",
            "training loss: 6.43088960647583\n",
            "training loss: 6.931445121765137\n",
            "training loss: 6.896454811096191\n",
            "training loss: 6.599337577819824\n",
            "training loss: 6.860062122344971\n",
            "training loss: 6.853127479553223\n",
            "training loss: 6.923922538757324\n",
            "training loss: 6.981241226196289\n",
            "training loss: 6.937855243682861\n",
            "training loss: 6.903875827789307\n",
            "training loss: 6.960937023162842\n",
            "training loss: 6.7072343826293945\n",
            "training loss: 6.7530412673950195\n",
            "training loss: 6.899454116821289\n",
            "training loss: 6.929662704467773\n",
            "training loss: 6.889918327331543\n",
            "training loss: 6.983304977416992\n",
            "training loss: 6.658946990966797\n",
            "training loss: 6.7253618240356445\n",
            "training loss: 6.9377241134643555\n",
            "training loss: 6.703854560852051\n",
            "training loss: 6.88286018371582\n",
            "training loss: 6.793797969818115\n",
            "training loss: 6.7307634353637695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  38%|███▊      | 23/60 [17:30<28:14, 45.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.199499607086182\n",
            "training loss: 6.866504192352295\n",
            "training loss: 6.617668151855469\n",
            "training loss: 6.963330268859863\n",
            "training loss: 6.875708103179932\n",
            "training loss: 6.802718162536621\n",
            "training loss: 7.062514305114746\n",
            "training loss: 7.091311454772949\n",
            "training loss: 6.548847198486328\n",
            "training loss: 7.089078903198242\n",
            "training loss: 6.86523962020874\n",
            "training loss: 6.867626667022705\n",
            "training loss: 6.883672714233398\n",
            "training loss: 6.760167121887207\n",
            "training loss: 6.881246089935303\n",
            "training loss: 6.413898468017578\n",
            "training loss: 6.601192474365234\n",
            "training loss: 6.875632286071777\n",
            "training loss: 6.705373287200928\n",
            "training loss: 6.597172737121582\n",
            "training loss: 6.648664474487305\n",
            "training loss: 6.522138595581055\n",
            "training loss: 6.567482948303223\n",
            "training loss: 6.787906169891357\n",
            "training loss: 6.856651306152344\n",
            "training loss: 6.6758856773376465\n",
            "training loss: 6.712767601013184\n",
            "training loss: 6.874711990356445\n",
            "training loss: 6.557489395141602\n",
            "training loss: 6.743903160095215\n",
            "training loss: 6.62106990814209\n",
            "training loss: 6.7994513511657715\n",
            "training loss: 6.986153602600098\n",
            "training loss: 6.960014343261719\n",
            "training loss: 7.051225662231445\n",
            "training loss: 6.940624713897705\n",
            "training loss: 6.895130634307861\n",
            "training loss: 6.816318511962891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  40%|████      | 24/60 [18:17<27:42, 46.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.227542877197266\n",
            "training loss: 7.369269371032715\n",
            "training loss: 7.2769646644592285\n",
            "training loss: 7.016892910003662\n",
            "training loss: 7.0605316162109375\n",
            "training loss: 7.028778553009033\n",
            "training loss: 7.184486389160156\n",
            "training loss: 7.048028945922852\n",
            "training loss: 6.904882431030273\n",
            "training loss: 7.044461250305176\n",
            "training loss: 6.850452899932861\n",
            "training loss: 6.8888959884643555\n",
            "training loss: 6.6100077629089355\n",
            "training loss: 6.565951347351074\n",
            "training loss: 6.831430912017822\n",
            "training loss: 6.79202127456665\n",
            "training loss: 6.92832088470459\n",
            "training loss: 6.908892631530762\n",
            "training loss: 6.942610740661621\n",
            "training loss: 6.877984523773193\n",
            "training loss: 6.901736259460449\n",
            "training loss: 6.905736446380615\n",
            "training loss: 6.873697757720947\n",
            "training loss: 6.663203239440918\n",
            "training loss: 6.678726673126221\n",
            "training loss: 6.832140922546387\n",
            "training loss: 6.695892333984375\n",
            "training loss: 6.643867492675781\n",
            "training loss: 6.713889122009277\n",
            "training loss: 6.604496955871582\n",
            "training loss: 6.740368843078613\n",
            "training loss: 6.714480400085449\n",
            "training loss: 6.735955238342285\n",
            "training loss: 6.919726371765137\n",
            "training loss: 6.90380334854126\n",
            "training loss: 6.774558067321777\n",
            "training loss: 6.669073104858398\n",
            "training loss: 6.6749138832092285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  42%|████▏     | 25/60 [19:03<26:51, 46.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.007665634155273\n",
            "training loss: 7.027242660522461\n",
            "training loss: 6.849948883056641\n",
            "training loss: 7.030841827392578\n",
            "training loss: 6.734046459197998\n",
            "training loss: 7.029674530029297\n",
            "training loss: 7.127051830291748\n",
            "training loss: 6.881989479064941\n",
            "training loss: 6.7659831047058105\n",
            "training loss: 6.948951244354248\n",
            "training loss: 6.747931480407715\n",
            "training loss: 6.989972114562988\n",
            "training loss: 6.877122402191162\n",
            "training loss: 6.717613220214844\n",
            "training loss: 6.735509395599365\n",
            "training loss: 6.84370231628418\n",
            "training loss: 6.831532955169678\n",
            "training loss: 6.871047019958496\n",
            "training loss: 6.917635917663574\n",
            "training loss: 6.808510780334473\n",
            "training loss: 6.814028739929199\n",
            "training loss: 6.997476577758789\n",
            "training loss: 6.876883506774902\n",
            "training loss: 6.898655891418457\n",
            "training loss: 6.565613746643066\n",
            "training loss: 6.559914588928223\n",
            "training loss: 6.710260391235352\n",
            "training loss: 6.714461326599121\n",
            "training loss: 6.765244483947754\n",
            "training loss: 6.781477928161621\n",
            "training loss: 6.872223854064941\n",
            "training loss: 6.824824333190918\n",
            "training loss: 6.7714362144470215\n",
            "training loss: 6.657509803771973\n",
            "training loss: 6.424880504608154\n",
            "training loss: 6.461026668548584\n",
            "training loss: 6.734627723693848\n",
            "training loss: 6.939379692077637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  43%|████▎     | 26/60 [19:48<25:58, 45.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.980547904968262\n",
            "training loss: 6.837255954742432\n",
            "training loss: 6.754097938537598\n",
            "training loss: 6.885218143463135\n",
            "training loss: 6.878586769104004\n",
            "training loss: 6.780972003936768\n",
            "training loss: 6.713320732116699\n",
            "training loss: 6.626438140869141\n",
            "training loss: 6.602710723876953\n",
            "training loss: 6.671553134918213\n",
            "training loss: 6.933245658874512\n",
            "training loss: 6.929400444030762\n",
            "training loss: 6.829934120178223\n",
            "training loss: 6.6412153244018555\n",
            "training loss: 6.69182825088501\n",
            "training loss: 6.93916654586792\n",
            "training loss: 6.818057060241699\n",
            "training loss: 6.861397743225098\n",
            "training loss: 6.701771259307861\n",
            "training loss: 6.715052127838135\n",
            "training loss: 6.729406356811523\n",
            "training loss: 6.658944606781006\n",
            "training loss: 6.902997016906738\n",
            "training loss: 6.952293872833252\n",
            "training loss: 6.874542236328125\n",
            "training loss: 7.086591720581055\n",
            "training loss: 6.789999008178711\n",
            "training loss: 6.8755035400390625\n",
            "training loss: 6.67317533493042\n",
            "training loss: 6.724173545837402\n",
            "training loss: 6.787289142608643\n",
            "training loss: 6.801307678222656\n",
            "training loss: 6.734643936157227\n",
            "training loss: 6.71571159362793\n",
            "training loss: 6.772538185119629\n",
            "training loss: 6.699240684509277\n",
            "training loss: 6.786007404327393\n",
            "training loss: 6.796639919281006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  45%|████▌     | 27/60 [20:33<25:08, 45.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.934345245361328\n",
            "training loss: 6.917420864105225\n",
            "training loss: 7.058665752410889\n",
            "training loss: 6.747150421142578\n",
            "training loss: 6.861330986022949\n",
            "training loss: 7.014536380767822\n",
            "training loss: 7.050825595855713\n",
            "training loss: 6.913643836975098\n",
            "training loss: 6.930006980895996\n",
            "training loss: 6.93690824508667\n",
            "training loss: 6.934239864349365\n",
            "training loss: 6.733522891998291\n",
            "training loss: 7.009497165679932\n",
            "training loss: 6.9420166015625\n",
            "training loss: 7.191382884979248\n",
            "training loss: 7.19824743270874\n",
            "training loss: 7.024604320526123\n",
            "training loss: 7.176676273345947\n",
            "training loss: 7.011536598205566\n",
            "training loss: 6.772850036621094\n",
            "training loss: 6.875816822052002\n",
            "training loss: 6.856369972229004\n",
            "training loss: 7.0225605964660645\n",
            "training loss: 7.073175430297852\n",
            "training loss: 6.832606315612793\n",
            "training loss: 6.659789562225342\n",
            "training loss: 6.793459892272949\n",
            "training loss: 6.931087493896484\n",
            "training loss: 6.734797477722168\n",
            "training loss: 6.762983322143555\n",
            "training loss: 6.704440116882324\n",
            "training loss: 6.853957176208496\n",
            "training loss: 6.976578712463379\n",
            "training loss: 6.5547308921813965\n",
            "training loss: 7.014373302459717\n",
            "training loss: 6.67274284362793\n",
            "training loss: 6.505512237548828\n",
            "training loss: 6.773468494415283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  47%|████▋     | 28/60 [21:19<24:18, 45.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9930806159973145\n",
            "training loss: 6.68887996673584\n",
            "training loss: 6.72783899307251\n",
            "training loss: 7.105206489562988\n",
            "training loss: 7.052713394165039\n",
            "training loss: 6.9526753425598145\n",
            "training loss: 6.857074737548828\n",
            "training loss: 6.936793804168701\n",
            "training loss: 6.584866523742676\n",
            "training loss: 6.717410564422607\n",
            "training loss: 6.7188825607299805\n",
            "training loss: 7.189762592315674\n",
            "training loss: 7.172756671905518\n",
            "training loss: 6.9468560218811035\n",
            "training loss: 6.903047561645508\n",
            "training loss: 6.988054275512695\n",
            "training loss: 6.812026023864746\n",
            "training loss: 6.91037654876709\n",
            "training loss: 6.849161148071289\n",
            "training loss: 6.674193382263184\n",
            "training loss: 6.931876182556152\n",
            "training loss: 6.80657958984375\n",
            "training loss: 6.831118583679199\n",
            "training loss: 6.879280090332031\n",
            "training loss: 7.01896333694458\n",
            "training loss: 6.840692520141602\n",
            "training loss: 6.464295387268066\n",
            "training loss: 6.672106742858887\n",
            "training loss: 6.787991523742676\n",
            "training loss: 6.6824631690979\n",
            "training loss: 6.80832052230835\n",
            "training loss: 6.6509599685668945\n",
            "training loss: 6.702541351318359\n",
            "training loss: 6.825997352600098\n",
            "training loss: 6.651878356933594\n",
            "training loss: 6.685119152069092\n",
            "training loss: 6.7559990882873535\n",
            "training loss: 6.6433329582214355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  48%|████▊     | 29/60 [22:04<23:29, 45.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.085411071777344\n",
            "training loss: 7.007406711578369\n",
            "training loss: 7.095555305480957\n",
            "training loss: 6.945134162902832\n",
            "training loss: 6.763009071350098\n",
            "training loss: 6.91019344329834\n",
            "training loss: 6.729281425476074\n",
            "training loss: 6.781976699829102\n",
            "training loss: 6.878025531768799\n",
            "training loss: 6.801668167114258\n",
            "training loss: 6.780455112457275\n",
            "training loss: 6.707632064819336\n",
            "training loss: 6.86306619644165\n",
            "training loss: 6.7573323249816895\n",
            "training loss: 6.833845615386963\n",
            "training loss: 6.840208530426025\n",
            "training loss: 6.999116897583008\n",
            "training loss: 6.716729164123535\n",
            "training loss: 6.885458946228027\n",
            "training loss: 6.861710548400879\n",
            "training loss: 6.848237991333008\n",
            "training loss: 6.598543643951416\n",
            "training loss: 6.4778852462768555\n",
            "training loss: 6.832572937011719\n",
            "training loss: 6.491189002990723\n",
            "training loss: 6.751909255981445\n",
            "training loss: 6.71849250793457\n",
            "training loss: 6.883721828460693\n",
            "training loss: 6.647684097290039\n",
            "training loss: 6.554445266723633\n",
            "training loss: 6.592464447021484\n",
            "training loss: 6.296488285064697\n",
            "training loss: 6.561405658721924\n",
            "training loss: 6.8111677169799805\n",
            "training loss: 6.890071868896484\n",
            "training loss: 6.678943634033203\n",
            "training loss: 6.646744728088379\n",
            "training loss: 6.687587738037109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  50%|█████     | 30/60 [22:51<22:58, 45.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.683835506439209\n",
            "training loss: 6.743326663970947\n",
            "training loss: 6.786556243896484\n",
            "training loss: 6.473556041717529\n",
            "training loss: 6.747782230377197\n",
            "training loss: 6.7887773513793945\n",
            "training loss: 6.470819473266602\n",
            "training loss: 6.7762908935546875\n",
            "training loss: 6.674113750457764\n",
            "training loss: 6.704207897186279\n",
            "training loss: 6.5515546798706055\n",
            "training loss: 6.775581359863281\n",
            "training loss: 6.652627944946289\n",
            "training loss: 6.747636795043945\n",
            "training loss: 6.665104389190674\n",
            "training loss: 6.5562357902526855\n",
            "training loss: 6.799558639526367\n",
            "training loss: 6.96550178527832\n",
            "training loss: 6.883288860321045\n",
            "training loss: 6.296144962310791\n",
            "training loss: 6.5819830894470215\n",
            "training loss: 6.614866733551025\n",
            "training loss: 6.5639848709106445\n",
            "training loss: 6.551514625549316\n",
            "training loss: 6.682626724243164\n",
            "training loss: 6.487369537353516\n",
            "training loss: 6.480538368225098\n",
            "training loss: 6.356064796447754\n",
            "training loss: 6.72018575668335\n",
            "training loss: 6.768064022064209\n",
            "training loss: 6.924216270446777\n",
            "training loss: 7.095561981201172\n",
            "training loss: 6.648244857788086\n",
            "training loss: 6.815171241760254\n",
            "training loss: 6.5865654945373535\n",
            "training loss: 6.708943843841553\n",
            "training loss: 6.952122688293457\n",
            "training loss: 6.9136061668396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  52%|█████▏    | 31/60 [23:37<22:08, 45.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.70701789855957\n",
            "training loss: 6.708139419555664\n",
            "training loss: 7.052096366882324\n",
            "training loss: 6.850091457366943\n",
            "training loss: 6.8515472412109375\n",
            "training loss: 6.560055255889893\n",
            "training loss: 6.7974090576171875\n",
            "training loss: 6.62650203704834\n",
            "training loss: 6.442910194396973\n",
            "training loss: 6.852076530456543\n",
            "training loss: 6.658753871917725\n",
            "training loss: 6.701901435852051\n",
            "training loss: 6.951814651489258\n",
            "training loss: 6.754408836364746\n",
            "training loss: 6.680286407470703\n",
            "training loss: 6.801328659057617\n",
            "training loss: 7.051225662231445\n",
            "training loss: 6.660491466522217\n",
            "training loss: 6.983423709869385\n",
            "training loss: 6.744423866271973\n",
            "training loss: 6.903264999389648\n",
            "training loss: 6.883598327636719\n",
            "training loss: 6.967724800109863\n",
            "training loss: 6.977583885192871\n",
            "training loss: 6.848321914672852\n",
            "training loss: 6.700210094451904\n",
            "training loss: 6.6253886222839355\n",
            "training loss: 6.647526741027832\n",
            "training loss: 6.693833351135254\n",
            "training loss: 6.910404682159424\n",
            "training loss: 6.6785759925842285\n",
            "training loss: 6.986239433288574\n",
            "training loss: 6.9591264724731445\n",
            "training loss: 7.054564952850342\n",
            "training loss: 6.904456615447998\n",
            "training loss: 6.9097900390625\n",
            "training loss: 6.859490394592285\n",
            "training loss: 6.889133453369141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  53%|█████▎    | 32/60 [24:22<21:22, 45.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9287285804748535\n",
            "training loss: 7.112066268920898\n",
            "training loss: 6.963013172149658\n",
            "training loss: 6.8890061378479\n",
            "training loss: 6.821324825286865\n",
            "training loss: 6.94786262512207\n",
            "training loss: 7.04097318649292\n",
            "training loss: 6.903249740600586\n",
            "training loss: 6.768686771392822\n",
            "training loss: 6.920213222503662\n",
            "training loss: 6.758356094360352\n",
            "training loss: 6.749529838562012\n",
            "training loss: 6.5192108154296875\n",
            "training loss: 6.586658477783203\n",
            "training loss: 6.686660289764404\n",
            "training loss: 6.492105960845947\n",
            "training loss: 6.75723123550415\n",
            "training loss: 6.357639789581299\n",
            "training loss: 6.677401542663574\n",
            "training loss: 6.63637113571167\n",
            "training loss: 6.837038040161133\n",
            "training loss: 6.818071365356445\n",
            "training loss: 6.935791969299316\n",
            "training loss: 6.958984375\n",
            "training loss: 6.963571548461914\n",
            "training loss: 7.271944046020508\n",
            "training loss: 7.084271430969238\n",
            "training loss: 6.962833881378174\n",
            "training loss: 6.88893461227417\n",
            "training loss: 6.687276363372803\n",
            "training loss: 6.432175636291504\n",
            "training loss: 6.49200963973999\n",
            "training loss: 6.669881820678711\n",
            "training loss: 6.77830171585083\n",
            "training loss: 7.173165798187256\n",
            "training loss: 6.785094261169434\n",
            "training loss: 6.734261512756348\n",
            "training loss: 6.601954936981201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  55%|█████▌    | 33/60 [25:08<20:36, 45.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.7804999351501465\n",
            "training loss: 6.8816070556640625\n",
            "training loss: 6.716559410095215\n",
            "training loss: 6.840807914733887\n",
            "training loss: 6.951757907867432\n",
            "training loss: 6.908575534820557\n",
            "training loss: 7.115070343017578\n",
            "training loss: 6.829700469970703\n",
            "training loss: 6.783844947814941\n",
            "training loss: 7.050289154052734\n",
            "training loss: 6.852725505828857\n",
            "training loss: 6.849778175354004\n",
            "training loss: 6.627501487731934\n",
            "training loss: 6.955693244934082\n",
            "training loss: 6.91240119934082\n",
            "training loss: 6.979672431945801\n",
            "training loss: 6.52856969833374\n",
            "training loss: 6.942220687866211\n",
            "training loss: 6.523028373718262\n",
            "training loss: 6.747713088989258\n",
            "training loss: 6.994846820831299\n",
            "training loss: 6.832077980041504\n",
            "training loss: 6.707734107971191\n",
            "training loss: 6.790949821472168\n",
            "training loss: 6.6554460525512695\n",
            "training loss: 6.679144382476807\n",
            "training loss: 6.800619602203369\n",
            "training loss: 6.630497932434082\n",
            "training loss: 6.641183853149414\n",
            "training loss: 6.64969539642334\n",
            "training loss: 6.758612632751465\n",
            "training loss: 7.02430534362793\n",
            "training loss: 6.798685073852539\n",
            "training loss: 6.911740779876709\n",
            "training loss: 6.700847625732422\n",
            "training loss: 6.821186065673828\n",
            "training loss: 6.54536247253418\n",
            "training loss: 6.772037506103516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  57%|█████▋    | 34/60 [25:54<19:49, 45.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.966711044311523\n",
            "training loss: 7.013848781585693\n",
            "training loss: 6.950074195861816\n",
            "training loss: 6.890866279602051\n",
            "training loss: 7.0068817138671875\n",
            "training loss: 6.786565780639648\n",
            "training loss: 6.765073299407959\n",
            "training loss: 6.994466781616211\n",
            "training loss: 6.930591106414795\n",
            "training loss: 6.73543119430542\n",
            "training loss: 6.864964008331299\n",
            "training loss: 7.016478538513184\n",
            "training loss: 6.8539042472839355\n",
            "training loss: 6.862965106964111\n",
            "training loss: 6.861280918121338\n",
            "training loss: 6.977138042449951\n",
            "training loss: 6.914889335632324\n",
            "training loss: 6.740185737609863\n",
            "training loss: 6.918570518493652\n",
            "training loss: 7.023462295532227\n",
            "training loss: 6.8035688400268555\n",
            "training loss: 6.7632646560668945\n",
            "training loss: 6.713349342346191\n",
            "training loss: 6.663658142089844\n",
            "training loss: 6.862995147705078\n",
            "training loss: 6.858443737030029\n",
            "training loss: 6.7885026931762695\n",
            "training loss: 6.80631160736084\n",
            "training loss: 6.881875991821289\n",
            "training loss: 6.882118225097656\n",
            "training loss: 6.927626609802246\n",
            "training loss: 6.859416961669922\n",
            "training loss: 6.692845344543457\n",
            "training loss: 6.773190498352051\n",
            "training loss: 6.865096092224121\n",
            "training loss: 6.69289493560791\n",
            "training loss: 6.659971237182617\n",
            "training loss: 6.804737091064453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  58%|█████▊    | 35/60 [26:40<19:06, 45.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.672133922576904\n",
            "training loss: 6.643571853637695\n",
            "training loss: 6.647491931915283\n",
            "training loss: 6.826595783233643\n",
            "training loss: 6.874412536621094\n",
            "training loss: 6.734643936157227\n",
            "training loss: 6.941755294799805\n",
            "training loss: 6.896108627319336\n",
            "training loss: 7.057120323181152\n",
            "training loss: 7.021714210510254\n",
            "training loss: 6.931737422943115\n",
            "training loss: 6.950732707977295\n",
            "training loss: 6.706484794616699\n",
            "training loss: 6.841907024383545\n",
            "training loss: 6.754990577697754\n",
            "training loss: 6.752811908721924\n",
            "training loss: 6.826625347137451\n",
            "training loss: 6.769858360290527\n",
            "training loss: 6.8849897384643555\n",
            "training loss: 6.7543416023254395\n",
            "training loss: 6.681036949157715\n",
            "training loss: 6.912942886352539\n",
            "training loss: 6.671344757080078\n",
            "training loss: 6.692107200622559\n",
            "training loss: 6.721718788146973\n",
            "training loss: 6.471715450286865\n",
            "training loss: 6.6051344871521\n",
            "training loss: 6.506546497344971\n",
            "training loss: 6.611166954040527\n",
            "training loss: 6.726034641265869\n",
            "training loss: 6.740996837615967\n",
            "training loss: 6.953283786773682\n",
            "training loss: 6.906846046447754\n",
            "training loss: 6.579452037811279\n",
            "training loss: 6.825085639953613\n",
            "training loss: 6.956228256225586\n",
            "training loss: 6.788432598114014\n",
            "training loss: 6.760815143585205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  60%|██████    | 36/60 [27:25<18:15, 45.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.062334060668945\n",
            "training loss: 6.4069976806640625\n",
            "training loss: 6.738360404968262\n",
            "training loss: 6.822524070739746\n",
            "training loss: 6.683297157287598\n",
            "training loss: 7.001412868499756\n",
            "training loss: 6.808695316314697\n",
            "training loss: 6.8598456382751465\n",
            "training loss: 6.758761882781982\n",
            "training loss: 6.902046203613281\n",
            "training loss: 6.906111240386963\n",
            "training loss: 6.904620170593262\n",
            "training loss: 6.617118835449219\n",
            "training loss: 6.716894149780273\n",
            "training loss: 6.969775199890137\n",
            "training loss: 6.564638614654541\n",
            "training loss: 6.4163713455200195\n",
            "training loss: 6.959871768951416\n",
            "training loss: 6.875002861022949\n",
            "training loss: 6.798608779907227\n",
            "training loss: 7.023468494415283\n",
            "training loss: 6.776725769042969\n",
            "training loss: 6.735323905944824\n",
            "training loss: 6.864041328430176\n",
            "training loss: 6.730116844177246\n",
            "training loss: 6.779249668121338\n",
            "training loss: 6.910282135009766\n",
            "training loss: 6.7153239250183105\n",
            "training loss: 6.707751274108887\n",
            "training loss: 6.670046806335449\n",
            "training loss: 6.375102519989014\n",
            "training loss: 6.477869510650635\n",
            "training loss: 6.897257328033447\n",
            "training loss: 7.151722431182861\n",
            "training loss: 7.316868782043457\n",
            "training loss: 7.140477180480957\n",
            "training loss: 6.960562705993652\n",
            "training loss: 6.827193260192871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  62%|██████▏   | 37/60 [28:10<17:27, 45.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.946121692657471\n",
            "training loss: 6.74671745300293\n",
            "training loss: 6.69073486328125\n",
            "training loss: 6.914317607879639\n",
            "training loss: 6.537485122680664\n",
            "training loss: 6.949707508087158\n",
            "training loss: 7.035577774047852\n",
            "training loss: 6.986106872558594\n",
            "training loss: 6.882530212402344\n",
            "training loss: 6.863786697387695\n",
            "training loss: 6.985378265380859\n",
            "training loss: 6.8767595291137695\n",
            "training loss: 6.5634846687316895\n",
            "training loss: 6.528192520141602\n",
            "training loss: 6.872715473175049\n",
            "training loss: 6.592001438140869\n",
            "training loss: 6.7795820236206055\n",
            "training loss: 6.795313358306885\n",
            "training loss: 6.497567653656006\n",
            "training loss: 7.041094779968262\n",
            "training loss: 7.033516883850098\n",
            "training loss: 7.088103771209717\n",
            "training loss: 6.880224704742432\n",
            "training loss: 6.8603739738464355\n",
            "training loss: 6.788443088531494\n",
            "training loss: 6.855069160461426\n",
            "training loss: 6.8876495361328125\n",
            "training loss: 6.885330677032471\n",
            "training loss: 6.839653491973877\n",
            "training loss: 6.775975227355957\n",
            "training loss: 6.8234543800354\n",
            "training loss: 6.963921546936035\n",
            "training loss: 6.994248390197754\n",
            "training loss: 6.777095794677734\n",
            "training loss: 6.63758659362793\n",
            "training loss: 6.650145530700684\n",
            "training loss: 6.7403483390808105\n",
            "training loss: 6.718338489532471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  63%|██████▎   | 38/60 [28:55<16:38, 45.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.707435607910156\n",
            "training loss: 7.043688774108887\n",
            "training loss: 6.976550102233887\n",
            "training loss: 6.60974645614624\n",
            "training loss: 6.837243556976318\n",
            "training loss: 6.786779403686523\n",
            "training loss: 6.740820407867432\n",
            "training loss: 6.7654314041137695\n",
            "training loss: 6.654280185699463\n",
            "training loss: 6.66288423538208\n",
            "training loss: 6.7348504066467285\n",
            "training loss: 6.728387355804443\n",
            "training loss: 6.641110897064209\n",
            "training loss: 6.883612632751465\n",
            "training loss: 7.161268711090088\n",
            "training loss: 6.8256754875183105\n",
            "training loss: 6.898489952087402\n",
            "training loss: 6.892679214477539\n",
            "training loss: 6.912034511566162\n",
            "training loss: 6.932725429534912\n",
            "training loss: 6.956565856933594\n",
            "training loss: 7.026939392089844\n",
            "training loss: 7.0372514724731445\n",
            "training loss: 6.870881080627441\n",
            "training loss: 6.836158275604248\n",
            "training loss: 6.873821258544922\n",
            "training loss: 6.622889041900635\n",
            "training loss: 6.886851787567139\n",
            "training loss: 6.8051042556762695\n",
            "training loss: 6.754901885986328\n",
            "training loss: 6.441158771514893\n",
            "training loss: 6.7201666831970215\n",
            "training loss: 6.786968231201172\n",
            "training loss: 6.487504959106445\n",
            "training loss: 6.505373477935791\n",
            "training loss: 6.79569149017334\n",
            "training loss: 6.634092807769775\n",
            "training loss: 6.7006330490112305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  65%|██████▌   | 39/60 [29:40<15:51, 45.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.874622344970703\n",
            "training loss: 6.84942626953125\n",
            "training loss: 6.970041275024414\n",
            "training loss: 6.711609840393066\n",
            "training loss: 6.87952184677124\n",
            "training loss: 6.923717498779297\n",
            "training loss: 6.97670316696167\n",
            "training loss: 6.793140411376953\n",
            "training loss: 6.904559135437012\n",
            "training loss: 6.634022235870361\n",
            "training loss: 6.903097152709961\n",
            "training loss: 6.569068908691406\n",
            "training loss: 6.816646575927734\n",
            "training loss: 6.380892753601074\n",
            "training loss: 6.682163715362549\n",
            "training loss: 6.9212965965271\n",
            "training loss: 6.738300323486328\n",
            "training loss: 6.688669681549072\n",
            "training loss: 6.979950904846191\n",
            "training loss: 6.642602920532227\n",
            "training loss: 6.599311828613281\n",
            "training loss: 6.6947021484375\n",
            "training loss: 6.7765116691589355\n",
            "training loss: 6.76749849319458\n",
            "training loss: 6.920474529266357\n",
            "training loss: 7.037248611450195\n",
            "training loss: 7.210365295410156\n",
            "training loss: 6.895777702331543\n",
            "training loss: 6.867243766784668\n",
            "training loss: 6.960733413696289\n",
            "training loss: 6.815974712371826\n",
            "training loss: 6.710139274597168\n",
            "training loss: 6.708834648132324\n",
            "training loss: 6.675083637237549\n",
            "training loss: 6.559353351593018\n",
            "training loss: 6.939723968505859\n",
            "training loss: 6.797536849975586\n",
            "training loss: 6.569569110870361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  67%|██████▋   | 40/60 [30:25<15:03, 45.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.66429328918457\n",
            "training loss: 6.826988220214844\n",
            "training loss: 6.754167079925537\n",
            "training loss: 6.820252895355225\n",
            "training loss: 6.62877893447876\n",
            "training loss: 6.833380699157715\n",
            "training loss: 6.756765365600586\n",
            "training loss: 7.152774333953857\n",
            "training loss: 6.82370662689209\n",
            "training loss: 7.0422258377075195\n",
            "training loss: 6.971214294433594\n",
            "training loss: 6.974381446838379\n",
            "training loss: 7.122184753417969\n",
            "training loss: 6.8299946784973145\n",
            "training loss: 6.918613433837891\n",
            "training loss: 6.508155822753906\n",
            "training loss: 6.391045570373535\n",
            "training loss: 6.635087966918945\n",
            "training loss: 6.847473621368408\n",
            "training loss: 6.675713062286377\n",
            "training loss: 6.954195976257324\n",
            "training loss: 6.889895439147949\n",
            "training loss: 7.104037284851074\n",
            "training loss: 6.736512660980225\n",
            "training loss: 6.722622871398926\n",
            "training loss: 6.970755577087402\n",
            "training loss: 6.793542861938477\n",
            "training loss: 6.887713432312012\n",
            "training loss: 6.780967712402344\n",
            "training loss: 6.862940788269043\n",
            "training loss: 6.555608749389648\n",
            "training loss: 6.760684013366699\n",
            "training loss: 6.702362060546875\n",
            "training loss: 6.856825828552246\n",
            "training loss: 6.695947170257568\n",
            "training loss: 6.489294052124023\n",
            "training loss: 6.869510173797607\n",
            "training loss: 6.971402645111084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  68%|██████▊   | 41/60 [31:12<14:28, 45.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.971856117248535\n",
            "training loss: 6.935060024261475\n",
            "training loss: 7.028018474578857\n",
            "training loss: 6.721705436706543\n",
            "training loss: 6.698345184326172\n",
            "training loss: 6.872567176818848\n",
            "training loss: 6.937856674194336\n",
            "training loss: 6.971989631652832\n",
            "training loss: 6.571497917175293\n",
            "training loss: 6.878663539886475\n",
            "training loss: 6.7787909507751465\n",
            "training loss: 6.748638153076172\n",
            "training loss: 6.809262275695801\n",
            "training loss: 6.732861518859863\n",
            "training loss: 6.766142845153809\n",
            "training loss: 6.650999546051025\n",
            "training loss: 6.795815467834473\n",
            "training loss: 6.526907444000244\n",
            "training loss: 6.836946964263916\n",
            "training loss: 6.5188798904418945\n",
            "training loss: 6.7975335121154785\n",
            "training loss: 6.95991325378418\n",
            "training loss: 6.973689079284668\n",
            "training loss: 6.758189678192139\n",
            "training loss: 6.786066055297852\n",
            "training loss: 6.775884628295898\n",
            "training loss: 6.829153060913086\n",
            "training loss: 6.630722999572754\n",
            "training loss: 6.54742431640625\n",
            "training loss: 6.744696140289307\n",
            "training loss: 6.7153239250183105\n",
            "training loss: 6.757559776306152\n",
            "training loss: 6.844725131988525\n",
            "training loss: 6.591917991638184\n",
            "training loss: 6.829474449157715\n",
            "training loss: 6.918537139892578\n",
            "training loss: 6.691013336181641\n",
            "training loss: 6.595409393310547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  70%|███████   | 42/60 [31:57<13:38, 45.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.887002468109131\n",
            "training loss: 6.899417877197266\n",
            "training loss: 6.882851600646973\n",
            "training loss: 6.920444965362549\n",
            "training loss: 6.750883102416992\n",
            "training loss: 6.853710174560547\n",
            "training loss: 6.870447158813477\n",
            "training loss: 6.831563949584961\n",
            "training loss: 6.87589693069458\n",
            "training loss: 6.793581962585449\n",
            "training loss: 6.799180030822754\n",
            "training loss: 6.577428817749023\n",
            "training loss: 6.883057594299316\n",
            "training loss: 6.800319194793701\n",
            "training loss: 6.8968658447265625\n",
            "training loss: 6.9026689529418945\n",
            "training loss: 6.867514610290527\n",
            "training loss: 6.686426162719727\n",
            "training loss: 6.6575822830200195\n",
            "training loss: 6.744716644287109\n",
            "training loss: 6.76984977722168\n",
            "training loss: 6.9327778816223145\n",
            "training loss: 6.930221080780029\n",
            "training loss: 7.0230207443237305\n",
            "training loss: 6.625628471374512\n",
            "training loss: 6.507763385772705\n",
            "training loss: 6.709113597869873\n",
            "training loss: 6.885255336761475\n",
            "training loss: 6.869056701660156\n",
            "training loss: 6.795700550079346\n",
            "training loss: 7.159306526184082\n",
            "training loss: 6.86440896987915\n",
            "training loss: 6.614290237426758\n",
            "training loss: 7.02780818939209\n",
            "training loss: 6.952428340911865\n",
            "training loss: 6.855999946594238\n",
            "training loss: 6.772274494171143\n",
            "training loss: 6.688886642456055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  72%|███████▏  | 43/60 [32:42<12:50, 45.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.788884162902832\n",
            "training loss: 6.813929557800293\n",
            "training loss: 6.939623832702637\n",
            "training loss: 7.024583339691162\n",
            "training loss: 6.792975425720215\n",
            "training loss: 6.999519348144531\n",
            "training loss: 6.783118724822998\n",
            "training loss: 6.632228374481201\n",
            "training loss: 6.790388107299805\n",
            "training loss: 6.895185947418213\n",
            "training loss: 7.055079460144043\n",
            "training loss: 6.715983867645264\n",
            "training loss: 6.930047512054443\n",
            "training loss: 6.92769193649292\n",
            "training loss: 6.884069442749023\n",
            "training loss: 6.739590167999268\n",
            "training loss: 6.8156609535217285\n",
            "training loss: 6.81300163269043\n",
            "training loss: 6.749888896942139\n",
            "training loss: 6.940107822418213\n",
            "training loss: 7.006683349609375\n",
            "training loss: 6.559800148010254\n",
            "training loss: 6.788941383361816\n",
            "training loss: 6.967978477478027\n",
            "training loss: 7.019843101501465\n",
            "training loss: 6.8167924880981445\n",
            "training loss: 6.678452491760254\n",
            "training loss: 6.715136528015137\n",
            "training loss: 6.863299369812012\n",
            "training loss: 6.928281784057617\n",
            "training loss: 6.986660003662109\n",
            "training loss: 7.037896156311035\n",
            "training loss: 7.196295261383057\n",
            "training loss: 6.732367515563965\n",
            "training loss: 6.894643306732178\n",
            "training loss: 6.79409122467041\n",
            "training loss: 6.898065567016602\n",
            "training loss: 6.890824794769287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  73%|███████▎  | 44/60 [33:27<12:03, 45.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9273481369018555\n",
            "training loss: 7.140222549438477\n",
            "training loss: 7.019172191619873\n",
            "training loss: 6.905631065368652\n",
            "training loss: 6.808406829833984\n",
            "training loss: 6.881687164306641\n",
            "training loss: 6.987568378448486\n",
            "training loss: 7.030330657958984\n",
            "training loss: 6.880859851837158\n",
            "training loss: 6.8900933265686035\n",
            "training loss: 6.7830586433410645\n",
            "training loss: 6.8974761962890625\n",
            "training loss: 6.875280380249023\n",
            "training loss: 6.732481956481934\n",
            "training loss: 6.8417582511901855\n",
            "training loss: 6.709212779998779\n",
            "training loss: 6.755513668060303\n",
            "training loss: 6.809499263763428\n",
            "training loss: 6.925595760345459\n",
            "training loss: 6.864306449890137\n",
            "training loss: 6.793795108795166\n",
            "training loss: 6.97605562210083\n",
            "training loss: 6.717647552490234\n",
            "training loss: 6.74681282043457\n",
            "training loss: 6.776519775390625\n",
            "training loss: 6.813398361206055\n",
            "training loss: 6.876263618469238\n",
            "training loss: 6.883181095123291\n",
            "training loss: 6.7248921394348145\n",
            "training loss: 6.694334030151367\n",
            "training loss: 6.760426998138428\n",
            "training loss: 6.970320224761963\n",
            "training loss: 6.818536281585693\n",
            "training loss: 6.811020851135254\n",
            "training loss: 6.876907825469971\n",
            "training loss: 6.865877151489258\n",
            "training loss: 6.919064521789551\n",
            "training loss: 6.805141448974609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  75%|███████▌  | 45/60 [34:12<11:17, 45.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9597015380859375\n",
            "training loss: 6.9469780921936035\n",
            "training loss: 7.176295280456543\n",
            "training loss: 7.052920341491699\n",
            "training loss: 7.098300457000732\n",
            "training loss: 7.057559013366699\n",
            "training loss: 7.103285789489746\n",
            "training loss: 6.924739837646484\n",
            "training loss: 7.015944957733154\n",
            "training loss: 6.770981788635254\n",
            "training loss: 6.963789939880371\n",
            "training loss: 6.95395040512085\n",
            "training loss: 6.799931526184082\n",
            "training loss: 6.821760654449463\n",
            "training loss: 6.756133079528809\n",
            "training loss: 6.90587043762207\n",
            "training loss: 6.7845458984375\n",
            "training loss: 6.747313499450684\n",
            "training loss: 6.603904724121094\n",
            "training loss: 6.676714897155762\n",
            "training loss: 6.627628326416016\n",
            "training loss: 6.799466133117676\n",
            "training loss: 6.92694091796875\n",
            "training loss: 6.5855207443237305\n",
            "training loss: 6.8290557861328125\n",
            "training loss: 6.750948905944824\n",
            "training loss: 6.709109306335449\n",
            "training loss: 6.692539691925049\n",
            "training loss: 6.5845746994018555\n",
            "training loss: 6.731441497802734\n",
            "training loss: 6.650722503662109\n",
            "training loss: 6.672172546386719\n",
            "training loss: 6.87971305847168\n",
            "training loss: 6.961671352386475\n",
            "training loss: 6.795965671539307\n",
            "training loss: 6.744978904724121\n",
            "training loss: 6.726521968841553\n",
            "training loss: 6.625899314880371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  77%|███████▋  | 46/60 [34:58<10:36, 45.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.813659191131592\n",
            "training loss: 6.724727153778076\n",
            "training loss: 6.662839412689209\n",
            "training loss: 6.823057174682617\n",
            "training loss: 7.222757339477539\n",
            "training loss: 6.875147342681885\n",
            "training loss: 7.12968635559082\n",
            "training loss: 6.775007724761963\n",
            "training loss: 6.955637454986572\n",
            "training loss: 6.752840518951416\n",
            "training loss: 6.866530418395996\n",
            "training loss: 6.878908157348633\n",
            "training loss: 6.9425201416015625\n",
            "training loss: 6.882503509521484\n",
            "training loss: 6.934907913208008\n",
            "training loss: 6.935068130493164\n",
            "training loss: 7.003519058227539\n",
            "training loss: 6.7826247215271\n",
            "training loss: 6.69931173324585\n",
            "training loss: 7.077367305755615\n",
            "training loss: 6.880280017852783\n",
            "training loss: 6.71052360534668\n",
            "training loss: 6.768429756164551\n",
            "training loss: 6.7771525382995605\n",
            "training loss: 6.893584251403809\n",
            "training loss: 7.050032615661621\n",
            "training loss: 6.681125164031982\n",
            "training loss: 7.0691046714782715\n",
            "training loss: 6.922080993652344\n",
            "training loss: 6.860708236694336\n",
            "training loss: 6.835485458374023\n",
            "training loss: 7.082548141479492\n",
            "training loss: 6.688014984130859\n",
            "training loss: 6.823764324188232\n",
            "training loss: 6.922863483428955\n",
            "training loss: 6.902589797973633\n",
            "training loss: 6.91663932800293\n",
            "training loss: 6.807992458343506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  78%|███████▊  | 47/60 [35:43<09:49, 45.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.985414505004883\n",
            "training loss: 6.9807844161987305\n",
            "training loss: 6.9339280128479\n",
            "training loss: 6.7326579093933105\n",
            "training loss: 6.880020618438721\n",
            "training loss: 7.025740623474121\n",
            "training loss: 6.9134135246276855\n",
            "training loss: 6.94951057434082\n",
            "training loss: 6.72886848449707\n",
            "training loss: 6.787585258483887\n",
            "training loss: 6.816003799438477\n",
            "training loss: 6.863408088684082\n",
            "training loss: 6.829242706298828\n",
            "training loss: 6.987724304199219\n",
            "training loss: 6.885061264038086\n",
            "training loss: 7.031763076782227\n",
            "training loss: 7.030865669250488\n",
            "training loss: 7.110639572143555\n",
            "training loss: 7.0990447998046875\n",
            "training loss: 6.95745849609375\n",
            "training loss: 6.669373035430908\n",
            "training loss: 6.792352676391602\n",
            "training loss: 7.041839599609375\n",
            "training loss: 6.859330654144287\n",
            "training loss: 6.838155746459961\n",
            "training loss: 6.829251766204834\n",
            "training loss: 6.823137283325195\n",
            "training loss: 6.769282341003418\n",
            "training loss: 6.881542682647705\n",
            "training loss: 6.583855628967285\n",
            "training loss: 6.810345649719238\n",
            "training loss: 6.732640266418457\n",
            "training loss: 6.582425594329834\n",
            "training loss: 6.889486312866211\n",
            "training loss: 6.8321733474731445\n",
            "training loss: 6.7202863693237305\n",
            "training loss: 6.864749908447266\n",
            "training loss: 6.5796003341674805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  80%|████████  | 48/60 [36:28<09:03, 45.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.617548942565918\n",
            "training loss: 6.915220737457275\n",
            "training loss: 6.750858306884766\n",
            "training loss: 7.043184757232666\n",
            "training loss: 6.9700775146484375\n",
            "training loss: 6.747428894042969\n",
            "training loss: 6.819566249847412\n",
            "training loss: 6.7621750831604\n",
            "training loss: 6.943421363830566\n",
            "training loss: 6.857110977172852\n",
            "training loss: 6.931509017944336\n",
            "training loss: 6.77047872543335\n",
            "training loss: 6.713770389556885\n",
            "training loss: 6.648604393005371\n",
            "training loss: 6.80102014541626\n",
            "training loss: 6.767567157745361\n",
            "training loss: 6.798944473266602\n",
            "training loss: 6.765817165374756\n",
            "training loss: 6.906838893890381\n",
            "training loss: 6.878876686096191\n",
            "training loss: 6.7204766273498535\n",
            "training loss: 6.728329658508301\n",
            "training loss: 7.016317367553711\n",
            "training loss: 6.714211463928223\n",
            "training loss: 6.7887163162231445\n",
            "training loss: 6.560492515563965\n",
            "training loss: 6.704232215881348\n",
            "training loss: 6.7326555252075195\n",
            "training loss: 6.9978485107421875\n",
            "training loss: 6.949411392211914\n",
            "training loss: 6.659707546234131\n",
            "training loss: 6.854382038116455\n",
            "training loss: 6.9221391677856445\n",
            "training loss: 6.689026832580566\n",
            "training loss: 6.818366050720215\n",
            "training loss: 6.8610453605651855\n",
            "training loss: 6.722395420074463\n",
            "training loss: 6.837166786193848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  82%|████████▏ | 49/60 [37:13<08:16, 45.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.973657608032227\n",
            "training loss: 6.858259201049805\n",
            "training loss: 6.735548496246338\n",
            "training loss: 6.801502227783203\n",
            "training loss: 6.914092063903809\n",
            "training loss: 7.019191741943359\n",
            "training loss: 6.972993850708008\n",
            "training loss: 6.774584770202637\n",
            "training loss: 6.878365516662598\n",
            "training loss: 6.887612819671631\n",
            "training loss: 6.951210975646973\n",
            "training loss: 6.7949395179748535\n",
            "training loss: 6.750025749206543\n",
            "training loss: 6.965892791748047\n",
            "training loss: 6.779019355773926\n",
            "training loss: 6.9020676612854\n",
            "training loss: 6.759128570556641\n",
            "training loss: 6.808337211608887\n",
            "training loss: 6.920501708984375\n",
            "training loss: 6.720554828643799\n",
            "training loss: 6.805470943450928\n",
            "training loss: 6.661004543304443\n",
            "training loss: 6.637083530426025\n",
            "training loss: 6.692992210388184\n",
            "training loss: 6.850744247436523\n",
            "training loss: 6.583793640136719\n",
            "training loss: 6.7017412185668945\n",
            "training loss: 6.583162307739258\n",
            "training loss: 6.836071968078613\n",
            "training loss: 6.700214862823486\n",
            "training loss: 6.691856861114502\n",
            "training loss: 6.774075508117676\n",
            "training loss: 6.816692352294922\n",
            "training loss: 6.470392227172852\n",
            "training loss: 6.712986946105957\n",
            "training loss: 6.590853214263916\n",
            "training loss: 6.786445140838623\n",
            "training loss: 6.754940986633301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  83%|████████▎ | 50/60 [37:58<07:31, 45.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.118099689483643\n",
            "training loss: 7.157649517059326\n",
            "training loss: 7.031292915344238\n",
            "training loss: 6.971976280212402\n",
            "training loss: 6.874509334564209\n",
            "training loss: 6.948801040649414\n",
            "training loss: 6.8173441886901855\n",
            "training loss: 7.068626880645752\n",
            "training loss: 6.800326347351074\n",
            "training loss: 6.9001264572143555\n",
            "training loss: 6.608641624450684\n",
            "training loss: 6.660823345184326\n",
            "training loss: 6.760529041290283\n",
            "training loss: 6.627899169921875\n",
            "training loss: 6.754018783569336\n",
            "training loss: 6.752533435821533\n",
            "training loss: 6.600854396820068\n",
            "training loss: 6.852756500244141\n",
            "training loss: 6.686408996582031\n",
            "training loss: 6.567929744720459\n",
            "training loss: 6.617177963256836\n",
            "training loss: 6.842311859130859\n",
            "training loss: 6.727612018585205\n",
            "training loss: 6.677058219909668\n",
            "training loss: 6.736153602600098\n",
            "training loss: 6.605854034423828\n",
            "training loss: 6.703823089599609\n",
            "training loss: 6.722185134887695\n",
            "training loss: 6.33219051361084\n",
            "training loss: 6.681979656219482\n",
            "training loss: 6.392587184906006\n",
            "training loss: 6.783724784851074\n",
            "training loss: 6.4658966064453125\n",
            "training loss: 6.592624664306641\n",
            "training loss: 6.492252349853516\n",
            "training loss: 6.529753684997559\n",
            "training loss: 6.44896125793457\n",
            "training loss: 6.559675216674805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  85%|████████▌ | 51/60 [38:43<06:45, 45.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.110559463500977\n",
            "training loss: 6.670175075531006\n",
            "training loss: 6.523802280426025\n",
            "training loss: 6.626766204833984\n",
            "training loss: 6.978812217712402\n",
            "training loss: 6.792912006378174\n",
            "training loss: 6.715640544891357\n",
            "training loss: 6.80654764175415\n",
            "training loss: 6.855187892913818\n",
            "training loss: 6.974751949310303\n",
            "training loss: 6.584571361541748\n",
            "training loss: 6.628264904022217\n",
            "training loss: 6.8603434562683105\n",
            "training loss: 6.740993499755859\n",
            "training loss: 6.872963905334473\n",
            "training loss: 6.822726249694824\n",
            "training loss: 7.063266277313232\n",
            "training loss: 6.843981742858887\n",
            "training loss: 7.122602939605713\n",
            "training loss: 6.870221138000488\n",
            "training loss: 6.901059627532959\n",
            "training loss: 7.131059646606445\n",
            "training loss: 7.141022205352783\n",
            "training loss: 6.953647136688232\n",
            "training loss: 6.767202377319336\n",
            "training loss: 6.638894081115723\n",
            "training loss: 6.720344543457031\n",
            "training loss: 7.0195722579956055\n",
            "training loss: 6.807021141052246\n",
            "training loss: 6.748037338256836\n",
            "training loss: 6.648377418518066\n",
            "training loss: 6.972932815551758\n",
            "training loss: 6.924314498901367\n",
            "training loss: 6.8749895095825195\n",
            "training loss: 6.948844909667969\n",
            "training loss: 6.653040409088135\n",
            "training loss: 6.844465732574463\n",
            "training loss: 6.709202289581299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  87%|████████▋ | 52/60 [39:30<06:04, 45.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.902923583984375\n",
            "training loss: 6.89597749710083\n",
            "training loss: 6.969753265380859\n",
            "training loss: 6.82275390625\n",
            "training loss: 6.865698337554932\n",
            "training loss: 7.0327348709106445\n",
            "training loss: 6.827754020690918\n",
            "training loss: 6.544930458068848\n",
            "training loss: 6.995575904846191\n",
            "training loss: 6.971026420593262\n",
            "training loss: 6.9148969650268555\n",
            "training loss: 6.728827953338623\n",
            "training loss: 6.858211517333984\n",
            "training loss: 6.977209091186523\n",
            "training loss: 6.809359550476074\n",
            "training loss: 7.110166549682617\n",
            "training loss: 6.92780876159668\n",
            "training loss: 6.904409408569336\n",
            "training loss: 6.719881534576416\n",
            "training loss: 6.78089714050293\n",
            "training loss: 6.82279109954834\n",
            "training loss: 6.8852033615112305\n",
            "training loss: 6.684919357299805\n",
            "training loss: 6.888938903808594\n",
            "training loss: 6.949856281280518\n",
            "training loss: 6.923384666442871\n",
            "training loss: 6.862636089324951\n",
            "training loss: 6.70736026763916\n",
            "training loss: 6.727116584777832\n",
            "training loss: 6.794552803039551\n",
            "training loss: 6.5728912353515625\n",
            "training loss: 6.647704124450684\n",
            "training loss: 6.839548110961914\n",
            "training loss: 6.78084659576416\n",
            "training loss: 6.928040027618408\n",
            "training loss: 6.855742931365967\n",
            "training loss: 6.6982598304748535\n",
            "training loss: 6.8652544021606445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  88%|████████▊ | 53/60 [40:15<05:18, 45.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.951461315155029\n",
            "training loss: 7.027754783630371\n",
            "training loss: 6.9591569900512695\n",
            "training loss: 6.966836452484131\n",
            "training loss: 6.89692497253418\n",
            "training loss: 6.893034934997559\n",
            "training loss: 7.00095272064209\n",
            "training loss: 6.807736396789551\n",
            "training loss: 6.769506454467773\n",
            "training loss: 6.795984268188477\n",
            "training loss: 7.050800800323486\n",
            "training loss: 6.822410583496094\n",
            "training loss: 6.859209060668945\n",
            "training loss: 6.826371192932129\n",
            "training loss: 6.870299816131592\n",
            "training loss: 6.910599708557129\n",
            "training loss: 6.7163848876953125\n",
            "training loss: 6.890369415283203\n",
            "training loss: 6.768640041351318\n",
            "training loss: 6.882633209228516\n",
            "training loss: 7.0113091468811035\n",
            "training loss: 6.847721099853516\n",
            "training loss: 6.887470245361328\n",
            "training loss: 6.740046501159668\n",
            "training loss: 6.780829429626465\n",
            "training loss: 6.768240928649902\n",
            "training loss: 6.873979568481445\n",
            "training loss: 6.967532634735107\n",
            "training loss: 6.9155683517456055\n",
            "training loss: 6.948982238769531\n",
            "training loss: 6.8041181564331055\n",
            "training loss: 6.9438157081604\n",
            "training loss: 6.891696929931641\n",
            "training loss: 6.963746070861816\n",
            "training loss: 6.813141822814941\n",
            "training loss: 6.830624580383301\n",
            "training loss: 6.759662628173828\n",
            "training loss: 6.637070655822754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  90%|█████████ | 54/60 [41:00<04:31, 45.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.846948623657227\n",
            "training loss: 6.887091636657715\n",
            "training loss: 7.0627827644348145\n",
            "training loss: 7.011360168457031\n",
            "training loss: 6.865917205810547\n",
            "training loss: 6.701663970947266\n",
            "training loss: 6.526789665222168\n",
            "training loss: 6.649946689605713\n",
            "training loss: 6.64280366897583\n",
            "training loss: 6.871837615966797\n",
            "training loss: 6.902759552001953\n",
            "training loss: 7.1420488357543945\n",
            "training loss: 6.962609767913818\n",
            "training loss: 6.970417022705078\n",
            "training loss: 6.831542491912842\n",
            "training loss: 7.235081672668457\n",
            "training loss: 6.8823466300964355\n",
            "training loss: 6.838824272155762\n",
            "training loss: 6.7395429611206055\n",
            "training loss: 6.846704959869385\n",
            "training loss: 6.88810920715332\n",
            "training loss: 6.922257900238037\n",
            "training loss: 6.509995460510254\n",
            "training loss: 6.8555097579956055\n",
            "training loss: 6.86483097076416\n",
            "training loss: 7.037425518035889\n",
            "training loss: 6.906097412109375\n",
            "training loss: 6.8866353034973145\n",
            "training loss: 6.9453277587890625\n",
            "training loss: 7.000904560089111\n",
            "training loss: 7.132196426391602\n",
            "training loss: 7.071500778198242\n",
            "training loss: 6.905299186706543\n",
            "training loss: 6.851552486419678\n",
            "training loss: 6.935604095458984\n",
            "training loss: 6.699926853179932\n",
            "training loss: 6.6901373863220215\n",
            "training loss: 6.5415754318237305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  92%|█████████▏| 55/60 [41:45<03:45, 45.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.068469047546387\n",
            "training loss: 6.876943588256836\n",
            "training loss: 7.004773139953613\n",
            "training loss: 6.929475784301758\n",
            "training loss: 6.918821334838867\n",
            "training loss: 6.815303802490234\n",
            "training loss: 6.94235897064209\n",
            "training loss: 6.829309463500977\n",
            "training loss: 6.960188388824463\n",
            "training loss: 6.889681816101074\n",
            "training loss: 6.93927001953125\n",
            "training loss: 6.7560038566589355\n",
            "training loss: 6.943920135498047\n",
            "training loss: 6.844280242919922\n",
            "training loss: 6.855259895324707\n",
            "training loss: 6.674488067626953\n",
            "training loss: 6.619543075561523\n",
            "training loss: 6.744829177856445\n",
            "training loss: 6.744450569152832\n",
            "training loss: 6.789815902709961\n",
            "training loss: 6.903300762176514\n",
            "training loss: 6.543539524078369\n",
            "training loss: 6.606318473815918\n",
            "training loss: 6.8126020431518555\n",
            "training loss: 6.853569984436035\n",
            "training loss: 6.6396331787109375\n",
            "training loss: 6.897051811218262\n",
            "training loss: 7.072958469390869\n",
            "training loss: 6.7981719970703125\n",
            "training loss: 6.852126598358154\n",
            "training loss: 6.89404821395874\n",
            "training loss: 6.889953136444092\n",
            "training loss: 6.832389831542969\n",
            "training loss: 6.510324954986572\n",
            "training loss: 6.9451680183410645\n",
            "training loss: 6.824936866760254\n",
            "training loss: 7.071653366088867\n",
            "training loss: 6.892121315002441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  93%|█████████▎| 56/60 [42:30<03:00, 45.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.073652744293213\n",
            "training loss: 7.155233860015869\n",
            "training loss: 6.943603992462158\n",
            "training loss: 6.53639554977417\n",
            "training loss: 6.803352355957031\n",
            "training loss: 7.122109413146973\n",
            "training loss: 7.037439346313477\n",
            "training loss: 6.756228446960449\n",
            "training loss: 6.766476631164551\n",
            "training loss: 6.59189510345459\n",
            "training loss: 6.851833343505859\n",
            "training loss: 6.906070709228516\n",
            "training loss: 6.8242692947387695\n",
            "training loss: 6.539278030395508\n",
            "training loss: 6.619720458984375\n",
            "training loss: 6.612303733825684\n",
            "training loss: 6.4839253425598145\n",
            "training loss: 6.721149444580078\n",
            "training loss: 6.755562782287598\n",
            "training loss: 6.824957847595215\n",
            "training loss: 7.065441608428955\n",
            "training loss: 6.951920986175537\n",
            "training loss: 6.872983932495117\n",
            "training loss: 6.836102485656738\n",
            "training loss: 6.892301559448242\n",
            "training loss: 6.772241592407227\n",
            "training loss: 6.832876205444336\n",
            "training loss: 7.0599751472473145\n",
            "training loss: 6.98640251159668\n",
            "training loss: 6.779674530029297\n",
            "training loss: 6.713631629943848\n",
            "training loss: 6.865896701812744\n",
            "training loss: 6.8602190017700195\n",
            "training loss: 6.361976623535156\n",
            "training loss: 6.480819225311279\n",
            "training loss: 6.814360618591309\n",
            "training loss: 6.773509979248047\n",
            "training loss: 6.691964626312256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  95%|█████████▌| 57/60 [43:16<02:15, 45.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.074467182159424\n",
            "training loss: 7.159377574920654\n",
            "training loss: 6.8985595703125\n",
            "training loss: 7.068881511688232\n",
            "training loss: 7.011404991149902\n",
            "training loss: 6.762505531311035\n",
            "training loss: 6.813424110412598\n",
            "training loss: 6.769837379455566\n",
            "training loss: 6.841525077819824\n",
            "training loss: 6.833755016326904\n",
            "training loss: 6.979512691497803\n",
            "training loss: 6.766971111297607\n",
            "training loss: 6.798800468444824\n",
            "training loss: 6.824716091156006\n",
            "training loss: 6.493391036987305\n",
            "training loss: 6.633876800537109\n",
            "training loss: 6.703490734100342\n",
            "training loss: 6.73164701461792\n",
            "training loss: 6.484523773193359\n",
            "training loss: 6.60111141204834\n",
            "training loss: 6.941540718078613\n",
            "training loss: 6.681454658508301\n",
            "training loss: 6.76834774017334\n",
            "training loss: 6.688573837280273\n",
            "training loss: 6.857107639312744\n",
            "training loss: 6.929861545562744\n",
            "training loss: 6.892350673675537\n",
            "training loss: 7.017892837524414\n",
            "training loss: 6.867506980895996\n",
            "training loss: 6.576261520385742\n",
            "training loss: 6.76118278503418\n",
            "training loss: 6.635990142822266\n",
            "training loss: 6.806288719177246\n",
            "training loss: 6.757574081420898\n",
            "training loss: 6.91579008102417\n",
            "training loss: 6.774636745452881\n",
            "training loss: 6.68161678314209\n",
            "training loss: 6.74129581451416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  97%|█████████▋| 58/60 [44:00<01:29, 44.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9375152587890625\n",
            "training loss: 7.015294551849365\n",
            "training loss: 7.205571174621582\n",
            "training loss: 7.032907009124756\n",
            "training loss: 6.88265323638916\n",
            "training loss: 6.899496078491211\n",
            "training loss: 6.9494428634643555\n",
            "training loss: 6.751394271850586\n",
            "training loss: 6.970069885253906\n",
            "training loss: 7.044668197631836\n",
            "training loss: 7.075357437133789\n",
            "training loss: 7.007778167724609\n",
            "training loss: 7.267297744750977\n",
            "training loss: 7.041871070861816\n",
            "training loss: 6.9662322998046875\n",
            "training loss: 6.958300590515137\n",
            "training loss: 6.831328392028809\n",
            "training loss: 6.865293979644775\n",
            "training loss: 6.927138328552246\n",
            "training loss: 6.862851142883301\n",
            "training loss: 6.722817897796631\n",
            "training loss: 6.812137603759766\n",
            "training loss: 6.739640235900879\n",
            "training loss: 6.602202415466309\n",
            "training loss: 6.751617431640625\n",
            "training loss: 6.8367767333984375\n",
            "training loss: 6.714827060699463\n",
            "training loss: 6.817465782165527\n",
            "training loss: 6.701075553894043\n",
            "training loss: 7.009490966796875\n",
            "training loss: 6.683579444885254\n",
            "training loss: 6.726235389709473\n",
            "training loss: 6.981079578399658\n",
            "training loss: 6.7482194900512695\n",
            "training loss: 6.836543083190918\n",
            "training loss: 6.788031578063965\n",
            "training loss: 6.718855857849121\n",
            "training loss: 6.927798748016357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  98%|█████████▊| 59/60 [44:45<00:44, 44.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.2043070793151855\n",
            "training loss: 6.921441078186035\n",
            "training loss: 7.039498329162598\n",
            "training loss: 6.9980316162109375\n",
            "training loss: 7.00398063659668\n",
            "training loss: 6.757467269897461\n",
            "training loss: 6.660848140716553\n",
            "training loss: 6.853983402252197\n",
            "training loss: 6.741368770599365\n",
            "training loss: 6.905227184295654\n",
            "training loss: 6.806404113769531\n",
            "training loss: 6.756591796875\n",
            "training loss: 6.55859375\n",
            "training loss: 6.875646591186523\n",
            "training loss: 6.783670425415039\n",
            "training loss: 6.888365745544434\n",
            "training loss: 6.765350341796875\n",
            "training loss: 6.646646022796631\n",
            "training loss: 6.496081352233887\n",
            "training loss: 6.837876319885254\n",
            "training loss: 6.892928123474121\n",
            "training loss: 6.619265079498291\n",
            "training loss: 6.7116851806640625\n",
            "training loss: 6.606154441833496\n",
            "training loss: 6.919314384460449\n",
            "training loss: 6.647457599639893\n",
            "training loss: 6.835141181945801\n",
            "training loss: 6.891315460205078\n",
            "training loss: 6.6789984703063965\n",
            "training loss: 6.74368143081665\n",
            "training loss: 6.803324222564697\n",
            "training loss: 6.761423587799072\n",
            "training loss: 6.849491596221924\n",
            "training loss: 6.8846282958984375\n",
            "training loss: 6.867119789123535\n",
            "training loss: 6.73446798324585\n",
            "training loss: 7.035898685455322\n",
            "training loss: 7.076390743255615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training: 100%|██████████| 60/60 [45:30<00:00, 45.51s/it]\n",
            "evaluation: 100%|██████████| 7/7 [03:21<00:00, 28.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 559.738037109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "training:   0%|          | 0/60 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.653079986572266\n",
            "training loss: 6.787682056427002\n",
            "training loss: 6.872834205627441\n",
            "training loss: 6.673317909240723\n",
            "training loss: 6.912899017333984\n",
            "training loss: 6.904175758361816\n",
            "training loss: 6.871979713439941\n",
            "training loss: 7.179072380065918\n",
            "training loss: 6.674527645111084\n",
            "training loss: 6.482403755187988\n",
            "training loss: 6.565899848937988\n",
            "training loss: 6.495768070220947\n",
            "training loss: 6.619516372680664\n",
            "training loss: 6.5719146728515625\n",
            "training loss: 6.645482063293457\n",
            "training loss: 6.847848892211914\n",
            "training loss: 6.412771224975586\n",
            "training loss: 6.7937188148498535\n",
            "training loss: 6.820189952850342\n",
            "training loss: 6.787355899810791\n",
            "training loss: 6.724823951721191\n",
            "training loss: 6.735095977783203\n",
            "training loss: 6.9848856925964355\n",
            "training loss: 6.660101413726807\n",
            "training loss: 6.706350326538086\n",
            "training loss: 6.762573719024658\n",
            "training loss: 6.782638072967529\n",
            "training loss: 6.678197860717773\n",
            "training loss: 6.83082914352417\n",
            "training loss: 6.831427574157715\n",
            "training loss: 6.707024574279785\n",
            "training loss: 6.946494102478027\n",
            "training loss: 6.703888893127441\n",
            "training loss: 6.970699787139893\n",
            "training loss: 6.8842573165893555\n",
            "training loss: 6.909339904785156\n",
            "training loss: 6.757366180419922\n",
            "training loss: 6.756416320800781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   2%|▏         | 1/60 [00:47<46:46, 47.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.833198070526123\n",
            "training loss: 6.763937473297119\n",
            "training loss: 6.94110107421875\n",
            "training loss: 6.9604597091674805\n",
            "training loss: 7.025938034057617\n",
            "training loss: 7.082327842712402\n",
            "training loss: 6.849137306213379\n",
            "training loss: 6.834611892700195\n",
            "training loss: 6.953508377075195\n",
            "training loss: 6.736793041229248\n",
            "training loss: 6.616795539855957\n",
            "training loss: 6.661437034606934\n",
            "training loss: 6.728543281555176\n",
            "training loss: 6.5634002685546875\n",
            "training loss: 6.929542541503906\n",
            "training loss: 7.032196521759033\n",
            "training loss: 6.994663238525391\n",
            "training loss: 6.991954326629639\n",
            "training loss: 7.032307147979736\n",
            "training loss: 6.971778392791748\n",
            "training loss: 6.809737682342529\n",
            "training loss: 6.964596748352051\n",
            "training loss: 6.890809535980225\n",
            "training loss: 6.757460117340088\n",
            "training loss: 6.990269660949707\n",
            "training loss: 6.9970808029174805\n",
            "training loss: 6.978709697723389\n",
            "training loss: 6.943329811096191\n",
            "training loss: 6.870488166809082\n",
            "training loss: 6.869540214538574\n",
            "training loss: 6.588888645172119\n",
            "training loss: 6.633842468261719\n",
            "training loss: 6.721412658691406\n",
            "training loss: 6.769291877746582\n",
            "training loss: 6.778631210327148\n",
            "training loss: 6.698729515075684\n",
            "training loss: 6.885973930358887\n",
            "training loss: 6.614978313446045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   3%|▎         | 2/60 [01:32<44:39, 46.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.768133163452148\n",
            "training loss: 6.806388854980469\n",
            "training loss: 6.723967552185059\n",
            "training loss: 6.797856330871582\n",
            "training loss: 6.791291236877441\n",
            "training loss: 6.858336448669434\n",
            "training loss: 6.7440643310546875\n",
            "training loss: 6.749855995178223\n",
            "training loss: 6.7216949462890625\n",
            "training loss: 6.732501983642578\n",
            "training loss: 6.848714351654053\n",
            "training loss: 6.789186477661133\n",
            "training loss: 6.661854267120361\n",
            "training loss: 6.605360984802246\n",
            "training loss: 6.7165751457214355\n",
            "training loss: 6.706352233886719\n",
            "training loss: 6.8840155601501465\n",
            "training loss: 6.849134922027588\n",
            "training loss: 6.872912406921387\n",
            "training loss: 6.764340400695801\n",
            "training loss: 6.863811492919922\n",
            "training loss: 6.7892303466796875\n",
            "training loss: 6.687952041625977\n",
            "training loss: 6.67983865737915\n",
            "training loss: 6.546215534210205\n",
            "training loss: 6.539629936218262\n",
            "training loss: 6.796475887298584\n",
            "training loss: 6.74360466003418\n",
            "training loss: 6.499196529388428\n",
            "training loss: 6.543737411499023\n",
            "training loss: 6.1706085205078125\n",
            "training loss: 6.746234893798828\n",
            "training loss: 6.474575996398926\n",
            "training loss: 6.955912113189697\n",
            "training loss: 6.696641445159912\n",
            "training loss: 6.924078941345215\n",
            "training loss: 7.009793281555176\n",
            "training loss: 6.778810977935791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   5%|▌         | 3/60 [02:18<43:34, 45.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.770238399505615\n",
            "training loss: 6.858987808227539\n",
            "training loss: 6.851914405822754\n",
            "training loss: 6.8205885887146\n",
            "training loss: 6.76986026763916\n",
            "training loss: 6.794256687164307\n",
            "training loss: 6.9012451171875\n",
            "training loss: 6.9720540046691895\n",
            "training loss: 6.769385814666748\n",
            "training loss: 6.770417213439941\n",
            "training loss: 6.795413970947266\n",
            "training loss: 6.861664295196533\n",
            "training loss: 6.778550148010254\n",
            "training loss: 6.822231292724609\n",
            "training loss: 6.664423942565918\n",
            "training loss: 6.672680854797363\n",
            "training loss: 7.055049896240234\n",
            "training loss: 6.808541297912598\n",
            "training loss: 6.811357021331787\n",
            "training loss: 6.68910026550293\n",
            "training loss: 6.782374382019043\n",
            "training loss: 6.912490367889404\n",
            "training loss: 6.862113952636719\n",
            "training loss: 6.778697967529297\n",
            "training loss: 6.759936332702637\n",
            "training loss: 6.620957374572754\n",
            "training loss: 6.539538383483887\n",
            "training loss: 6.711192607879639\n",
            "training loss: 6.588675022125244\n",
            "training loss: 6.658809185028076\n",
            "training loss: 6.789950370788574\n",
            "training loss: 6.830002784729004\n",
            "training loss: 6.811506748199463\n",
            "training loss: 6.733403205871582\n",
            "training loss: 6.772336006164551\n",
            "training loss: 6.955787658691406\n",
            "training loss: 6.836549758911133\n",
            "training loss: 6.782918930053711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   7%|▋         | 4/60 [03:04<42:54, 45.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.053360462188721\n",
            "training loss: 6.893199920654297\n",
            "training loss: 7.188529968261719\n",
            "training loss: 6.997653961181641\n",
            "training loss: 7.042776107788086\n",
            "training loss: 6.890557289123535\n",
            "training loss: 6.855426788330078\n",
            "training loss: 6.917327880859375\n",
            "training loss: 6.823399543762207\n",
            "training loss: 6.921402931213379\n",
            "training loss: 6.827497482299805\n",
            "training loss: 6.640810012817383\n",
            "training loss: 7.0213518142700195\n",
            "training loss: 6.527616024017334\n",
            "training loss: 6.408824920654297\n",
            "training loss: 6.907508850097656\n",
            "training loss: 6.8001933097839355\n",
            "training loss: 6.596977233886719\n",
            "training loss: 6.584358215332031\n",
            "training loss: 6.477051258087158\n",
            "training loss: 6.735989093780518\n",
            "training loss: 6.909031867980957\n",
            "training loss: 6.777955532073975\n",
            "training loss: 6.798521041870117\n",
            "training loss: 6.8067545890808105\n",
            "training loss: 6.554733753204346\n",
            "training loss: 6.723384380340576\n",
            "training loss: 6.691439628601074\n",
            "training loss: 6.422093391418457\n",
            "training loss: 6.582364559173584\n",
            "training loss: 6.658868789672852\n",
            "training loss: 6.493371963500977\n",
            "training loss: 6.538939952850342\n",
            "training loss: 6.8351263999938965\n",
            "training loss: 6.700876235961914\n",
            "training loss: 6.8081183433532715\n",
            "training loss: 6.632046222686768\n",
            "training loss: 6.873181343078613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   8%|▊         | 5/60 [03:49<41:44, 45.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.997900009155273\n",
            "training loss: 6.363039493560791\n",
            "training loss: 6.496057033538818\n",
            "training loss: 6.699873924255371\n",
            "training loss: 6.904446125030518\n",
            "training loss: 6.863947868347168\n",
            "training loss: 6.796751022338867\n",
            "training loss: 6.843972206115723\n",
            "training loss: 6.771087646484375\n",
            "training loss: 6.815910816192627\n",
            "training loss: 6.7689056396484375\n",
            "training loss: 6.909980773925781\n",
            "training loss: 6.976486682891846\n",
            "training loss: 6.984729766845703\n",
            "training loss: 6.947916507720947\n",
            "training loss: 6.710231781005859\n",
            "training loss: 6.910336494445801\n",
            "training loss: 6.777259349822998\n",
            "training loss: 6.816072463989258\n",
            "training loss: 6.676203727722168\n",
            "training loss: 6.774444103240967\n",
            "training loss: 6.413917541503906\n",
            "training loss: 6.7631378173828125\n",
            "training loss: 6.690497398376465\n",
            "training loss: 6.705524444580078\n",
            "training loss: 6.652331352233887\n",
            "training loss: 6.573073863983154\n",
            "training loss: 6.737515449523926\n",
            "training loss: 6.667511940002441\n",
            "training loss: 6.692837715148926\n",
            "training loss: 6.3526611328125\n",
            "training loss: 6.805700302124023\n",
            "training loss: 6.809508800506592\n",
            "training loss: 6.853892803192139\n",
            "training loss: 7.153615474700928\n",
            "training loss: 6.8621978759765625\n",
            "training loss: 6.874361038208008\n",
            "training loss: 6.9568352699279785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  10%|█         | 6/60 [04:33<40:44, 45.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.862298488616943\n",
            "training loss: 6.981101989746094\n",
            "training loss: 6.821468353271484\n",
            "training loss: 6.993210792541504\n",
            "training loss: 6.8023152351379395\n",
            "training loss: 7.047108173370361\n",
            "training loss: 7.003007411956787\n",
            "training loss: 6.844115257263184\n",
            "training loss: 6.692314147949219\n",
            "training loss: 6.851118564605713\n",
            "training loss: 6.915839195251465\n",
            "training loss: 6.6171488761901855\n",
            "training loss: 6.672018051147461\n",
            "training loss: 6.654702186584473\n",
            "training loss: 6.82102108001709\n",
            "training loss: 6.714496612548828\n",
            "training loss: 6.9137444496154785\n",
            "training loss: 6.670977592468262\n",
            "training loss: 6.892205715179443\n",
            "training loss: 6.780327796936035\n",
            "training loss: 6.690483093261719\n",
            "training loss: 6.751298427581787\n",
            "training loss: 6.872488498687744\n",
            "training loss: 6.630335807800293\n",
            "training loss: 6.73447847366333\n",
            "training loss: 6.584606170654297\n",
            "training loss: 6.705689907073975\n",
            "training loss: 6.403355598449707\n",
            "training loss: 6.776950836181641\n",
            "training loss: 6.736647129058838\n",
            "training loss: 6.666880130767822\n",
            "training loss: 6.7744832038879395\n",
            "training loss: 6.667731285095215\n",
            "training loss: 6.994734764099121\n",
            "training loss: 6.81011438369751\n",
            "training loss: 6.724155426025391\n",
            "training loss: 6.635321617126465\n",
            "training loss: 6.535855293273926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  12%|█▏        | 7/60 [05:18<39:49, 45.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.977161407470703\n",
            "training loss: 7.001771926879883\n",
            "training loss: 7.103734016418457\n",
            "training loss: 6.592108726501465\n",
            "training loss: 6.887852668762207\n",
            "training loss: 6.9341630935668945\n",
            "training loss: 6.790191650390625\n",
            "training loss: 7.011256217956543\n",
            "training loss: 6.733860015869141\n",
            "training loss: 6.742122650146484\n",
            "training loss: 6.814472198486328\n",
            "training loss: 6.763212203979492\n",
            "training loss: 6.74227237701416\n",
            "training loss: 6.8572611808776855\n",
            "training loss: 6.824877738952637\n",
            "training loss: 6.761814594268799\n",
            "training loss: 6.992175579071045\n",
            "training loss: 6.684933185577393\n",
            "training loss: 6.697047710418701\n",
            "training loss: 6.765316963195801\n",
            "training loss: 6.801074028015137\n",
            "training loss: 6.613753795623779\n",
            "training loss: 6.659562110900879\n",
            "training loss: 6.6733222007751465\n",
            "training loss: 6.942657470703125\n",
            "training loss: 6.702758312225342\n",
            "training loss: 6.804868698120117\n",
            "training loss: 6.69206428527832\n",
            "training loss: 6.6258864402771\n",
            "training loss: 6.622724533081055\n",
            "training loss: 6.5437726974487305\n",
            "training loss: 6.683946132659912\n",
            "training loss: 6.46755313873291\n",
            "training loss: 6.637422561645508\n",
            "training loss: 6.432605266571045\n",
            "training loss: 6.8899312019348145\n",
            "training loss: 6.635166168212891\n",
            "training loss: 6.598977088928223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  13%|█▎        | 8/60 [06:03<38:58, 44.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.993865489959717\n",
            "training loss: 7.054170608520508\n",
            "training loss: 6.904050827026367\n",
            "training loss: 6.945105075836182\n",
            "training loss: 6.802419662475586\n",
            "training loss: 6.628384590148926\n",
            "training loss: 6.719486236572266\n",
            "training loss: 7.033241271972656\n",
            "training loss: 6.915124893188477\n",
            "training loss: 6.991113185882568\n",
            "training loss: 6.957678318023682\n",
            "training loss: 6.835542678833008\n",
            "training loss: 6.577420234680176\n",
            "training loss: 6.847100257873535\n",
            "training loss: 6.678097724914551\n",
            "training loss: 6.820459365844727\n",
            "training loss: 6.7209272384643555\n",
            "training loss: 6.942686080932617\n",
            "training loss: 6.5783185958862305\n",
            "training loss: 6.658351898193359\n",
            "training loss: 7.140475273132324\n",
            "training loss: 6.925769805908203\n",
            "training loss: 6.803318023681641\n",
            "training loss: 6.692038536071777\n",
            "training loss: 6.8041582107543945\n",
            "training loss: 6.6958818435668945\n",
            "training loss: 6.662113189697266\n",
            "training loss: 6.829571723937988\n",
            "training loss: 6.829894065856934\n",
            "training loss: 6.729199409484863\n",
            "training loss: 6.776800155639648\n",
            "training loss: 6.6049485206604\n",
            "training loss: 6.759710788726807\n",
            "training loss: 6.855811595916748\n",
            "training loss: 6.768548011779785\n",
            "training loss: 6.690977573394775\n",
            "training loss: 6.742829322814941\n",
            "training loss: 6.772193908691406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  15%|█▌        | 9/60 [06:50<38:41, 45.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.73366641998291\n",
            "training loss: 6.702786922454834\n",
            "training loss: 6.5880327224731445\n",
            "training loss: 6.341425895690918\n",
            "training loss: 6.666243076324463\n",
            "training loss: 6.808850288391113\n",
            "training loss: 6.861759185791016\n",
            "training loss: 6.731145858764648\n",
            "training loss: 6.638104438781738\n",
            "training loss: 6.55708646774292\n",
            "training loss: 6.756797790527344\n",
            "training loss: 6.76838493347168\n",
            "training loss: 6.6648664474487305\n",
            "training loss: 6.367756366729736\n",
            "training loss: 6.4877519607543945\n",
            "training loss: 6.554801940917969\n",
            "training loss: 6.518699645996094\n",
            "training loss: 6.593636512756348\n",
            "training loss: 6.964340686798096\n",
            "training loss: 6.569332122802734\n",
            "training loss: 6.3862104415893555\n",
            "training loss: 6.821187973022461\n",
            "training loss: 6.980278968811035\n",
            "training loss: 6.865396022796631\n",
            "training loss: 6.8885955810546875\n",
            "training loss: 6.707718849182129\n",
            "training loss: 6.673789978027344\n",
            "training loss: 6.757640838623047\n",
            "training loss: 7.105406284332275\n",
            "training loss: 6.8209757804870605\n",
            "training loss: 6.687162399291992\n",
            "training loss: 6.804327011108398\n",
            "training loss: 6.624470233917236\n",
            "training loss: 6.5522260665893555\n",
            "training loss: 6.4417243003845215\n",
            "training loss: 6.540904521942139\n",
            "training loss: 6.819032669067383\n",
            "training loss: 6.77908992767334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  17%|█▋        | 10/60 [07:34<37:46, 45.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.899343013763428\n",
            "training loss: 6.851167678833008\n",
            "training loss: 6.355642318725586\n",
            "training loss: 6.649394989013672\n",
            "training loss: 7.088214874267578\n",
            "training loss: 7.111241340637207\n",
            "training loss: 6.905237197875977\n",
            "training loss: 6.76381254196167\n",
            "training loss: 6.819019317626953\n",
            "training loss: 6.9468584060668945\n",
            "training loss: 6.783190727233887\n",
            "training loss: 6.882589340209961\n",
            "training loss: 6.707957744598389\n",
            "training loss: 6.593177795410156\n",
            "training loss: 6.675677299499512\n",
            "training loss: 6.816839218139648\n",
            "training loss: 6.865103721618652\n",
            "training loss: 6.69210147857666\n",
            "training loss: 6.856276512145996\n",
            "training loss: 6.658657550811768\n",
            "training loss: 6.788762092590332\n",
            "training loss: 6.972644805908203\n",
            "training loss: 6.592868328094482\n",
            "training loss: 6.800561428070068\n",
            "training loss: 6.708356857299805\n",
            "training loss: 6.863319396972656\n",
            "training loss: 6.662578582763672\n",
            "training loss: 6.818404674530029\n",
            "training loss: 6.660883903503418\n",
            "training loss: 6.58603572845459\n",
            "training loss: 6.870535850524902\n",
            "training loss: 6.597831726074219\n",
            "training loss: 6.810819625854492\n",
            "training loss: 6.840213298797607\n",
            "training loss: 6.94550895690918\n",
            "training loss: 6.863703727722168\n",
            "training loss: 6.898097038269043\n",
            "training loss: 6.935172080993652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  18%|█▊        | 11/60 [08:20<37:05, 45.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.697707653045654\n",
            "training loss: 6.6839118003845215\n",
            "training loss: 6.876555919647217\n",
            "training loss: 6.855933666229248\n",
            "training loss: 6.794694423675537\n",
            "training loss: 7.044451713562012\n",
            "training loss: 6.939905643463135\n",
            "training loss: 6.845189094543457\n",
            "training loss: 6.73380184173584\n",
            "training loss: 6.732227325439453\n",
            "training loss: 6.90339469909668\n",
            "training loss: 6.63409423828125\n",
            "training loss: 6.996423721313477\n",
            "training loss: 6.668768882751465\n",
            "training loss: 6.760868072509766\n",
            "training loss: 6.764457702636719\n",
            "training loss: 6.757811546325684\n",
            "training loss: 6.805854797363281\n",
            "training loss: 6.6768035888671875\n",
            "training loss: 6.6764984130859375\n",
            "training loss: 6.975581645965576\n",
            "training loss: 6.908633232116699\n",
            "training loss: 7.039620399475098\n",
            "training loss: 6.868054389953613\n",
            "training loss: 6.647736072540283\n",
            "training loss: 6.643670558929443\n",
            "training loss: 6.628572463989258\n",
            "training loss: 6.752996444702148\n",
            "training loss: 6.681876182556152\n",
            "training loss: 6.74785041809082\n",
            "training loss: 6.745149612426758\n",
            "training loss: 6.792376518249512\n",
            "training loss: 6.812487602233887\n",
            "training loss: 6.877192497253418\n",
            "training loss: 6.810503005981445\n",
            "training loss: 6.705472469329834\n",
            "training loss: 6.873537063598633\n",
            "training loss: 6.811210632324219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  20%|██        | 12/60 [09:05<36:18, 45.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.733649253845215\n",
            "training loss: 6.87883996963501\n",
            "training loss: 6.750992298126221\n",
            "training loss: 6.786092758178711\n",
            "training loss: 6.553967475891113\n",
            "training loss: 6.764764785766602\n",
            "training loss: 7.048670291900635\n",
            "training loss: 7.087837219238281\n",
            "training loss: 6.90940523147583\n",
            "training loss: 6.958517074584961\n",
            "training loss: 6.841954231262207\n",
            "training loss: 6.603942394256592\n",
            "training loss: 6.692165374755859\n",
            "training loss: 6.928756237030029\n",
            "training loss: 6.920845031738281\n",
            "training loss: 6.729691505432129\n",
            "training loss: 6.754177093505859\n",
            "training loss: 6.870694160461426\n",
            "training loss: 6.717443466186523\n",
            "training loss: 6.669740200042725\n",
            "training loss: 6.907842636108398\n",
            "training loss: 6.757707595825195\n",
            "training loss: 6.842045307159424\n",
            "training loss: 6.97648286819458\n",
            "training loss: 6.891412258148193\n",
            "training loss: 6.818144798278809\n",
            "training loss: 7.082326412200928\n",
            "training loss: 7.011999130249023\n",
            "training loss: 6.737200736999512\n",
            "training loss: 6.7894158363342285\n",
            "training loss: 6.87791633605957\n",
            "training loss: 6.893957138061523\n",
            "training loss: 6.750669479370117\n",
            "training loss: 6.7102251052856445\n",
            "training loss: 6.507757663726807\n",
            "training loss: 6.652806282043457\n",
            "training loss: 6.718015670776367\n",
            "training loss: 6.819979667663574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  22%|██▏       | 13/60 [09:51<35:33, 45.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.819276809692383\n",
            "training loss: 6.922855377197266\n",
            "training loss: 6.829349517822266\n",
            "training loss: 6.591181755065918\n",
            "training loss: 6.577451229095459\n",
            "training loss: 7.0455474853515625\n",
            "training loss: 6.62939977645874\n",
            "training loss: 6.84124231338501\n",
            "training loss: 6.921801567077637\n",
            "training loss: 6.779057502746582\n",
            "training loss: 6.683743953704834\n",
            "training loss: 6.877786636352539\n",
            "training loss: 6.710283279418945\n",
            "training loss: 6.675947666168213\n",
            "training loss: 6.684950828552246\n",
            "training loss: 6.689060688018799\n",
            "training loss: 6.760432243347168\n",
            "training loss: 6.961021423339844\n",
            "training loss: 6.687814235687256\n",
            "training loss: 6.732133865356445\n",
            "training loss: 6.627830505371094\n",
            "training loss: 6.782088279724121\n",
            "training loss: 6.822669982910156\n",
            "training loss: 6.605250358581543\n",
            "training loss: 6.685283660888672\n",
            "training loss: 6.687193393707275\n",
            "training loss: 6.612580299377441\n",
            "training loss: 6.724003791809082\n",
            "training loss: 6.587679386138916\n",
            "training loss: 6.441806793212891\n",
            "training loss: 6.552306175231934\n",
            "training loss: 6.670295715332031\n",
            "training loss: 6.663331031799316\n",
            "training loss: 6.760102272033691\n",
            "training loss: 6.8304619789123535\n",
            "training loss: 6.388453960418701\n",
            "training loss: 6.676756858825684\n",
            "training loss: 6.765590667724609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  23%|██▎       | 14/60 [10:36<34:47, 45.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.996939659118652\n",
            "training loss: 7.119034767150879\n",
            "training loss: 6.833601474761963\n",
            "training loss: 6.802980422973633\n",
            "training loss: 6.7512383460998535\n",
            "training loss: 6.7660627365112305\n",
            "training loss: 6.71282958984375\n",
            "training loss: 6.7503275871276855\n",
            "training loss: 6.787762641906738\n",
            "training loss: 6.823698997497559\n",
            "training loss: 6.922248363494873\n",
            "training loss: 6.767703533172607\n",
            "training loss: 6.8258891105651855\n",
            "training loss: 6.8820600509643555\n",
            "training loss: 6.827592372894287\n",
            "training loss: 6.889673709869385\n",
            "training loss: 6.89373779296875\n",
            "training loss: 6.91480827331543\n",
            "training loss: 6.814910888671875\n",
            "training loss: 6.789401531219482\n",
            "training loss: 6.956191539764404\n",
            "training loss: 6.753790855407715\n",
            "training loss: 6.704615592956543\n",
            "training loss: 6.822837829589844\n",
            "training loss: 6.749815940856934\n",
            "training loss: 6.9525675773620605\n",
            "training loss: 6.74569845199585\n",
            "training loss: 6.825700759887695\n",
            "training loss: 6.576272010803223\n",
            "training loss: 6.725336074829102\n",
            "training loss: 6.829800605773926\n",
            "training loss: 6.961872100830078\n",
            "training loss: 7.033682823181152\n",
            "training loss: 6.569799423217773\n",
            "training loss: 6.773752212524414\n",
            "training loss: 6.727197170257568\n",
            "training loss: 6.847052097320557\n",
            "training loss: 6.807676315307617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  25%|██▌       | 15/60 [11:22<34:11, 45.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.739010810852051\n",
            "training loss: 6.80997371673584\n",
            "training loss: 6.947746276855469\n",
            "training loss: 6.971170425415039\n",
            "training loss: 6.707573890686035\n",
            "training loss: 6.897651195526123\n",
            "training loss: 6.847761154174805\n",
            "training loss: 6.726821422576904\n",
            "training loss: 6.919647216796875\n",
            "training loss: 7.084735870361328\n",
            "training loss: 6.9626994132995605\n",
            "training loss: 6.717307090759277\n",
            "training loss: 6.953549861907959\n",
            "training loss: 6.990329265594482\n",
            "training loss: 6.854784965515137\n",
            "training loss: 6.875973701477051\n",
            "training loss: 6.633232116699219\n",
            "training loss: 6.794865608215332\n",
            "training loss: 6.650081157684326\n",
            "training loss: 6.634123802185059\n",
            "training loss: 6.814561367034912\n",
            "training loss: 6.999707221984863\n",
            "training loss: 6.811787128448486\n",
            "training loss: 6.754670143127441\n",
            "training loss: 6.633973598480225\n",
            "training loss: 6.619475364685059\n",
            "training loss: 6.615668773651123\n",
            "training loss: 6.524667739868164\n",
            "training loss: 6.717647552490234\n",
            "training loss: 6.764040946960449\n",
            "training loss: 6.756603240966797\n",
            "training loss: 6.63606071472168\n",
            "training loss: 6.8344244956970215\n",
            "training loss: 6.80185604095459\n",
            "training loss: 7.08072566986084\n",
            "training loss: 6.882176399230957\n",
            "training loss: 6.715949058532715\n",
            "training loss: 6.7820634841918945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  27%|██▋       | 16/60 [12:08<33:21, 45.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.909641742706299\n",
            "training loss: 6.916820049285889\n",
            "training loss: 6.890138626098633\n",
            "training loss: 7.027522563934326\n",
            "training loss: 7.007516860961914\n",
            "training loss: 7.012462139129639\n",
            "training loss: 6.881561279296875\n",
            "training loss: 6.593024253845215\n",
            "training loss: 7.018763065338135\n",
            "training loss: 7.031432628631592\n",
            "training loss: 6.8368635177612305\n",
            "training loss: 6.676445960998535\n",
            "training loss: 6.876640319824219\n",
            "training loss: 6.873058319091797\n",
            "training loss: 6.969511985778809\n",
            "training loss: 6.768960475921631\n",
            "training loss: 6.502998352050781\n",
            "training loss: 6.845542907714844\n",
            "training loss: 6.926739692687988\n",
            "training loss: 6.873624801635742\n",
            "training loss: 6.688720226287842\n",
            "training loss: 6.690771102905273\n",
            "training loss: 6.620011806488037\n",
            "training loss: 6.721551895141602\n",
            "training loss: 6.459439754486084\n",
            "training loss: 6.717494010925293\n",
            "training loss: 6.597632884979248\n",
            "training loss: 6.619083881378174\n",
            "training loss: 6.711838722229004\n",
            "training loss: 6.560497283935547\n",
            "training loss: 6.794681072235107\n",
            "training loss: 6.550475597381592\n",
            "training loss: 6.717626571655273\n",
            "training loss: 6.599313735961914\n",
            "training loss: 6.679313659667969\n",
            "training loss: 6.694140434265137\n",
            "training loss: 6.505337715148926\n",
            "training loss: 6.64962100982666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  28%|██▊       | 17/60 [12:53<32:35, 45.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.155115127563477\n",
            "training loss: 6.955444812774658\n",
            "training loss: 7.2356791496276855\n",
            "training loss: 7.200037002563477\n",
            "training loss: 6.923254013061523\n",
            "training loss: 7.0596747398376465\n",
            "training loss: 6.936466693878174\n",
            "training loss: 7.171476364135742\n",
            "training loss: 6.7757568359375\n",
            "training loss: 7.077747344970703\n",
            "training loss: 6.863221645355225\n",
            "training loss: 6.724725723266602\n",
            "training loss: 6.788729190826416\n",
            "training loss: 6.833458423614502\n",
            "training loss: 6.894635200500488\n",
            "training loss: 6.974055290222168\n",
            "training loss: 6.790470123291016\n",
            "training loss: 6.661439418792725\n",
            "training loss: 6.977521896362305\n",
            "training loss: 6.925622940063477\n",
            "training loss: 6.983738899230957\n",
            "training loss: 6.848520278930664\n",
            "training loss: 6.84213924407959\n",
            "training loss: 6.819979667663574\n",
            "training loss: 6.693511962890625\n",
            "training loss: 6.832985877990723\n",
            "training loss: 6.806814193725586\n",
            "training loss: 6.818690299987793\n",
            "training loss: 6.739292621612549\n",
            "training loss: 6.673776626586914\n",
            "training loss: 6.787371635437012\n",
            "training loss: 6.910798072814941\n",
            "training loss: 6.916097640991211\n",
            "training loss: 6.697096824645996\n",
            "training loss: 6.826692581176758\n",
            "training loss: 6.6672468185424805\n",
            "training loss: 6.533708572387695\n",
            "training loss: 6.749343395233154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  30%|███       | 18/60 [13:38<31:48, 45.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.853843688964844\n",
            "training loss: 6.9605488777160645\n",
            "training loss: 7.084613800048828\n",
            "training loss: 6.955981254577637\n",
            "training loss: 6.982043266296387\n",
            "training loss: 6.7516608238220215\n",
            "training loss: 6.887682914733887\n",
            "training loss: 6.799661159515381\n",
            "training loss: 7.008004665374756\n",
            "training loss: 6.969522953033447\n",
            "training loss: 6.971083641052246\n",
            "training loss: 6.913122177124023\n",
            "training loss: 6.78688383102417\n",
            "training loss: 6.781733512878418\n",
            "training loss: 6.755253791809082\n",
            "training loss: 6.794094562530518\n",
            "training loss: 6.921108245849609\n",
            "training loss: 6.746642112731934\n",
            "training loss: 6.925051689147949\n",
            "training loss: 6.954679489135742\n",
            "training loss: 6.756794452667236\n",
            "training loss: 6.8511199951171875\n",
            "training loss: 6.80358362197876\n",
            "training loss: 6.811736583709717\n",
            "training loss: 6.848420143127441\n",
            "training loss: 6.740364074707031\n",
            "training loss: 6.68891716003418\n",
            "training loss: 6.831413269042969\n",
            "training loss: 6.6753153800964355\n",
            "training loss: 6.907164096832275\n",
            "training loss: 6.622293472290039\n",
            "training loss: 6.970311164855957\n",
            "training loss: 7.097445487976074\n",
            "training loss: 6.583970069885254\n",
            "training loss: 6.822183609008789\n",
            "training loss: 6.67982292175293\n",
            "training loss: 6.805447578430176\n",
            "training loss: 6.5824055671691895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  32%|███▏      | 19/60 [14:24<31:00, 45.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.702777862548828\n",
            "training loss: 6.729759693145752\n",
            "training loss: 6.902584075927734\n",
            "training loss: 7.003697395324707\n",
            "training loss: 6.963726997375488\n",
            "training loss: 6.970893859863281\n",
            "training loss: 7.047964096069336\n",
            "training loss: 6.934426307678223\n",
            "training loss: 6.772966384887695\n",
            "training loss: 6.848216533660889\n",
            "training loss: 6.837828159332275\n",
            "training loss: 6.7362060546875\n",
            "training loss: 6.942641735076904\n",
            "training loss: 7.085667133331299\n",
            "training loss: 6.962338447570801\n",
            "training loss: 6.721959114074707\n",
            "training loss: 6.911671161651611\n",
            "training loss: 6.614144325256348\n",
            "training loss: 6.953888416290283\n",
            "training loss: 6.983226776123047\n",
            "training loss: 7.0099101066589355\n",
            "training loss: 6.758757591247559\n",
            "training loss: 6.7532639503479\n",
            "training loss: 6.739114284515381\n",
            "training loss: 6.721161842346191\n",
            "training loss: 6.4306416511535645\n",
            "training loss: 6.587745189666748\n",
            "training loss: 6.561168670654297\n",
            "training loss: 6.673214912414551\n",
            "training loss: 6.928292274475098\n",
            "training loss: 6.940244674682617\n",
            "training loss: 6.86265754699707\n",
            "training loss: 6.813604831695557\n",
            "training loss: 6.659514427185059\n",
            "training loss: 6.60861873626709\n",
            "training loss: 6.796101093292236\n",
            "training loss: 6.831830024719238\n",
            "training loss: 6.777298927307129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  33%|███▎      | 20/60 [15:09<30:14, 45.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.704233169555664\n",
            "training loss: 6.784054279327393\n",
            "training loss: 6.849352836608887\n",
            "training loss: 6.8137102127075195\n",
            "training loss: 6.9390363693237305\n",
            "training loss: 6.9407124519348145\n",
            "training loss: 6.821970462799072\n",
            "training loss: 6.877354621887207\n",
            "training loss: 7.15906286239624\n",
            "training loss: 6.787216663360596\n",
            "training loss: 6.757865905761719\n",
            "training loss: 6.87886381149292\n",
            "training loss: 6.860283851623535\n",
            "training loss: 6.940434455871582\n",
            "training loss: 6.820624351501465\n",
            "training loss: 6.882044315338135\n",
            "training loss: 6.729586124420166\n",
            "training loss: 6.638625144958496\n",
            "training loss: 6.9702911376953125\n",
            "training loss: 6.865670204162598\n",
            "training loss: 6.724265098571777\n",
            "training loss: 6.726332664489746\n",
            "training loss: 6.792254447937012\n",
            "training loss: 6.895707130432129\n",
            "training loss: 6.960745811462402\n",
            "training loss: 6.891232967376709\n",
            "training loss: 6.897783279418945\n",
            "training loss: 6.814210891723633\n",
            "training loss: 6.876985549926758\n",
            "training loss: 7.0302958488464355\n",
            "training loss: 6.914320945739746\n",
            "training loss: 6.946707248687744\n",
            "training loss: 6.799849033355713\n",
            "training loss: 6.741862773895264\n",
            "training loss: 6.792189598083496\n",
            "training loss: 6.827070236206055\n",
            "training loss: 6.887707710266113\n",
            "training loss: 6.915369033813477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  35%|███▌      | 21/60 [15:55<29:40, 45.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.923999309539795\n",
            "training loss: 6.862432479858398\n",
            "training loss: 6.911858081817627\n",
            "training loss: 6.959689617156982\n",
            "training loss: 6.914988040924072\n",
            "training loss: 6.932669639587402\n",
            "training loss: 7.009799003601074\n",
            "training loss: 6.785918712615967\n",
            "training loss: 6.886253356933594\n",
            "training loss: 6.760593414306641\n",
            "training loss: 6.5985260009765625\n",
            "training loss: 6.688581943511963\n",
            "training loss: 6.887700080871582\n",
            "training loss: 6.923869609832764\n",
            "training loss: 6.677639007568359\n",
            "training loss: 6.958761215209961\n",
            "training loss: 6.6239423751831055\n",
            "training loss: 6.773797035217285\n",
            "training loss: 6.647665500640869\n",
            "training loss: 6.74229621887207\n",
            "training loss: 6.825677871704102\n",
            "training loss: 6.990959167480469\n",
            "training loss: 6.790706157684326\n",
            "training loss: 6.839398384094238\n",
            "training loss: 6.6616644859313965\n",
            "training loss: 6.63722038269043\n",
            "training loss: 6.767477512359619\n",
            "training loss: 6.916469573974609\n",
            "training loss: 6.8285112380981445\n",
            "training loss: 6.842627048492432\n",
            "training loss: 6.783840179443359\n",
            "training loss: 6.882349014282227\n",
            "training loss: 7.018902778625488\n",
            "training loss: 6.455843448638916\n",
            "training loss: 6.554652214050293\n",
            "training loss: 6.536355972290039\n",
            "training loss: 6.726821422576904\n",
            "training loss: 6.760550498962402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  37%|███▋      | 22/60 [16:40<28:45, 45.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.021117210388184\n",
            "training loss: 6.9215312004089355\n",
            "training loss: 7.0992817878723145\n",
            "training loss: 6.975449085235596\n",
            "training loss: 6.745241641998291\n",
            "training loss: 6.870562553405762\n",
            "training loss: 6.906679630279541\n",
            "training loss: 6.887897491455078\n",
            "training loss: 6.653140068054199\n",
            "training loss: 7.001369953155518\n",
            "training loss: 6.89112663269043\n",
            "training loss: 6.974593162536621\n",
            "training loss: 6.819385528564453\n",
            "training loss: 6.897171974182129\n",
            "training loss: 6.845462799072266\n",
            "training loss: 6.962101459503174\n",
            "training loss: 6.776627540588379\n",
            "training loss: 6.629945278167725\n",
            "training loss: 6.771758079528809\n",
            "training loss: 6.774885654449463\n",
            "training loss: 6.894036769866943\n",
            "training loss: 6.830636978149414\n",
            "training loss: 7.021017074584961\n",
            "training loss: 6.889332294464111\n",
            "training loss: 6.831574440002441\n",
            "training loss: 6.940142631530762\n",
            "training loss: 6.874208927154541\n",
            "training loss: 6.878599166870117\n",
            "training loss: 7.000661849975586\n",
            "training loss: 6.929520130157471\n",
            "training loss: 6.762169361114502\n",
            "training loss: 6.872297763824463\n",
            "training loss: 6.794084548950195\n",
            "training loss: 6.559876441955566\n",
            "training loss: 6.669567108154297\n",
            "training loss: 6.726981163024902\n",
            "training loss: 6.60352897644043\n",
            "training loss: 6.6210036277771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  38%|███▊      | 23/60 [17:25<27:50, 45.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.852403163909912\n",
            "training loss: 6.724656105041504\n",
            "training loss: 6.751327991485596\n",
            "training loss: 6.339446067810059\n",
            "training loss: 6.735651969909668\n",
            "training loss: 6.683229446411133\n",
            "training loss: 6.690771102905273\n",
            "training loss: 7.057096481323242\n",
            "training loss: 6.823065757751465\n",
            "training loss: 6.7823028564453125\n",
            "training loss: 6.816006660461426\n",
            "training loss: 6.92372465133667\n",
            "training loss: 6.833366870880127\n",
            "training loss: 7.086153507232666\n",
            "training loss: 6.653322219848633\n",
            "training loss: 6.837362289428711\n",
            "training loss: 7.076043605804443\n",
            "training loss: 7.030373573303223\n",
            "training loss: 6.9590559005737305\n",
            "training loss: 6.697378158569336\n",
            "training loss: 6.477150917053223\n",
            "training loss: 6.696976661682129\n",
            "training loss: 6.806207656860352\n",
            "training loss: 6.766538143157959\n",
            "training loss: 6.837607383728027\n",
            "training loss: 6.6113810539245605\n",
            "training loss: 6.582569599151611\n",
            "training loss: 6.540719985961914\n",
            "training loss: 6.70694637298584\n",
            "training loss: 6.640725135803223\n",
            "training loss: 6.665884017944336\n",
            "training loss: 6.943312168121338\n",
            "training loss: 6.843713283538818\n",
            "training loss: 6.855195045471191\n",
            "training loss: 6.772942066192627\n",
            "training loss: 6.6533203125\n",
            "training loss: 6.6844635009765625\n",
            "training loss: 6.663118839263916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  40%|████      | 24/60 [18:09<26:59, 44.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.8662824630737305\n",
            "training loss: 6.866498947143555\n",
            "training loss: 6.95956563949585\n",
            "training loss: 6.879673004150391\n",
            "training loss: 7.002493858337402\n",
            "training loss: 6.932704448699951\n",
            "training loss: 6.831730842590332\n",
            "training loss: 6.8488030433654785\n",
            "training loss: 6.988205432891846\n",
            "training loss: 6.8704962730407715\n",
            "training loss: 6.777853488922119\n",
            "training loss: 7.154077053070068\n",
            "training loss: 6.970934867858887\n",
            "training loss: 6.590971946716309\n",
            "training loss: 6.951336860656738\n",
            "training loss: 6.82797384262085\n",
            "training loss: 6.758521556854248\n",
            "training loss: 6.928829193115234\n",
            "training loss: 6.979824066162109\n",
            "training loss: 6.4729437828063965\n",
            "training loss: 6.8084397315979\n",
            "training loss: 6.795798301696777\n",
            "training loss: 6.882961273193359\n",
            "training loss: 6.740006446838379\n",
            "training loss: 6.8619842529296875\n",
            "training loss: 6.545851707458496\n",
            "training loss: 6.76038932800293\n",
            "training loss: 6.928574562072754\n",
            "training loss: 6.884109973907471\n",
            "training loss: 6.793501853942871\n",
            "training loss: 6.9599738121032715\n",
            "training loss: 6.783170700073242\n",
            "training loss: 6.714195251464844\n",
            "training loss: 6.769289016723633\n",
            "training loss: 6.694972515106201\n",
            "training loss: 6.607066631317139\n",
            "training loss: 6.83169412612915\n",
            "training loss: 6.6904296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  42%|████▏     | 25/60 [18:54<26:11, 44.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.692261695861816\n",
            "training loss: 6.678041458129883\n",
            "training loss: 6.628879547119141\n",
            "training loss: 6.998112678527832\n",
            "training loss: 6.807029724121094\n",
            "training loss: 6.5698699951171875\n",
            "training loss: 6.637909889221191\n",
            "training loss: 6.708503723144531\n",
            "training loss: 6.938014030456543\n",
            "training loss: 6.8213653564453125\n",
            "training loss: 6.870738983154297\n",
            "training loss: 6.886765956878662\n",
            "training loss: 6.951753616333008\n",
            "training loss: 6.983293533325195\n",
            "training loss: 6.939093589782715\n",
            "training loss: 6.959382057189941\n",
            "training loss: 6.860938549041748\n",
            "training loss: 6.918458938598633\n",
            "training loss: 6.943537712097168\n",
            "training loss: 7.0619797706604\n",
            "training loss: 7.2651591300964355\n",
            "training loss: 6.822703838348389\n",
            "training loss: 6.829257965087891\n",
            "training loss: 6.776309967041016\n",
            "training loss: 6.773262023925781\n",
            "training loss: 6.9126787185668945\n",
            "training loss: 6.706666946411133\n",
            "training loss: 6.8842854499816895\n",
            "training loss: 6.666593551635742\n",
            "training loss: 6.739411354064941\n",
            "training loss: 6.728830337524414\n",
            "training loss: 6.957517623901367\n",
            "training loss: 6.580981254577637\n",
            "training loss: 6.721970558166504\n",
            "training loss: 6.865787506103516\n",
            "training loss: 6.838665008544922\n",
            "training loss: 6.709483623504639\n",
            "training loss: 6.678258895874023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  43%|████▎     | 26/60 [19:38<25:20, 44.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.139492988586426\n",
            "training loss: 6.971549987792969\n",
            "training loss: 6.894658088684082\n",
            "training loss: 6.87574577331543\n",
            "training loss: 6.626535415649414\n",
            "training loss: 6.953787803649902\n",
            "training loss: 6.898509979248047\n",
            "training loss: 7.1360368728637695\n",
            "training loss: 7.049934387207031\n",
            "training loss: 7.0084686279296875\n",
            "training loss: 6.912446975708008\n",
            "training loss: 6.953791618347168\n",
            "training loss: 6.659189224243164\n",
            "training loss: 6.848690032958984\n",
            "training loss: 6.820557117462158\n",
            "training loss: 6.574777603149414\n",
            "training loss: 6.802280426025391\n",
            "training loss: 6.809194087982178\n",
            "training loss: 7.1672844886779785\n",
            "training loss: 7.0066752433776855\n",
            "training loss: 6.945926666259766\n",
            "training loss: 6.880513668060303\n",
            "training loss: 6.974428653717041\n",
            "training loss: 6.826433181762695\n",
            "training loss: 6.670979022979736\n",
            "training loss: 6.710505485534668\n",
            "training loss: 6.5822529792785645\n",
            "training loss: 6.7980241775512695\n",
            "training loss: 6.915805339813232\n",
            "training loss: 6.722172737121582\n",
            "training loss: 6.563902854919434\n",
            "training loss: 6.585373401641846\n",
            "training loss: 6.553726673126221\n",
            "training loss: 6.6245551109313965\n",
            "training loss: 6.705121040344238\n",
            "training loss: 6.906268119812012\n",
            "training loss: 6.679139614105225\n",
            "training loss: 6.414905548095703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  45%|████▌     | 27/60 [20:24<24:49, 45.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.952749252319336\n",
            "training loss: 7.072371006011963\n",
            "training loss: 6.9482741355896\n",
            "training loss: 7.021210193634033\n",
            "training loss: 6.936614036560059\n",
            "training loss: 6.845325469970703\n",
            "training loss: 7.129125595092773\n",
            "training loss: 7.038130283355713\n",
            "training loss: 6.962783336639404\n",
            "training loss: 6.94389533996582\n",
            "training loss: 7.049191474914551\n",
            "training loss: 6.970274925231934\n",
            "training loss: 7.065036296844482\n",
            "training loss: 6.790561676025391\n",
            "training loss: 6.8810553550720215\n",
            "training loss: 6.8196611404418945\n",
            "training loss: 6.904994964599609\n",
            "training loss: 6.6715898513793945\n",
            "training loss: 7.019364356994629\n",
            "training loss: 6.9190521240234375\n",
            "training loss: 6.941789150238037\n",
            "training loss: 6.91511869430542\n",
            "training loss: 6.5705037117004395\n",
            "training loss: 6.816986560821533\n",
            "training loss: 6.875112533569336\n",
            "training loss: 6.893251419067383\n",
            "training loss: 6.959647178649902\n",
            "training loss: 7.047877311706543\n",
            "training loss: 6.868582725524902\n",
            "training loss: 6.828732967376709\n",
            "training loss: 6.8528151512146\n",
            "training loss: 6.974388599395752\n",
            "training loss: 6.919131755828857\n",
            "training loss: 6.600892543792725\n",
            "training loss: 6.694980144500732\n",
            "training loss: 6.985446453094482\n",
            "training loss: 7.114765167236328\n",
            "training loss: 6.809271812438965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  47%|████▋     | 28/60 [21:09<23:57, 44.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.970284461975098\n",
            "training loss: 6.88440465927124\n",
            "training loss: 6.681701183319092\n",
            "training loss: 6.739579200744629\n",
            "training loss: 6.929623603820801\n",
            "training loss: 6.893744468688965\n",
            "training loss: 6.938204765319824\n",
            "training loss: 6.69601583480835\n",
            "training loss: 6.753668785095215\n",
            "training loss: 6.891101837158203\n",
            "training loss: 6.876132011413574\n",
            "training loss: 6.7897210121154785\n",
            "training loss: 6.87226676940918\n",
            "training loss: 6.846380710601807\n",
            "training loss: 6.912928581237793\n",
            "training loss: 6.813223838806152\n",
            "training loss: 6.623641490936279\n",
            "training loss: 6.732484340667725\n",
            "training loss: 6.622857093811035\n",
            "training loss: 6.512842655181885\n",
            "training loss: 6.895417213439941\n",
            "training loss: 6.873866081237793\n",
            "training loss: 6.824685573577881\n",
            "training loss: 6.931482315063477\n",
            "training loss: 6.73196268081665\n",
            "training loss: 6.8757643699646\n",
            "training loss: 6.744572639465332\n",
            "training loss: 6.680845260620117\n",
            "training loss: 6.723103046417236\n",
            "training loss: 6.5636115074157715\n",
            "training loss: 6.7775115966796875\n",
            "training loss: 6.92553186416626\n",
            "training loss: 6.770318031311035\n",
            "training loss: 6.934380531311035\n",
            "training loss: 6.912045478820801\n",
            "training loss: 6.634853839874268\n",
            "training loss: 6.478184700012207\n",
            "training loss: 6.816149711608887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  48%|████▊     | 29/60 [21:53<23:08, 44.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.867549896240234\n",
            "training loss: 6.914914131164551\n",
            "training loss: 6.8249406814575195\n",
            "training loss: 6.909613609313965\n",
            "training loss: 7.022340774536133\n",
            "training loss: 6.602866172790527\n",
            "training loss: 6.439159870147705\n",
            "training loss: 6.627997875213623\n",
            "training loss: 6.788354396820068\n",
            "training loss: 6.7709808349609375\n",
            "training loss: 6.638724327087402\n",
            "training loss: 6.888580322265625\n",
            "training loss: 6.743072986602783\n",
            "training loss: 6.744379043579102\n",
            "training loss: 6.979535102844238\n",
            "training loss: 6.967832565307617\n",
            "training loss: 6.770896911621094\n",
            "training loss: 6.671833038330078\n",
            "training loss: 6.85599422454834\n",
            "training loss: 6.899222373962402\n",
            "training loss: 6.895947456359863\n",
            "training loss: 6.693963050842285\n",
            "training loss: 6.476744174957275\n",
            "training loss: 6.828291416168213\n",
            "training loss: 6.862894058227539\n",
            "training loss: 6.9055938720703125\n",
            "training loss: 6.820798397064209\n",
            "training loss: 6.743765354156494\n",
            "training loss: 6.867539405822754\n",
            "training loss: 6.731939315795898\n",
            "training loss: 6.862800121307373\n",
            "training loss: 6.891124725341797\n",
            "training loss: 6.790839672088623\n",
            "training loss: 6.776955604553223\n",
            "training loss: 6.851505279541016\n",
            "training loss: 6.720561504364014\n",
            "training loss: 6.988977432250977\n",
            "training loss: 6.671774864196777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  50%|█████     | 30/60 [22:38<22:23, 44.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.117714881896973\n",
            "training loss: 6.838415145874023\n",
            "training loss: 6.853755474090576\n",
            "training loss: 7.011058807373047\n",
            "training loss: 6.77216911315918\n",
            "training loss: 7.076582431793213\n",
            "training loss: 6.853273391723633\n",
            "training loss: 6.899035453796387\n",
            "training loss: 6.791905879974365\n",
            "training loss: 6.829851150512695\n",
            "training loss: 6.7987380027771\n",
            "training loss: 6.835423469543457\n",
            "training loss: 6.862522125244141\n",
            "training loss: 6.828605651855469\n",
            "training loss: 6.793010234832764\n",
            "training loss: 6.630672454833984\n",
            "training loss: 6.621706008911133\n",
            "training loss: 6.862911224365234\n",
            "training loss: 6.697810173034668\n",
            "training loss: 6.96030855178833\n",
            "training loss: 6.927403450012207\n",
            "training loss: 6.623443126678467\n",
            "training loss: 6.8109869956970215\n",
            "training loss: 6.7515459060668945\n",
            "training loss: 6.626745223999023\n",
            "training loss: 6.618884086608887\n",
            "training loss: 6.894274711608887\n",
            "training loss: 6.731074333190918\n",
            "training loss: 6.783788681030273\n",
            "training loss: 6.816290855407715\n",
            "training loss: 6.576508522033691\n",
            "training loss: 6.943765640258789\n",
            "training loss: 6.988436698913574\n",
            "training loss: 6.695343017578125\n",
            "training loss: 6.963393688201904\n",
            "training loss: 6.853412628173828\n",
            "training loss: 6.9131245613098145\n",
            "training loss: 6.907085418701172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  52%|█████▏    | 31/60 [23:22<21:35, 44.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.989700794219971\n",
            "training loss: 6.560686111450195\n",
            "training loss: 6.695925712585449\n",
            "training loss: 6.646876335144043\n",
            "training loss: 6.926250457763672\n",
            "training loss: 6.988813400268555\n",
            "training loss: 6.847475051879883\n",
            "training loss: 6.720335006713867\n",
            "training loss: 6.710857391357422\n",
            "training loss: 6.712601184844971\n",
            "training loss: 6.885673999786377\n",
            "training loss: 6.895553112030029\n",
            "training loss: 6.993335723876953\n",
            "training loss: 6.682633876800537\n",
            "training loss: 6.550601005554199\n",
            "training loss: 6.4153032302856445\n",
            "training loss: 6.538814544677734\n",
            "training loss: 6.685776710510254\n",
            "training loss: 6.479696273803711\n",
            "training loss: 6.640942573547363\n",
            "training loss: 6.69477653503418\n",
            "training loss: 6.583846092224121\n",
            "training loss: 6.773604869842529\n",
            "training loss: 6.746626853942871\n",
            "training loss: 6.823740005493164\n",
            "training loss: 6.761748313903809\n",
            "training loss: 6.321986675262451\n",
            "training loss: 6.865418434143066\n",
            "training loss: 6.65409517288208\n",
            "training loss: 6.703287601470947\n",
            "training loss: 6.701878547668457\n",
            "training loss: 6.956918239593506\n",
            "training loss: 6.888218402862549\n",
            "training loss: 6.7321929931640625\n",
            "training loss: 6.684140682220459\n",
            "training loss: 6.81107234954834\n",
            "training loss: 6.692160606384277\n",
            "training loss: 6.900017261505127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  53%|█████▎    | 32/60 [24:07<20:52, 44.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.028203010559082\n",
            "training loss: 7.04050350189209\n",
            "training loss: 6.833827495574951\n",
            "training loss: 6.927138328552246\n",
            "training loss: 7.01465368270874\n",
            "training loss: 6.831358432769775\n",
            "training loss: 6.611294746398926\n",
            "training loss: 6.679944038391113\n",
            "training loss: 6.975754261016846\n",
            "training loss: 6.978098392486572\n",
            "training loss: 6.931570053100586\n",
            "training loss: 6.8371500968933105\n",
            "training loss: 6.691301345825195\n",
            "training loss: 6.804644584655762\n",
            "training loss: 7.0298051834106445\n",
            "training loss: 7.056245803833008\n",
            "training loss: 6.937967777252197\n",
            "training loss: 6.750370979309082\n",
            "training loss: 6.682950019836426\n",
            "training loss: 6.847690582275391\n",
            "training loss: 6.812080383300781\n",
            "training loss: 6.8474531173706055\n",
            "training loss: 6.7462310791015625\n",
            "training loss: 6.8370137214660645\n",
            "training loss: 6.772614479064941\n",
            "training loss: 6.702040672302246\n",
            "training loss: 6.677067756652832\n",
            "training loss: 6.704407215118408\n",
            "training loss: 6.702130317687988\n",
            "training loss: 6.911488056182861\n",
            "training loss: 7.053327560424805\n",
            "training loss: 7.086666107177734\n",
            "training loss: 6.769831657409668\n",
            "training loss: 6.861741065979004\n",
            "training loss: 6.821010589599609\n",
            "training loss: 6.513894081115723\n",
            "training loss: 6.855688571929932\n",
            "training loss: 6.88778018951416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  55%|█████▌    | 33/60 [24:52<20:08, 44.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.029606342315674\n",
            "training loss: 6.935445785522461\n",
            "training loss: 6.941768169403076\n",
            "training loss: 6.820746898651123\n",
            "training loss: 6.853278160095215\n",
            "training loss: 6.725433826446533\n",
            "training loss: 6.925129413604736\n",
            "training loss: 6.765660285949707\n",
            "training loss: 6.397704124450684\n",
            "training loss: 6.7233476638793945\n",
            "training loss: 6.890830993652344\n",
            "training loss: 7.017444133758545\n",
            "training loss: 6.922606945037842\n",
            "training loss: 6.861456871032715\n",
            "training loss: 6.802008628845215\n",
            "training loss: 6.950282573699951\n",
            "training loss: 6.915421485900879\n",
            "training loss: 6.5700297355651855\n",
            "training loss: 6.83023738861084\n",
            "training loss: 6.710787296295166\n",
            "training loss: 6.898138999938965\n",
            "training loss: 6.793797492980957\n",
            "training loss: 6.83954381942749\n",
            "training loss: 6.702221870422363\n",
            "training loss: 7.062380790710449\n",
            "training loss: 6.644728660583496\n",
            "training loss: 6.895832061767578\n",
            "training loss: 6.937894344329834\n",
            "training loss: 6.841384410858154\n",
            "training loss: 6.672391891479492\n",
            "training loss: 6.747254371643066\n",
            "training loss: 6.795666217803955\n",
            "training loss: 6.417819499969482\n",
            "training loss: 6.640395641326904\n",
            "training loss: 6.760744571685791\n",
            "training loss: 6.826555252075195\n",
            "training loss: 6.940121173858643\n",
            "training loss: 6.887356281280518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  57%|█████▋    | 34/60 [25:37<19:22, 44.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.050739765167236\n",
            "training loss: 7.0055389404296875\n",
            "training loss: 6.883036136627197\n",
            "training loss: 6.917232513427734\n",
            "training loss: 6.976725101470947\n",
            "training loss: 6.8220953941345215\n",
            "training loss: 7.115458965301514\n",
            "training loss: 6.7590460777282715\n",
            "training loss: 6.566529273986816\n",
            "training loss: 6.645084857940674\n",
            "training loss: 6.85474967956543\n",
            "training loss: 6.81693172454834\n",
            "training loss: 6.897618293762207\n",
            "training loss: 6.656550407409668\n",
            "training loss: 6.628170013427734\n",
            "training loss: 6.846381664276123\n",
            "training loss: 6.52509880065918\n",
            "training loss: 6.815708637237549\n",
            "training loss: 6.967388153076172\n",
            "training loss: 6.676365375518799\n",
            "training loss: 6.848577976226807\n",
            "training loss: 6.839484214782715\n",
            "training loss: 6.8116679191589355\n",
            "training loss: 6.877511501312256\n",
            "training loss: 6.798869609832764\n",
            "training loss: 6.623898029327393\n",
            "training loss: 6.589882850646973\n",
            "training loss: 6.8912153244018555\n",
            "training loss: 6.565587043762207\n",
            "training loss: 6.49532413482666\n",
            "training loss: 6.545091152191162\n",
            "training loss: 6.913915634155273\n",
            "training loss: 6.8600311279296875\n",
            "training loss: 6.670811653137207\n",
            "training loss: 6.421590328216553\n",
            "training loss: 6.798946380615234\n",
            "training loss: 6.599822998046875\n",
            "training loss: 6.763322830200195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  58%|█████▊    | 35/60 [26:21<18:37, 44.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.000713348388672\n",
            "training loss: 6.948362350463867\n",
            "training loss: 7.09318733215332\n",
            "training loss: 6.754456043243408\n",
            "training loss: 7.021719455718994\n",
            "training loss: 6.884471893310547\n",
            "training loss: 7.0136823654174805\n",
            "training loss: 6.713543891906738\n",
            "training loss: 6.815431594848633\n",
            "training loss: 6.871935844421387\n",
            "training loss: 6.702406883239746\n",
            "training loss: 7.053311824798584\n",
            "training loss: 6.917673110961914\n",
            "training loss: 7.0071516036987305\n",
            "training loss: 6.894250392913818\n",
            "training loss: 6.887335300445557\n",
            "training loss: 6.786166191101074\n",
            "training loss: 6.837224006652832\n",
            "training loss: 6.670581817626953\n",
            "training loss: 6.612634658813477\n",
            "training loss: 6.668194770812988\n",
            "training loss: 6.973628520965576\n",
            "training loss: 7.046982765197754\n",
            "training loss: 6.860302448272705\n",
            "training loss: 6.923048496246338\n",
            "training loss: 6.648425102233887\n",
            "training loss: 6.714034080505371\n",
            "training loss: 6.688961982727051\n",
            "training loss: 6.836160659790039\n",
            "training loss: 6.704631805419922\n",
            "training loss: 6.9574809074401855\n",
            "training loss: 6.6510820388793945\n",
            "training loss: 6.705743789672852\n",
            "training loss: 6.8422136306762695\n",
            "training loss: 6.85426139831543\n",
            "training loss: 6.771481990814209\n",
            "training loss: 6.749026775360107\n",
            "training loss: 6.674108982086182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  60%|██████    | 36/60 [27:06<17:51, 44.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.9348554611206055\n",
            "training loss: 6.9257283210754395\n",
            "training loss: 6.863643646240234\n",
            "training loss: 6.955752849578857\n",
            "training loss: 6.739015579223633\n",
            "training loss: 6.707779407501221\n",
            "training loss: 6.9004950523376465\n",
            "training loss: 6.84898042678833\n",
            "training loss: 6.679724216461182\n",
            "training loss: 6.810198783874512\n",
            "training loss: 6.757545471191406\n",
            "training loss: 6.86531925201416\n",
            "training loss: 6.7994160652160645\n",
            "training loss: 7.005102157592773\n",
            "training loss: 6.997951030731201\n",
            "training loss: 6.837888717651367\n",
            "training loss: 6.980426788330078\n",
            "training loss: 6.737482070922852\n",
            "training loss: 6.961299896240234\n",
            "training loss: 6.887242317199707\n",
            "training loss: 6.854706764221191\n",
            "training loss: 6.896624565124512\n",
            "training loss: 6.847882270812988\n",
            "training loss: 6.830931663513184\n",
            "training loss: 6.771068572998047\n",
            "training loss: 6.886785507202148\n",
            "training loss: 6.8758745193481445\n",
            "training loss: 6.807316303253174\n",
            "training loss: 6.76992654800415\n",
            "training loss: 6.638401031494141\n",
            "training loss: 6.776669502258301\n",
            "training loss: 6.538678169250488\n",
            "training loss: 6.809724807739258\n",
            "training loss: 6.665003776550293\n",
            "training loss: 6.859015941619873\n",
            "training loss: 7.003530025482178\n",
            "training loss: 6.88381290435791\n",
            "training loss: 6.939120769500732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  62%|██████▏   | 37/60 [27:51<17:07, 44.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.830173492431641\n",
            "training loss: 6.968594551086426\n",
            "training loss: 6.839354038238525\n",
            "training loss: 6.708443641662598\n",
            "training loss: 6.777116298675537\n",
            "training loss: 6.800210952758789\n",
            "training loss: 6.94788122177124\n",
            "training loss: 6.901858329772949\n",
            "training loss: 6.813380241394043\n",
            "training loss: 6.751763820648193\n",
            "training loss: 6.885247230529785\n",
            "training loss: 6.695529460906982\n",
            "training loss: 6.731130123138428\n",
            "training loss: 6.796130657196045\n",
            "training loss: 6.595026016235352\n",
            "training loss: 6.854001522064209\n",
            "training loss: 6.790268898010254\n",
            "training loss: 6.950928688049316\n",
            "training loss: 6.783388137817383\n",
            "training loss: 6.832623481750488\n",
            "training loss: 6.90391731262207\n",
            "training loss: 6.858321666717529\n",
            "training loss: 6.9618635177612305\n",
            "training loss: 6.911701202392578\n",
            "training loss: 6.860449314117432\n",
            "training loss: 6.883790016174316\n",
            "training loss: 6.730298042297363\n",
            "training loss: 6.7667236328125\n",
            "training loss: 6.856867790222168\n",
            "training loss: 6.868241310119629\n",
            "training loss: 6.767040729522705\n",
            "training loss: 6.786110877990723\n",
            "training loss: 6.689375877380371\n",
            "training loss: 6.712550163269043\n",
            "training loss: 6.6865997314453125\n",
            "training loss: 6.708479881286621\n",
            "training loss: 6.8556108474731445\n",
            "training loss: 6.540348529815674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  63%|██████▎   | 38/60 [28:37<16:31, 45.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.227909088134766\n",
            "training loss: 6.899824619293213\n",
            "training loss: 6.689585208892822\n",
            "training loss: 6.82105827331543\n",
            "training loss: 6.773006916046143\n",
            "training loss: 6.8372087478637695\n",
            "training loss: 6.873997688293457\n",
            "training loss: 6.730380535125732\n",
            "training loss: 6.912137031555176\n",
            "training loss: 6.842158317565918\n",
            "training loss: 7.074305057525635\n",
            "training loss: 7.006960868835449\n",
            "training loss: 6.851817607879639\n",
            "training loss: 6.684739112854004\n",
            "training loss: 6.879753112792969\n",
            "training loss: 6.8065266609191895\n",
            "training loss: 6.718747615814209\n",
            "training loss: 6.807255268096924\n",
            "training loss: 6.795094013214111\n",
            "training loss: 6.620858192443848\n",
            "training loss: 6.6098809242248535\n",
            "training loss: 6.690987586975098\n",
            "training loss: 6.66945743560791\n",
            "training loss: 6.613151550292969\n",
            "training loss: 6.811807155609131\n",
            "training loss: 6.672669410705566\n",
            "training loss: 6.770681381225586\n",
            "training loss: 7.129941940307617\n",
            "training loss: 6.58862829208374\n",
            "training loss: 6.758073329925537\n",
            "training loss: 6.652167320251465\n",
            "training loss: 6.806432247161865\n",
            "training loss: 6.713027477264404\n",
            "training loss: 6.786561012268066\n",
            "training loss: 6.93596887588501\n",
            "training loss: 6.570760726928711\n",
            "training loss: 6.90203857421875\n",
            "training loss: 6.7123188972473145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  65%|██████▌   | 39/60 [29:21<15:43, 44.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.962841987609863\n",
            "training loss: 6.696640491485596\n",
            "training loss: 6.736343860626221\n",
            "training loss: 6.923839569091797\n",
            "training loss: 6.9850993156433105\n",
            "training loss: 7.002504348754883\n",
            "training loss: 6.976738452911377\n",
            "training loss: 7.068864345550537\n",
            "training loss: 6.760782241821289\n",
            "training loss: 7.102933883666992\n",
            "training loss: 6.888166427612305\n",
            "training loss: 6.522704601287842\n",
            "training loss: 6.7315263748168945\n",
            "training loss: 6.8271965980529785\n",
            "training loss: 6.825697422027588\n",
            "training loss: 6.608133316040039\n",
            "training loss: 6.7754645347595215\n",
            "training loss: 6.783705711364746\n",
            "training loss: 6.876555919647217\n",
            "training loss: 6.92287540435791\n",
            "training loss: 6.72125768661499\n",
            "training loss: 6.873137950897217\n",
            "training loss: 6.7916259765625\n",
            "training loss: 6.75057315826416\n",
            "training loss: 6.9765214920043945\n",
            "training loss: 6.469149589538574\n",
            "training loss: 6.619971752166748\n",
            "training loss: 6.886848449707031\n",
            "training loss: 6.826204299926758\n",
            "training loss: 6.675229072570801\n",
            "training loss: 6.825695991516113\n",
            "training loss: 6.6213579177856445\n",
            "training loss: 6.849409103393555\n",
            "training loss: 6.792722702026367\n",
            "training loss: 6.756735801696777\n",
            "training loss: 6.710934638977051\n",
            "training loss: 6.732465744018555\n",
            "training loss: 6.658710479736328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  67%|██████▋   | 40/60 [30:06<14:57, 44.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.595308303833008\n",
            "training loss: 6.983922481536865\n",
            "training loss: 6.871082305908203\n",
            "training loss: 6.649259090423584\n",
            "training loss: 6.939970016479492\n",
            "training loss: 6.831782341003418\n",
            "training loss: 6.926309108734131\n",
            "training loss: 6.806405067443848\n",
            "training loss: 6.890371322631836\n",
            "training loss: 6.900766372680664\n",
            "training loss: 6.7252397537231445\n",
            "training loss: 6.656093120574951\n",
            "training loss: 6.731021404266357\n",
            "training loss: 6.483651161193848\n",
            "training loss: 6.364301681518555\n",
            "training loss: 6.745718955993652\n",
            "training loss: 6.679222583770752\n",
            "training loss: 6.533806324005127\n",
            "training loss: 6.580842018127441\n",
            "training loss: 6.774577617645264\n",
            "training loss: 6.6648149490356445\n",
            "training loss: 6.680274963378906\n",
            "training loss: 6.742338180541992\n",
            "training loss: 6.637871265411377\n",
            "training loss: 6.6413373947143555\n",
            "training loss: 7.123331069946289\n",
            "training loss: 7.190957546234131\n",
            "training loss: 6.758890151977539\n",
            "training loss: 6.7922139167785645\n",
            "training loss: 6.852349281311035\n",
            "training loss: 6.62410306930542\n",
            "training loss: 6.6809258460998535\n",
            "training loss: 6.946074485778809\n",
            "training loss: 6.489091873168945\n",
            "training loss: 6.962418079376221\n",
            "training loss: 6.846195220947266\n",
            "training loss: 6.27672004699707\n",
            "training loss: 6.214890003204346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  68%|██████▊   | 41/60 [30:51<14:12, 44.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.991476535797119\n",
            "training loss: 6.82023286819458\n",
            "training loss: 6.938830375671387\n",
            "training loss: 6.74902868270874\n",
            "training loss: 6.81050443649292\n",
            "training loss: 6.9782514572143555\n",
            "training loss: 6.652031421661377\n",
            "training loss: 6.907898426055908\n",
            "training loss: 6.743636131286621\n",
            "training loss: 6.945128440856934\n",
            "training loss: 6.828021049499512\n",
            "training loss: 6.8422746658325195\n",
            "training loss: 6.751640319824219\n",
            "training loss: 6.732684135437012\n",
            "training loss: 6.934967994689941\n",
            "training loss: 6.676239490509033\n",
            "training loss: 6.761639595031738\n",
            "training loss: 7.0439982414245605\n",
            "training loss: 6.88498592376709\n",
            "training loss: 6.886906147003174\n",
            "training loss: 6.839501857757568\n",
            "training loss: 6.742115020751953\n",
            "training loss: 6.8018798828125\n",
            "training loss: 6.7803144454956055\n",
            "training loss: 6.766501426696777\n",
            "training loss: 6.753495216369629\n",
            "training loss: 6.847279071807861\n",
            "training loss: 6.859405040740967\n",
            "training loss: 6.820359230041504\n",
            "training loss: 6.962996006011963\n",
            "training loss: 6.46243953704834\n",
            "training loss: 6.856786251068115\n",
            "training loss: 6.931927680969238\n",
            "training loss: 7.04188346862793\n",
            "training loss: 7.1450958251953125\n",
            "training loss: 7.000622749328613\n",
            "training loss: 6.690663814544678\n",
            "training loss: 6.6136369705200195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  70%|███████   | 42/60 [31:35<13:25, 44.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.78066873550415\n",
            "training loss: 6.667798042297363\n",
            "training loss: 6.710038185119629\n",
            "training loss: 6.65382194519043\n",
            "training loss: 6.517118453979492\n",
            "training loss: 6.850224494934082\n",
            "training loss: 6.974388599395752\n",
            "training loss: 6.659626483917236\n",
            "training loss: 6.650263786315918\n",
            "training loss: 6.6704840660095215\n",
            "training loss: 6.904090881347656\n",
            "training loss: 6.923977851867676\n",
            "training loss: 6.772884368896484\n",
            "training loss: 6.605795383453369\n",
            "training loss: 6.710068225860596\n",
            "training loss: 6.747293472290039\n",
            "training loss: 6.6957292556762695\n",
            "training loss: 6.971186637878418\n",
            "training loss: 6.908010482788086\n",
            "training loss: 6.776673316955566\n",
            "training loss: 6.93698787689209\n",
            "training loss: 6.682469367980957\n",
            "training loss: 6.712449550628662\n",
            "training loss: 6.88424825668335\n",
            "training loss: 6.763942718505859\n",
            "training loss: 6.689413070678711\n",
            "training loss: 6.74259090423584\n",
            "training loss: 6.921609401702881\n",
            "training loss: 7.007639408111572\n",
            "training loss: 6.623830795288086\n",
            "training loss: 6.8592329025268555\n",
            "training loss: 6.856163024902344\n",
            "training loss: 6.968496322631836\n",
            "training loss: 6.910843372344971\n",
            "training loss: 7.024182319641113\n",
            "training loss: 6.8057661056518555\n",
            "training loss: 6.628079414367676\n",
            "training loss: 6.812977313995361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  72%|███████▏  | 43/60 [32:20<12:41, 44.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.931423664093018\n",
            "training loss: 7.127018928527832\n",
            "training loss: 7.007565021514893\n",
            "training loss: 7.1603193283081055\n",
            "training loss: 6.937081813812256\n",
            "training loss: 7.029806137084961\n",
            "training loss: 6.796108245849609\n",
            "training loss: 6.932586669921875\n",
            "training loss: 6.748565196990967\n",
            "training loss: 6.725934982299805\n",
            "training loss: 6.959476470947266\n",
            "training loss: 6.638948917388916\n",
            "training loss: 6.756728172302246\n",
            "training loss: 6.714357852935791\n",
            "training loss: 6.833187103271484\n",
            "training loss: 6.754195690155029\n",
            "training loss: 6.749386310577393\n",
            "training loss: 6.753212928771973\n",
            "training loss: 6.683821678161621\n",
            "training loss: 6.912377834320068\n",
            "training loss: 6.667544841766357\n",
            "training loss: 6.633501052856445\n",
            "training loss: 6.811209201812744\n",
            "training loss: 6.955865383148193\n",
            "training loss: 6.449606895446777\n",
            "training loss: 6.6674041748046875\n",
            "training loss: 6.8627166748046875\n",
            "training loss: 6.388641357421875\n",
            "training loss: 6.518276691436768\n",
            "training loss: 6.7773637771606445\n",
            "training loss: 6.698282241821289\n",
            "training loss: 6.953063011169434\n",
            "training loss: 6.92729377746582\n",
            "training loss: 6.646349906921387\n",
            "training loss: 6.707719802856445\n",
            "training loss: 6.92149543762207\n",
            "training loss: 6.620367050170898\n",
            "training loss: 7.011833190917969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  73%|███████▎  | 44/60 [33:06<12:03, 45.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.990352630615234\n",
            "training loss: 6.9221601486206055\n",
            "training loss: 6.9108991622924805\n",
            "training loss: 6.953190326690674\n",
            "training loss: 6.946397304534912\n",
            "training loss: 6.765018939971924\n",
            "training loss: 6.956328392028809\n",
            "training loss: 6.802232265472412\n",
            "training loss: 6.797432899475098\n",
            "training loss: 6.80060338973999\n",
            "training loss: 6.863383769989014\n",
            "training loss: 6.7830047607421875\n",
            "training loss: 6.845199108123779\n",
            "training loss: 6.752083778381348\n",
            "training loss: 6.824828147888184\n",
            "training loss: 6.397876262664795\n",
            "training loss: 6.578472137451172\n",
            "training loss: 6.513650894165039\n",
            "training loss: 6.730405807495117\n",
            "training loss: 6.758874416351318\n",
            "training loss: 6.706263542175293\n",
            "training loss: 6.547001838684082\n",
            "training loss: 6.459465980529785\n",
            "training loss: 6.77259635925293\n",
            "training loss: 6.609291076660156\n",
            "training loss: 6.807211875915527\n",
            "training loss: 6.879330158233643\n",
            "training loss: 6.685220241546631\n",
            "training loss: 6.741176128387451\n",
            "training loss: 6.721127033233643\n",
            "training loss: 6.736298561096191\n",
            "training loss: 6.628180503845215\n",
            "training loss: 6.780012607574463\n",
            "training loss: 6.406562328338623\n",
            "training loss: 6.852783203125\n",
            "training loss: 6.993350982666016\n",
            "training loss: 6.851365566253662\n",
            "training loss: 6.752214431762695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  75%|███████▌  | 45/60 [33:51<11:14, 44.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.005637168884277\n",
            "training loss: 6.683933734893799\n",
            "training loss: 6.866515636444092\n",
            "training loss: 7.217301368713379\n",
            "training loss: 6.962307453155518\n",
            "training loss: 6.903826713562012\n",
            "training loss: 6.844697952270508\n",
            "training loss: 6.854801177978516\n",
            "training loss: 7.025251865386963\n",
            "training loss: 7.17579460144043\n",
            "training loss: 6.862044334411621\n",
            "training loss: 6.747820854187012\n",
            "training loss: 6.707242965698242\n",
            "training loss: 6.748998641967773\n",
            "training loss: 6.871517181396484\n",
            "training loss: 6.8098297119140625\n",
            "training loss: 6.623433589935303\n",
            "training loss: 6.752463340759277\n",
            "training loss: 6.9252190589904785\n",
            "training loss: 6.676874160766602\n",
            "training loss: 6.707753658294678\n",
            "training loss: 6.753272533416748\n",
            "training loss: 6.7754316329956055\n",
            "training loss: 6.651833534240723\n",
            "training loss: 7.03383731842041\n",
            "training loss: 6.835952281951904\n",
            "training loss: 6.685672283172607\n",
            "training loss: 6.75966215133667\n",
            "training loss: 6.600025177001953\n",
            "training loss: 6.805363655090332\n",
            "training loss: 6.646623611450195\n",
            "training loss: 6.814436912536621\n",
            "training loss: 6.7045135498046875\n",
            "training loss: 6.775456428527832\n",
            "training loss: 6.712987899780273\n",
            "training loss: 6.526088714599609\n",
            "training loss: 6.451416015625\n",
            "training loss: 6.760164260864258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  77%|███████▋  | 46/60 [34:35<10:28, 44.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.05584716796875\n",
            "training loss: 7.045480728149414\n",
            "training loss: 7.071638584136963\n",
            "training loss: 6.818426132202148\n",
            "training loss: 6.993566513061523\n",
            "training loss: 6.830952167510986\n",
            "training loss: 6.947368621826172\n",
            "training loss: 6.673580646514893\n",
            "training loss: 6.657420635223389\n",
            "training loss: 6.7367119789123535\n",
            "training loss: 6.847733497619629\n",
            "training loss: 7.060541152954102\n",
            "training loss: 6.986931800842285\n",
            "training loss: 6.6869797706604\n",
            "training loss: 6.65199089050293\n",
            "training loss: 6.729301452636719\n",
            "training loss: 6.449631214141846\n",
            "training loss: 6.786164283752441\n",
            "training loss: 6.4621686935424805\n",
            "training loss: 6.6324872970581055\n",
            "training loss: 6.752444744110107\n",
            "training loss: 6.724258899688721\n",
            "training loss: 6.909562110900879\n",
            "training loss: 6.853693008422852\n",
            "training loss: 6.933905124664307\n",
            "training loss: 7.019547462463379\n",
            "training loss: 6.879885673522949\n",
            "training loss: 6.846607208251953\n",
            "training loss: 6.716951370239258\n",
            "training loss: 6.833297252655029\n",
            "training loss: 6.825832843780518\n",
            "training loss: 6.528566360473633\n",
            "training loss: 6.901206016540527\n",
            "training loss: 6.918257713317871\n",
            "training loss: 6.4913716316223145\n",
            "training loss: 6.762833118438721\n",
            "training loss: 6.74489688873291\n",
            "training loss: 6.499446868896484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  78%|███████▊  | 47/60 [35:20<09:41, 44.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.866178512573242\n",
            "training loss: 6.855092525482178\n",
            "training loss: 6.834680557250977\n",
            "training loss: 6.777047157287598\n",
            "training loss: 6.621417045593262\n",
            "training loss: 6.909450054168701\n",
            "training loss: 6.739223480224609\n",
            "training loss: 6.670779228210449\n",
            "training loss: 6.70351505279541\n",
            "training loss: 6.635648727416992\n",
            "training loss: 7.0609259605407715\n",
            "training loss: 6.849264144897461\n",
            "training loss: 6.810807704925537\n",
            "training loss: 6.8080620765686035\n",
            "training loss: 7.017826557159424\n",
            "training loss: 7.009071350097656\n",
            "training loss: 6.977697849273682\n",
            "training loss: 6.976235389709473\n",
            "training loss: 6.718510627746582\n",
            "training loss: 7.032981872558594\n",
            "training loss: 7.097759246826172\n",
            "training loss: 6.853598117828369\n",
            "training loss: 7.1447930335998535\n",
            "training loss: 6.847440719604492\n",
            "training loss: 6.898896217346191\n",
            "training loss: 6.9146647453308105\n",
            "training loss: 7.002099990844727\n",
            "training loss: 6.6189727783203125\n",
            "training loss: 6.689111232757568\n",
            "training loss: 6.674746513366699\n",
            "training loss: 6.6831254959106445\n",
            "training loss: 6.936007499694824\n",
            "training loss: 6.818187713623047\n",
            "training loss: 6.7306413650512695\n",
            "training loss: 6.758609294891357\n",
            "training loss: 6.720639228820801\n",
            "training loss: 6.546756744384766\n",
            "training loss: 6.423824787139893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  80%|████████  | 48/60 [36:04<08:54, 44.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.789247989654541\n",
            "training loss: 7.103627681732178\n",
            "training loss: 7.076617240905762\n",
            "training loss: 7.040964126586914\n",
            "training loss: 7.197653770446777\n",
            "training loss: 7.007895469665527\n",
            "training loss: 7.113962650299072\n",
            "training loss: 6.892739295959473\n",
            "training loss: 6.826172828674316\n",
            "training loss: 7.037013053894043\n",
            "training loss: 6.903631210327148\n",
            "training loss: 6.717931270599365\n",
            "training loss: 6.967843532562256\n",
            "training loss: 7.160801887512207\n",
            "training loss: 7.025185585021973\n",
            "training loss: 6.835664749145508\n",
            "training loss: 6.630358695983887\n",
            "training loss: 6.730201721191406\n",
            "training loss: 6.891681671142578\n",
            "training loss: 6.647487163543701\n",
            "training loss: 6.939371109008789\n",
            "training loss: 6.842286109924316\n",
            "training loss: 6.824128150939941\n",
            "training loss: 6.955102443695068\n",
            "training loss: 6.826622009277344\n",
            "training loss: 6.979812145233154\n",
            "training loss: 6.886673927307129\n",
            "training loss: 6.72537899017334\n",
            "training loss: 6.750226020812988\n",
            "training loss: 6.848414897918701\n",
            "training loss: 6.657550811767578\n",
            "training loss: 6.726352214813232\n",
            "training loss: 6.7412872314453125\n",
            "training loss: 6.934723377227783\n",
            "training loss: 6.914576530456543\n",
            "training loss: 6.806919097900391\n",
            "training loss: 6.780612468719482\n",
            "training loss: 6.745927810668945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  82%|████████▏ | 49/60 [36:48<08:08, 44.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.060410499572754\n",
            "training loss: 6.9337029457092285\n",
            "training loss: 7.244453430175781\n",
            "training loss: 7.135880947113037\n",
            "training loss: 6.867122173309326\n",
            "training loss: 6.68199348449707\n",
            "training loss: 6.995946884155273\n",
            "training loss: 6.855944633483887\n",
            "training loss: 6.867120742797852\n",
            "training loss: 6.862418174743652\n",
            "training loss: 7.013364315032959\n",
            "training loss: 7.034933090209961\n",
            "training loss: 6.600066661834717\n",
            "training loss: 6.662127494812012\n",
            "training loss: 6.950394630432129\n",
            "training loss: 6.848710060119629\n",
            "training loss: 6.615695476531982\n",
            "training loss: 6.620631217956543\n",
            "training loss: 6.404394149780273\n",
            "training loss: 6.871369361877441\n",
            "training loss: 6.910619735717773\n",
            "training loss: 6.814702987670898\n",
            "training loss: 6.5081706047058105\n",
            "training loss: 6.60158634185791\n",
            "training loss: 6.715150833129883\n",
            "training loss: 6.623115062713623\n",
            "training loss: 6.8308186531066895\n",
            "training loss: 6.9572014808654785\n",
            "training loss: 6.6331963539123535\n",
            "training loss: 6.53782844543457\n",
            "training loss: 6.78043270111084\n",
            "training loss: 6.76863956451416\n",
            "training loss: 6.7205071449279785\n",
            "training loss: 6.808658123016357\n",
            "training loss: 6.777750015258789\n",
            "training loss: 6.641203880310059\n",
            "training loss: 6.702694892883301\n",
            "training loss: 6.515505790710449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  83%|████████▎ | 50/60 [37:33<07:27, 44.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.946627616882324\n",
            "training loss: 6.919190406799316\n",
            "training loss: 6.712922096252441\n",
            "training loss: 6.84352970123291\n",
            "training loss: 7.003230094909668\n",
            "training loss: 6.939303874969482\n",
            "training loss: 6.940060615539551\n",
            "training loss: 6.985443592071533\n",
            "training loss: 6.762641429901123\n",
            "training loss: 6.857743740081787\n",
            "training loss: 7.059823989868164\n",
            "training loss: 6.890435218811035\n",
            "training loss: 6.757691383361816\n",
            "training loss: 7.055419445037842\n",
            "training loss: 6.742281913757324\n",
            "training loss: 6.771975040435791\n",
            "training loss: 6.705211162567139\n",
            "training loss: 6.628200054168701\n",
            "training loss: 6.987769603729248\n",
            "training loss: 6.8922576904296875\n",
            "training loss: 7.052491664886475\n",
            "training loss: 7.198223114013672\n",
            "training loss: 6.908904075622559\n",
            "training loss: 6.770943641662598\n",
            "training loss: 6.874757289886475\n",
            "training loss: 6.793854236602783\n",
            "training loss: 6.681744575500488\n",
            "training loss: 6.686190128326416\n",
            "training loss: 6.721324443817139\n",
            "training loss: 6.794504642486572\n",
            "training loss: 6.799674034118652\n",
            "training loss: 6.74558162689209\n",
            "training loss: 6.928972244262695\n",
            "training loss: 6.856265544891357\n",
            "training loss: 6.880568504333496\n",
            "training loss: 6.946216106414795\n",
            "training loss: 6.794065475463867\n",
            "training loss: 6.8296895027160645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  85%|████████▌ | 51/60 [38:17<06:40, 44.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.724647045135498\n",
            "training loss: 6.783707618713379\n",
            "training loss: 6.947519302368164\n",
            "training loss: 6.866488933563232\n",
            "training loss: 6.878560543060303\n",
            "training loss: 6.769696235656738\n",
            "training loss: 6.76023530960083\n",
            "training loss: 6.793209075927734\n",
            "training loss: 6.616102695465088\n",
            "training loss: 6.690528869628906\n",
            "training loss: 6.766738414764404\n",
            "training loss: 6.734953880310059\n",
            "training loss: 6.331267356872559\n",
            "training loss: 6.5170817375183105\n",
            "training loss: 6.636862277984619\n",
            "training loss: 6.700304985046387\n",
            "training loss: 6.748148441314697\n",
            "training loss: 6.711885452270508\n",
            "training loss: 6.8967509269714355\n",
            "training loss: 6.878975868225098\n",
            "training loss: 6.594389915466309\n",
            "training loss: 6.647706031799316\n",
            "training loss: 6.712264060974121\n",
            "training loss: 6.768217086791992\n",
            "training loss: 6.891278266906738\n",
            "training loss: 6.709778308868408\n",
            "training loss: 6.757904052734375\n",
            "training loss: 6.7845458984375\n",
            "training loss: 6.96627140045166\n",
            "training loss: 6.820450782775879\n",
            "training loss: 6.983388423919678\n",
            "training loss: 6.801181316375732\n",
            "training loss: 6.715183258056641\n",
            "training loss: 7.000616073608398\n",
            "training loss: 6.802511692047119\n",
            "training loss: 6.826325416564941\n",
            "training loss: 6.760960578918457\n",
            "training loss: 6.874362945556641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  87%|████████▋ | 52/60 [39:02<05:55, 44.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.869962215423584\n",
            "training loss: 7.03563928604126\n",
            "training loss: 6.977692604064941\n",
            "training loss: 6.900615215301514\n",
            "training loss: 6.9255218505859375\n",
            "training loss: 7.031053066253662\n",
            "training loss: 6.808694839477539\n",
            "training loss: 6.750919342041016\n",
            "training loss: 6.750294208526611\n",
            "training loss: 6.658038139343262\n",
            "training loss: 6.703537940979004\n",
            "training loss: 6.878395080566406\n",
            "training loss: 6.891085147857666\n",
            "training loss: 6.869298458099365\n",
            "training loss: 7.049217224121094\n",
            "training loss: 6.8477678298950195\n",
            "training loss: 6.658186435699463\n",
            "training loss: 6.848686218261719\n",
            "training loss: 6.797871112823486\n",
            "training loss: 6.658743858337402\n",
            "training loss: 6.604108810424805\n",
            "training loss: 6.8047966957092285\n",
            "training loss: 6.722949028015137\n",
            "training loss: 6.6173930168151855\n",
            "training loss: 6.7778544425964355\n",
            "training loss: 6.649733543395996\n",
            "training loss: 6.769294261932373\n",
            "training loss: 6.626543045043945\n",
            "training loss: 6.800495147705078\n",
            "training loss: 6.50053071975708\n",
            "training loss: 6.646660804748535\n",
            "training loss: 6.615232944488525\n",
            "training loss: 6.753722190856934\n",
            "training loss: 7.004782199859619\n",
            "training loss: 6.745397567749023\n",
            "training loss: 6.8017072677612305\n",
            "training loss: 6.800302028656006\n",
            "training loss: 6.703521728515625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  88%|████████▊ | 53/60 [39:46<05:11, 44.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.671805381774902\n",
            "training loss: 6.794869422912598\n",
            "training loss: 6.978945732116699\n",
            "training loss: 6.85023307800293\n",
            "training loss: 6.941187858581543\n",
            "training loss: 6.824036598205566\n",
            "training loss: 6.711551189422607\n",
            "training loss: 6.731969833374023\n",
            "training loss: 6.598822116851807\n",
            "training loss: 6.685663223266602\n",
            "training loss: 7.093117713928223\n",
            "training loss: 6.906042575836182\n",
            "training loss: 6.857504844665527\n",
            "training loss: 6.95975399017334\n",
            "training loss: 6.9264912605285645\n",
            "training loss: 6.910419464111328\n",
            "training loss: 6.998505115509033\n",
            "training loss: 6.793216705322266\n",
            "training loss: 6.754652976989746\n",
            "training loss: 6.775754451751709\n",
            "training loss: 6.834897994995117\n",
            "training loss: 6.821693420410156\n",
            "training loss: 6.904482841491699\n",
            "training loss: 6.629404544830322\n",
            "training loss: 6.806224346160889\n",
            "training loss: 6.88192081451416\n",
            "training loss: 6.650879859924316\n",
            "training loss: 6.939759254455566\n",
            "training loss: 6.885676383972168\n",
            "training loss: 6.940486907958984\n",
            "training loss: 6.838658809661865\n",
            "training loss: 6.84614896774292\n",
            "training loss: 7.026703834533691\n",
            "training loss: 6.774738788604736\n",
            "training loss: 6.6800689697265625\n",
            "training loss: 6.805431365966797\n",
            "training loss: 6.721923351287842\n",
            "training loss: 6.745452880859375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  90%|█████████ | 54/60 [40:31<04:26, 44.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.951619625091553\n",
            "training loss: 7.045842170715332\n",
            "training loss: 7.091106414794922\n",
            "training loss: 6.919526100158691\n",
            "training loss: 6.899987697601318\n",
            "training loss: 6.655780792236328\n",
            "training loss: 6.702169418334961\n",
            "training loss: 6.8906450271606445\n",
            "training loss: 6.754733562469482\n",
            "training loss: 6.667217254638672\n",
            "training loss: 6.395048141479492\n",
            "training loss: 6.616778373718262\n",
            "training loss: 6.757534503936768\n",
            "training loss: 6.619312763214111\n",
            "training loss: 6.754955291748047\n",
            "training loss: 6.923076629638672\n",
            "training loss: 6.881025314331055\n",
            "training loss: 6.754110336303711\n",
            "training loss: 6.763138294219971\n",
            "training loss: 6.835114002227783\n",
            "training loss: 6.767251014709473\n",
            "training loss: 6.53684139251709\n",
            "training loss: 6.7774858474731445\n",
            "training loss: 6.918887138366699\n",
            "training loss: 6.719938278198242\n",
            "training loss: 6.7079267501831055\n",
            "training loss: 6.710048675537109\n",
            "training loss: 6.991179466247559\n",
            "training loss: 6.619680881500244\n",
            "training loss: 6.574758529663086\n",
            "training loss: 6.468436241149902\n",
            "training loss: 6.894420146942139\n",
            "training loss: 6.766648769378662\n",
            "training loss: 6.562002182006836\n",
            "training loss: 6.727445125579834\n",
            "training loss: 6.64243221282959\n",
            "training loss: 6.7484893798828125\n",
            "training loss: 6.53576135635376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  92%|█████████▏| 55/60 [41:15<03:41, 44.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 7.007963180541992\n",
            "training loss: 7.159438133239746\n",
            "training loss: 7.011298179626465\n",
            "training loss: 6.69057559967041\n",
            "training loss: 6.715489387512207\n",
            "training loss: 6.949400901794434\n",
            "training loss: 6.792532920837402\n",
            "training loss: 6.740147590637207\n",
            "training loss: 6.881240367889404\n",
            "training loss: 6.687745094299316\n",
            "training loss: 6.79519510269165\n",
            "training loss: 6.622842788696289\n",
            "training loss: 6.767934799194336\n",
            "training loss: 6.671315670013428\n",
            "training loss: 6.691495418548584\n",
            "training loss: 6.856657981872559\n",
            "training loss: 6.8954877853393555\n",
            "training loss: 6.626975059509277\n",
            "training loss: 6.666172027587891\n",
            "training loss: 6.914669036865234\n",
            "training loss: 6.962092399597168\n",
            "training loss: 6.691919326782227\n",
            "training loss: 6.733644008636475\n",
            "training loss: 6.7356414794921875\n",
            "training loss: 6.51277494430542\n",
            "training loss: 6.754828453063965\n",
            "training loss: 6.628201007843018\n",
            "training loss: 6.897411346435547\n",
            "training loss: 6.85250186920166\n",
            "training loss: 6.448227405548096\n",
            "training loss: 6.584709167480469\n",
            "training loss: 6.447031021118164\n",
            "training loss: 6.800057411193848\n",
            "training loss: 6.5190205574035645\n",
            "training loss: 6.729123592376709\n",
            "training loss: 6.837628364562988\n",
            "training loss: 6.473816871643066\n",
            "training loss: 6.857430458068848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  93%|█████████▎| 56/60 [42:01<02:59, 44.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.797827243804932\n",
            "training loss: 6.759607315063477\n",
            "training loss: 6.85659122467041\n",
            "training loss: 6.78914737701416\n",
            "training loss: 6.981288909912109\n",
            "training loss: 6.917618751525879\n",
            "training loss: 6.8360395431518555\n",
            "training loss: 6.820718288421631\n",
            "training loss: 6.686929702758789\n",
            "training loss: 6.842837810516357\n",
            "training loss: 6.609134674072266\n",
            "training loss: 6.7176313400268555\n",
            "training loss: 6.613124847412109\n",
            "training loss: 6.758836269378662\n",
            "training loss: 6.831055164337158\n",
            "training loss: 6.76753044128418\n",
            "training loss: 6.796454429626465\n",
            "training loss: 6.739566802978516\n",
            "training loss: 6.914268493652344\n",
            "training loss: 6.668508052825928\n",
            "training loss: 6.699785232543945\n",
            "training loss: 6.775129795074463\n",
            "training loss: 6.771200180053711\n",
            "training loss: 6.690496921539307\n",
            "training loss: 6.635709285736084\n",
            "training loss: 6.66858434677124\n",
            "training loss: 6.660706996917725\n",
            "training loss: 6.605125904083252\n",
            "training loss: 6.822094440460205\n",
            "training loss: 6.720168113708496\n",
            "training loss: 6.7575459480285645\n",
            "training loss: 6.840296268463135\n",
            "training loss: 6.778925895690918\n",
            "training loss: 6.796205520629883\n",
            "training loss: 6.955105781555176\n",
            "training loss: 6.676165580749512\n",
            "training loss: 6.722005844116211\n",
            "training loss: 6.866161346435547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  95%|█████████▌| 57/60 [42:45<02:13, 44.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.606444358825684\n",
            "training loss: 6.853038787841797\n",
            "training loss: 6.764427185058594\n",
            "training loss: 6.736867427825928\n",
            "training loss: 6.901340484619141\n",
            "training loss: 7.02724552154541\n",
            "training loss: 6.875988006591797\n",
            "training loss: 6.892104148864746\n",
            "training loss: 6.744516372680664\n",
            "training loss: 6.827359199523926\n",
            "training loss: 6.958185195922852\n",
            "training loss: 6.736724853515625\n",
            "training loss: 6.723901748657227\n",
            "training loss: 6.765573024749756\n",
            "training loss: 6.868349552154541\n",
            "training loss: 6.642460823059082\n",
            "training loss: 6.433295249938965\n",
            "training loss: 6.65081262588501\n",
            "training loss: 6.613783836364746\n",
            "training loss: 6.6848883628845215\n",
            "training loss: 6.995840072631836\n",
            "training loss: 6.696464538574219\n",
            "training loss: 6.860509872436523\n",
            "training loss: 6.832457542419434\n",
            "training loss: 6.493842601776123\n",
            "training loss: 6.847802639007568\n",
            "training loss: 6.617728233337402\n",
            "training loss: 6.825465202331543\n",
            "training loss: 7.018266201019287\n",
            "training loss: 6.709499359130859\n",
            "training loss: 6.763846397399902\n",
            "training loss: 6.7505269050598145\n",
            "training loss: 6.840058326721191\n",
            "training loss: 6.670571804046631\n",
            "training loss: 6.85072660446167\n",
            "training loss: 6.9716796875\n",
            "training loss: 6.805851459503174\n",
            "training loss: 6.890529155731201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  97%|█████████▋| 58/60 [43:29<01:29, 44.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.882970809936523\n",
            "training loss: 6.782001495361328\n",
            "training loss: 7.169014930725098\n",
            "training loss: 6.889671325683594\n",
            "training loss: 6.914960861206055\n",
            "training loss: 6.911332130432129\n",
            "training loss: 6.799187660217285\n",
            "training loss: 6.774523735046387\n",
            "training loss: 6.8341217041015625\n",
            "training loss: 6.931153297424316\n",
            "training loss: 6.885107517242432\n",
            "training loss: 6.851388931274414\n",
            "training loss: 6.850838661193848\n",
            "training loss: 6.867079734802246\n",
            "training loss: 7.163212299346924\n",
            "training loss: 6.896615028381348\n",
            "training loss: 6.750495910644531\n",
            "training loss: 6.7500128746032715\n",
            "training loss: 6.696978569030762\n",
            "training loss: 6.747719764709473\n",
            "training loss: 6.845434188842773\n",
            "training loss: 6.889888763427734\n",
            "training loss: 6.497117042541504\n",
            "training loss: 7.125438213348389\n",
            "training loss: 6.75816535949707\n",
            "training loss: 6.880037784576416\n",
            "training loss: 6.726534843444824\n",
            "training loss: 6.796693801879883\n",
            "training loss: 6.784647464752197\n",
            "training loss: 6.815014362335205\n",
            "training loss: 6.780012130737305\n",
            "training loss: 6.708072662353516\n",
            "training loss: 6.767285346984863\n",
            "training loss: 6.982049942016602\n",
            "training loss: 7.011098861694336\n",
            "training loss: 6.946250915527344\n",
            "training loss: 6.951863765716553\n",
            "training loss: 6.9137468338012695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  98%|█████████▊| 59/60 [44:14<00:44, 44.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss: 6.903246879577637\n",
            "training loss: 6.909697532653809\n",
            "training loss: 7.084811687469482\n",
            "training loss: 6.921163082122803\n",
            "training loss: 6.787458419799805\n",
            "training loss: 6.727825164794922\n",
            "training loss: 6.968396186828613\n",
            "training loss: 6.669325828552246\n",
            "training loss: 6.744665145874023\n",
            "training loss: 6.900182723999023\n",
            "training loss: 6.851892471313477\n",
            "training loss: 6.8301591873168945\n",
            "training loss: 6.639166831970215\n",
            "training loss: 6.757025718688965\n",
            "training loss: 6.893001556396484\n",
            "training loss: 6.961509704589844\n",
            "training loss: 6.767419338226318\n",
            "training loss: 6.682001113891602\n",
            "training loss: 6.7333221435546875\n",
            "training loss: 6.973587512969971\n",
            "training loss: 7.052105903625488\n",
            "training loss: 7.095136642456055\n",
            "training loss: 7.083889961242676\n",
            "training loss: 6.672475814819336\n",
            "training loss: 6.846254348754883\n",
            "training loss: 6.772671222686768\n",
            "training loss: 6.66552209854126\n",
            "training loss: 6.683398723602295\n",
            "training loss: 6.724193572998047\n",
            "training loss: 6.803128242492676\n",
            "training loss: 6.656091690063477\n",
            "training loss: 6.8601861000061035\n",
            "training loss: 6.7769670486450195\n",
            "training loss: 6.752176284790039\n",
            "training loss: 6.742641448974609\n",
            "training loss: 6.7055816650390625\n",
            "training loss: 6.562867641448975\n",
            "training loss: 6.621020317077637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "training: 100%|██████████| 60/60 [44:58<00:00, 44.97s/it]\n",
            "evaluation: 100%|██████████| 7/7 [03:21<00:00, 28.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "perplexity: 532.1536254882812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "#Luigi\n",
        "perplexity_list = []\n",
        "with open(f'drive/MyDrive/Colab Notebooks/perplexity_memorizing_tr.pkl', 'rb') as pklfile:\n",
        "  perplexity_list = pkl.load(pklfile)\n"
      ],
      "metadata": {
        "id": "16-Mkrn0WGN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EImcz56-GmYS",
        "outputId": "c2ce49c9-fc19-4b27-8f61-4b4d6b8c06da"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[577.5076904296875, 559.738037109375, 532.1536254882812]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(epochs + 1)[1:], perplexity_list, label = \"Memorizing Transformer Perplexity Plot\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "n1DiMQgKWJnx",
        "outputId": "a97a4744-5207-4d67-8b9b-7fbae231346c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer decoder training"
      ],
      "metadata": {
        "id": "ayPdgmodFg4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we have defined the TransformerDecoder class that allows to create decoder-only transformers. We have trained an object of this class in order to compare it to the memorizing transformer of the previous section."
      ],
      "metadata": {
        "id": "PL1AgnOKfYmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module): #decoder-only architecture of the transformer\n",
        "  def __init__(\n",
        "        self,\n",
        "        num_tokens,\n",
        "        d,\n",
        "        heads = 8,\n",
        "        depth = 4,\n",
        "        hidden_size = 1000,\n",
        "        dropout = 0.3,\n",
        "        batch_size = 16,\n",
        "        use_bert = True\n",
        "    ):\n",
        "      self.use_bert = use_bert\n",
        "      self.d = d if not self.use_bert else 768\n",
        "      assert self.d % heads == 0\n",
        " \n",
        "      super(TransformerDecoder, self).__init__()\n",
        "      if self.use_bert:\n",
        "        self.token_emb = BertModel.from_pretrained('bert-base-uncased')\n",
        "      else:\n",
        "        self.token_emb = nn.Embedding(num_tokens, self.d)\n",
        "        \n",
        "      self.positional_enc = PositionalEncoding(self.d, max_len = 5000)\n",
        "      self.dim_head = self.d // heads\n",
        "      self.heads = heads\n",
        "      self.depth = depth\n",
        "      self.hidden_size = hidden_size\n",
        "      self.dropout = dropout\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "      self.layers = nn.ModuleList([])\n",
        "      for idx in range(depth):\n",
        "          self.layers.append(\n",
        "              TransformerBlock(d, heads, batch_size, hidden_size, dropout)\n",
        "          )\n",
        "\n",
        "      self.to_out = nn.Linear(d, num_tokens)\n",
        "    \n",
        "  def create_mask(self, x):\n",
        "    batch_size, seq_len = x.shape\n",
        "    mask = torch.tril(torch.ones((seq_len, seq_len))).expand(\n",
        "        batch_size, 1, seq_len, seq_len\n",
        "    )\n",
        "    return mask \n",
        "          \n",
        "  def forward(self, x):\n",
        "    mask = self.create_mask(x)\n",
        "\n",
        "    if self.use_bert:\n",
        "      x = self.token_emb(x)[0] #with bert\n",
        "    else:\n",
        "      x = self.token_emb(x) #without bert\n",
        "    x = self.positional_enc(x)\n",
        "\n",
        "    for idx in range(self.depth):\n",
        "        x= self.layers[idx](x, mask)\n",
        "\n",
        "    return self.to_out(x).transpose(1, 2)"
      ],
      "metadata": {
        "id": "lBz91btCHjXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "SEQ_LEN = 256\n",
        "SEGMENTS = 5\n",
        "HEADS = 8\n",
        "DIM_HEAD = SEQ_LEN // HEADS\n",
        "DIM_HEAD_BERT = 768 // HEADS\n",
        "LEARNING_RATE = 2e-4\n",
        "MAX_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "EVAL_EVERY = 20\n",
        "CHECKPOINT = 5"
      ],
      "metadata": {
        "id": "sF-Xk7gtKMA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tr_decoder = TransformerDecoder(\n",
        "    num_tokens = vocabulary_size,\n",
        "    d = SEQ_LEN,\n",
        "    depth = 4,\n",
        "    heads = HEADS,\n",
        "    hidden_size = 1000,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    use_bert = True\n",
        ").to(device)\n",
        "\n",
        "train_loader_ = DataLoader(train_ds, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)\n",
        "test_loader_ = DataLoader(test_ds, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)"
      ],
      "metadata": {
        "id": "GOz3oBuiGkYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer\n",
        "optimizer = torch.optim.Adam(tr_decoder.parameters(), lr = LEARNING_RATE)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "epochs = 5\n",
        "# training\n",
        "\n",
        "perplexity_tr_decoder = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  for i, data in enumerate(tqdm.tqdm(train_loader_, desc = 'training')):\n",
        "    tr_decoder.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "\n",
        "    num_seq = 10000 // (SEQ_LEN + 1)\n",
        "    data = data.long().to(device)\n",
        "    for j in range(num_seq):\n",
        "      mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "      seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "\n",
        "      out = tr_decoder(seq)\n",
        "\n",
        "      loss_item = loss(out, labels)\n",
        "      print(f'training loss: {loss_item}', flush = True)\n",
        "      loss_item.backward() \n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_CLIP_NORM)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "  data = None\n",
        "    \n",
        "\n",
        "  if e % EVAL_EVERY == 0:\n",
        "    tr_decoder.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      metric = Perplexity().to(device)\n",
        "      for i, data in enumerate(tqdm.tqdm(test_loader_, desc = 'evaluation')):\n",
        "        num_seq = 10000 // (SEQ_LEN + 1)\n",
        "        data = data.long().to(device)\n",
        "\n",
        "        for j in range(num_seq):\n",
        "          mini_batch = data[:, j*(SEQ_LEN + 1):(j+1)*(SEQ_LEN + 1)]\n",
        "          seq, labels = mini_batch[:, :-1], mini_batch[:, 1:]\n",
        "\n",
        "          out = tr_decoder(seq)\n",
        "\n",
        "          test_loss = loss(out, labels)\n",
        "          metric(out.transpose(1, 2), labels)\n",
        "          print(f'test loss: {test_loss}', flush = True)\n",
        "\n",
        "      perplexity = metric.compute()\n",
        "      perplexity_tr_decoder.append(perplexity.to(\"cpu\").item())\n",
        "      print(f'perplexity: {perplexity}', flush = True)\n",
        "\n",
        "  data = None\n",
        "  if e % CHECKPOINT == 0:\n",
        "    #Luigi\n",
        "    torch.save({\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, 'drive/MyDrive/Colab Notebooks/model_optimizer_tr_decoder.pt')\n",
        "    \"\"\"\n",
        "    #Lorenzo\n",
        "    with open('/content/drive/MyDrive/Università/Magistrale/Secondo Anno/Neural Networks/project/perplexity_moreNN.npy', 'wb') as f:\n",
        "      np.save(f, np.array(perplexity_list))\n",
        "    \"\"\"\n",
        "    #Luigi\n",
        "    with open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'wb') as pklfile:\n",
        "      pkl.dump(perplexity_tr_decoder, pklfile)"
      ],
      "metadata": {
        "id": "tqKuP2z1BeFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "perplexity_tr_decoder = []\n",
        "with open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\n",
        "  perplexity_tr_decoder = pkl.load(pklfile)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QcYwi7zKXre0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "89d72de5-e537-4baf-ff4f-1cf5caf6b5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nperplexity_tr_decoder = []\\nwith open(f'drive/MyDrive/Colab Notebooks/perplexity_tr_decoder.pkl', 'rb') as pklfile:\\n  perplexity_tr_decoder = pkl.load(pklfile)\\n  pklfile.close()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(epochs + 1)[1:], perplexity_tr_decoder, label = 'Perplexity transformer decoder')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1rb7IdThijCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A further experiment to do could be the memory fine-tuning, where a KNNMemory object is passed to a decoder-only transformer only after some training epochs. In order to do this we would need to modify the TransformerDecoder class or to create a memorizing transformer after some changes in the KNNAttention class. The latter method would consists in modifying the forward method of KNNAttention to handle a missing KNNMemory so that until we pass to the layer a memory the layer acts like a standard multi-head attention.\n",
        "\n",
        "In the paper memory fine-tuning is showed to be very effective since it allows a transformer to perform like a memorizing transformer after enough training steps. It would be useful because the retrieval of the nearest neighbors from the external memory clearly makes the vanilla memorizing transformer slower than a regular decoder-only transformer and we could avoid for many training steps this computation and achieve the same results."
      ],
      "metadata": {
        "id": "aTh-D095j7UP"
      }
    }
  ]
}